import { SearchPayload } from "@/components/jamie-horizontal-timeline";

export const sampleSearchPayloads: SearchPayload[] =
[
  {
    "query": "one x robot capabilities user forum discussions",
    "results": []
  },
  {
    "query": "technical challenges in one x company's autonomous robot development",
    "results": []
  },
  {
    "query": "technical challenges in one x robot's autonomous door-opening capability",
    "results": []
  },
  {
    "query": "one x robot autonomy claims vs real-world performance dishes task",
    "results": []
  },
  {
    "query": "comparative study of ai product overhyping across companies",
    "results": []
  },
  {
    "query": "user forum reactions to rabbit r1's ai capabilities",
    "results": []
  },
  {
    "query": "selling the dream in ai marketing trends 2025",
    "results": []
  },
  {
    "query": "comparative study of ai product overhyping across companies 2025",
    "results": [
      {
        "title": "The Agony and Ecstasy of Reviewing Humane's Ai Pin",
        "url": "https://www.inverse.com/tech/humane-ai-pin-in-depth-review",
        "snippet": "# Humane\u2019s Ai Pin Isn't Ready to Replace Your Phone, But One Day It Might\\n\\nThe Ai Pin is an ambitious device and blueprint for the future of mobile computing, but first-gen compromises keep it grounded in the present.\\n\\nMurphy\u2019s law states that \u201canything that can go wrong will go wrong.\u201d That pretty much sums up my first three days with Humane\u2019s Ai Pin.\\n\\nMusic from Tidal wouldn\u2019t stream. High-res versions of the photos I took and regular videos recorded with the Ai Pin wouldn\u2019t upload to my connected \u201cHumane.Center\u201d cloud portal. And the multi-modal artificial intelligence voice assistant that you engage with to answer your questions or remember \u201cnotes\u201d that you tell it, like a \u201csecond brain,\u201d felt brain-dead half the time, failing to answer questions it previously got correct.\\n\\nNot great for a product that is supposed to showcase how AI could make mobile computing even more personal, more ambient, and less disruptive than the smartphones and addictive apps we\u2019ve come to rely on.\\n\\nAfter many emails trying to troubleshoot all of the issues with my Ai Pin review unit, Humane co-founder and CEO Bethany Bongiorno invited me to the company\u2019s New York City office a second time to get a replacement. I left with two Ai Pins to test, but it turned out a factory reset was all that was needed to resolve the problems on my review unit.... Smartphones changed all of that, and now, companies like Humane and Rabbit claim AI is going to shift mobile computing from being app-based (where you input, tap, scroll, and swipe on things to get stuff done) to straight-up delivering info and doing a task for you. Bongiorno says AI is a faster \u2014 if not necessarily better \u2014 way to compute instead of poking at a smartphone display or an even tinier smartwatch screen. She and Chaudhri hired a lot of former Apple employees, including Ken Kocienda (aka the guy who invented the original iPhone\u2019s autocorrect keyboard), and they all seem to believe a head-worn computer like the Apple Vision Pro isn\u2019t the future they want to create and foist onto the next generations.\\n\\nThere is some irony in buying a $699 device with phone-like capabilities and paying $24 for a monthly Humane subscription plan with the goal of using your phone less.\\n\\nSpeed is essential for AI-powered experiences to resonate with consumers, and that\u2019s also the Ai Pin\u2019s biggest compromise. At launch, the Ai Pin\u2019s whole \u201cCosmos\u201d operating system and AI stack, comprised of the voice-based AI assistant and the Laser Ink Display projector, is slow to answer even basic questions. Tapping the touchpad with a single finger and then speaking to, or asking a question to the Ai Mic is easy after you learn the gesture controls, but it\u2019s the time spent waiting for the AI to respond that often frustrated me. Compared to Alexa, Google Assistant, and yes, even Siri, getting an answer to certain basic questions like \u201cWhat\u2019s the weather?\u201d using the Ai Pin can take as long as six seconds. That may not seem like a long wait, but when the other assistants can answer almost immediately, the Ai Pin feels like a turtle crawling while the hares race by, leaving a trail of dust.... When the Ai Pin isn\u2019t testing my patience with answer wait times, the AI often is confused or forgetful. For example, I asked the AI: \u201cWhat was the last article that Raymond Wong at\\n\\n*Inverse* wrote?\u201d Sometimes, it gave me the correct answer: \u201cThe last article written by Raymond Wong for *Inverse* was 'Spatial Personas Make Apple Vision Pro a Less Isolating...' published 7 days ago.\u201d Other times, when asked at a later time or another day, it simply doesn\u2019t know or remember that it correctly answered the question before. It answered back: \u201cThe latest article by Ray Wong at *Inverse* is not available in the provided search results\u201d and \u201cThere is no information available about the latest article by Ray Wong at *Inverse*. Is there anything else you'd like to know?\u201d\\n\\nThere\u2019s a reason why Humane uses a lowercase \u201ci\u201d to write AI in Ai Pin. \u201cTo signify we\u2019re in the early days of artificial intelligence,\u201d Bongiorno tells me. Clearly, the AI in the Ai Pin still has a ways to go.... The Ai Pin\u2019s AI isn\u2019t always missing \u2014 when it hits, it feels like a revelatory moment. The \u201cmagic\u201d of AI versus Alexa/Google Assistant/Siri is that you don\u2019t need to speak like a robot for it to understand what you\u2019re saying. You can also ask follow-up questions because AI is contextual and knows what you said earlier. This natural language processing (NLP) is what everyone is holding up as the next way to interact with computers. Just talk to it like you would to another human. Instead of saying to the Ai Pin, \u201cPlay the song \u2018Thunderstruck\u2019 by AC/DC\u201d you could say, \u201cPlay me a kickass anthem to get this party started.\u201d In theory, the Ai Pin\u2019s should be able to do that every time when asked, and the AI has successfully played that song for me when asked to set the vibe, but it can also fail as well. Bongiorno tells me a range of reasons, from server-side bugs at Humane or Tidal (the only music streaming service Ai Pin supports at launch) to even a poor wireless signal (either over LTE or Wi-Fi) can cause the AI to give bad answers or none at all. Throughout the majority of my week of testing, Humane said it had addressed several bugs that caused the AI to perform at less than optimal intelligence and responsiveness. The built-in speaker is by no means the best quality, and it does sound tinny at louder volume levels, but it\u2019s convenient walking in the park and getting ambient music at ear level without holding up my phone. You can also connect Bluetooth earbuds for private listening at any time.... When I kept badgering the AI, it caved and told me it had simulated the scene:\\n\\nThe information provided earlier was based on a simulated scene analysis and not actual visual observation. If there's anything else you'd like to know or discuss, feel free to ask.\\n\\nIf I were a person with a visual impairment, I wouldn\u2019t be able to rely on the Vision feature to accurately describe a scene. Clearly, Vision is labeled a beta feature for a reason.\\n\\nNearly 3,000 words into this review, you\u2019re probably wondering why I\u2019m just now getting to what it\u2019s like operating the Ai Pin \u2014 using its touchpad with one and two-finger taps, double-taps, tap and holds, and using hand gestures (selecting with a tap of your thumb and index finger, pushing and pulling to navigate menus like the PIN lock, tilting and rolling your hand to move in different directions and scroll up and down, and closing your hand to go back to the previous screen or back to the \u201chome\u201d screen that show the time, battery life, and wireless connection) with the sci-fi-like Laser Ink Display projector. I have a reason for that: Because as cool as the projector is \u2014 everyone gets a kick from seeing it in action \u2014 it\u2019s not meant to be used very much. It\u2019s for brief interactions where it might be inappropriate for the AI to speak out loud or you need confirmation for something such as the composition of a photo or video.... ## A Very First-Gen Preview of The Future\\n\\nThe early messaging for the Ai Pin seemed to tout it as a smartphone replacement. Humane walked that back, either because of vocal criticism or, as I\u2019ve found out for myself, because the hardware and AI just aren\u2019t able to do a lot of essential phone things either as reliably, faster, better, or even at all.\\n\\nTake the 13-megapixel ultra-wide camera. It\u2019s simply terrible. Photos look like they were taken with an iPhone 4 with poor dynamic range, no shadow detail, and overall bad sharpness. It doesn\u2019t matter if I take photos inside or outside, or in good lighting or bad lighting \u2014 they don\u2019t look good. I couldn\u2019t get anything resembling what Humane\u2019s been showing off. The chipset is using a four-year-old image signal processor, so that doesn\u2019t help matters.\\n\\nVideos are pretty bad, too, with awful stabilization that always results in really visibly jiggly footage.\\n\\nOn top of that, most of my captured photos and videos are poorly framed, usually tilted or aimed too low. I consider myself an above-average amateur photographer with a solid grasp of composition guidelines like the rule of thirds, but there\u2019s nowhere on my body where I can clip the Ai Pin and get a shot that I would later look at and love. That\u2019s partially the Ai Pin\u2019s fault because the camera is aimed slightly downwards and not straight ahead, and partially because I\u2019m 5\u20196\u201d (66 inches tall). Attaching the Ai Pin at just above my heart, that\u2019s 15 inches lower than the top of my head and 10 inches lower than my eye level (basically equivalent to a camera on top of a 51-inch tripod), or what my real POV would be and the height at which I typically hold up my phone to capture a photo or video. If you\u2019re taller, the Ai Pin will be at a higher height, but how your footage turns out will depend entirely on your height. That\u2019s not something Humane can fix in the second or third generation unless it has a camera that can aim upward or uses AI to auto-magically reframe a shot. I was really excited to see how the AI would be used to create the best shot with a mixture of auto-cropping, straightening, and image fusion. I\u2019m disappointed to see the camera is worse than a GoPro or photos taken with smartglasses like the ones from Meta and Ray-Ban.",
        "published_at": "2024-04-11"
      },
      {
        "title": "Humane Ai Pin Reviews Nightmare: Takeaways and Analysis",
        "url": "https://www.techsponential.com/reports/humanereviews",
        "snippet": "# Humane Ai Pin Reviews Nightmare: Takeaways and Analysis\\n\\n### Ai Pin Reviews and Humane\u2019s Response\\n\\nHumane is a well-funded startup with excellent pedigree for modern mobile electronics; its founders and many of its key engineers previously worked on the iPhone at Apple. My analysis of the Ai Pin when it emerged from stealth was somewhat skeptical of the stand-alone product positioning, but noted that if Humane\u2019s voice-driven, laser projection/gesture interface provided a uniquely valuable experience, the price point would not be an issue. Then, at MWC 2024, the company gave live demos inside the Qualcomm booth that showed off the promise of the concept.\\n\\nOver the past week, initial Humane Ai Pin reviews were released and were so universally terrible that they generated controversy over the role of product reviewers. However, this isn\u2019t a case of Marques Brownlee (MKBHD on YouTube) seeking to draw viewers with sensationalism by calling the Ai Pin, \u201cthe worst product I\u2019ve ever reviewed.\u201d TheVerge\u2019s David Pierce described it as \u201cnot even close,\u201d and there were similar reactions from Arun Maines (Mrwhosetheboss on YouTube), CNET\u2019s Scott Stein, and Bloomberg\u2019s Mark Gurman. Even Michael Fisher (MrMobile on YouTube), who has been pining for a Star Trek comm badge for decades, could not recommend the product.\\n\\nThe company's official response has been to thank reviewers for approaching the category optimistically and emphasizing pricing and execution problems, not the concept of an AI wearable (even though some did question whether new AI wearables can exist alongside AI phones and smartwatches). Humane says that it appreciates the feedback and that it is working to add functionality and fix the problems that reviewers have pointed out. This is the best approach the company could take at this point; attacking reviewers would just make things worse. Reviewers\u2019 responsibility is to their audience and the algorithm, not the manufacturer.... ### It Didn\u2019t Have to Be This Way\\n\\nOf course, it didn\u2019t have to be this way. Launching a new company in a new category is always going to be a challenge, but Humane made things harder for itself by courting hype, over-promising, and then releasing the product well before it had a minimally viable feature set and a product that worked properly. If nothing else, the reviewers\u2019 reactions should not have been a surprise if Humane had conducted a third-party mock review / viability process. (Full disclosure: Techsponential regularly provides this as a service. We are often asked to test products before launch under NDA and write a review for internal use that includes bugs encountered, whether the product is ready for launch, pricing, and marketing positioning recommendations. Reach out if you\u2019d like to schedule one.)\\n\\nThis is not an indictment of all 1.0 products. In order to get something out the door \u2013 and get revenue flowing in \u2013 companies often have to ship something before the vision for the product is fully realized. Amazon\u2019s Kindle Scribe launched without critical features for managing your notes, but even at launch it was a fine large format Kindle for reading, and the team at Amazon continued improving the software and it\u2019s a much better product today. Apple launched the Apple Vision Pro without much software support, but that is growing daily, and even on day one the Apple Vision Pro offered a superior video watching experience with extensive content, along with nearly a million 2D iPad apps for productivity. That begs the question: is the problem with Humane\u2019s Ai Pin that it shipped too soon, before it reached an MVP (Minimum Viable Product) state? Or is the problem that the AI accessory product category as a whole is doomed?... ### What Can Likely Be Fixed\\n\\nSome of the complaints about the Ai Pin are specific to this iteration of the product that could be fixed with software updates, hardware updates, or interface tweaks:\\n\\nAccording to all the reviewers, the Ai Pin regularly overheats.\\n\\nBattery life is so poor that Humane includes multiple batteries and a portable charger in the box.\\n\\nAI responses are sometimes unbearably slow.\\n\\nThe Pin requires frequent authentication that is difficult to enter with the projection interface.\\n\\nThe projection interface itself can only be used for short periods of time and gets easily washed out outdoors.\\n\\nCamera output is poor, photos can be skewed depending on how the Pin is angled on your clothing, and it isn\u2019t always obvious when taking photos what is in frame.\\n\\nDoing anything with content \u2013 including sharing or posting photos \u2013 must be mediated by Humane\u2019s website rather than an app on your phone.\\n\\nCommon tasks where having an AI assistant a tap away on your chest would be most useful -- like to-do entries and calendar integration \u2013 aren\u2019t supported.\\n\\nThere are very few services integrated with the Ai Pin. For example, Tidal is the only music service supported.\\n\\nNot all of these issues need to be fixed for the product to be successful, but all of them can be addressed with improvements to the hardware or software. Some of this is already on Humane\u2019s roadmap, with the company promising fixes to the overheating issue, calendar integration, and an API for third party services in future software updates. Others may require new iterations of the hardware.... ### What Might Also Be Fixable\\n\\nIn the least surprising conclusion from the reviews, today\u2019s AI provides answers that are sometimes just wrong. AI for its own sake is suspect as a value proposition today.\\n\\n*Any* product that is sold primarily for AI access needs to account for the state of the technology. This may change over time. Developers are working on ways for LLMs to internally fact check with trusted sources before responding, and AI is advancing so rapidly that it may just be a matter of time where you can ask Jarvis and trust the answer is correct. Or not. We\u2019ll see.\\n\\nPricing is a key concern. If the price was lower, the bar for utility would be lower as well. The Ai Pin is both a relatively expensive $700 device and requires an ongoing $24/month service subscription. If the Ai Pin could replace your phone, that pricing would not be an issue, but for an accessory, at the very least it pushes it into well-heeled early adopter territory. There is also profitability to consider; Humane is a well-funded startup, but still just a startup, not a division of a company that makes billions on advertising, software, or hardware. If Humane cuts pricing to spur demand, it will have to cut deep, and then its revenue numbers won't add up for investors.... ### What Isn\u2019t Going to Change\\n\\nHowever, some of the issues that reviewers highlighted are based on Humane\u2019s design and positioning of the Ai Pin, and these cannot be changed without altering what the Ai Pin is.\\n\\nAs an independent device, Humane\u2019s Ai Pin has its own phone number and does not work with any group messaging platform such as WhatsApp or iMessage. That limits how the Ai Pin can be used for communication, and means that the AI summary \u201ccatch-up\u201d feature misses many important notifications.\\n\\nA wearable without an interactive display requires voice, and there are lots of situations where voice doesn't work (such as loud environments) or is socially inappropriate (on public transportation, in meetings, dealing with anything personal public spaces, etc.). However, a pin-style wearable simply cannot support a display directly. Smart glasses, smartwatches, or using your phone\u2019s display are all ways around this, but then it\u2019s not a pin anymore. This doesn\u2019t mean that there is no market for this form factor, but the form factor does limit how many jobs the product can do. It almost demands that this form factor act not as a standalone device, but as an extension of something else: your phone.\\n\\nThere are many paths to get to AI, including your phone, earbuds, smart watches, smart glasses, smart cars, smart speakers, and smart appliances. However, the smartphone is the center of your digital life, and AI integration is necessarily going to have to live there. Phones are not going away. They are too useful, flexible, and deeply integrated into the digital and real world. That doesn't mean that a secondary device or a smart pin can't succeed, but it needs to piggyback on the phone and then provide use cases that the phone does not address.",
        "published_at": "2024-08-07"
      },
      {
        "title": "The Worst Product I've Ever Reviewed... For Now",
        "url": "https://www.youtube.com/watch?v=TitZV6k8zfA",
        "snippet": "{ts:0} - All right, so this is the Humane AI Pin. It is a brand new product,\\n{ts:7} and a really, really\\ninteresting form factor of an ultra futuristic wearable computer. So in a time of all these\\ncrazy gadgets and Vision Pro,\\n{ts:17} and wearable glasses, it's so sick that we get so many genuinely new first\\ngeneration products like this\\n{ts:23} to give a shot. Unfortunately, it's also\\nthe new worst product I think I've ever reviewed,\\nin its current state.\\n{ts:31} There's just so many things bad about it. It's so bad, in fact, that I think it's actually\\nkind of distracting\\n{ts:39} to like understand what\\nthe point of the device is as we go through it. So I'm gonna have to separate\\nit out for this video.\\n{ts:44} First, I'm gonna tell you what it is, and what it's supposed to do, and then I'll tell you what my experience\\n{ts:53} has actually been using it. (mellow instrumental music) So this thing is a\\nsmall, wearable computer,\\n{ts:63} with an AI inside, that can help you throughout your day. It... all the time with you.\\n{ts:289} So, you can ask it things. It doesn't have a wake word, it only turns the mic on and\\nlistens when you touch it.\\n{ts:294} So you can go... (AI Pin beeps) How tall is the Empire State Building?\\n{ts:298} (AI Pin beeps) And then when you let go, it starts sending that\\nquery off to the crowd.\\n{ts:302} The- - [AI Pin] The Empire State Building is 1,454 feet tall to the tip.\\n{ts:308} - The Cloud. And then gets you an\\nanswer, which is great. And it also is multimodal.\\n{ts:312} So that means it can look at the camera, and see things, and interact\\nwith the world around you. So...\\n{ts:317} (AI Pin beeps) Look and tell me what you see. (AI Pin beeps)\\n{ts:321} So it'll scan the room,\\nuse the Cloud again. That little noise was it\\ntaking a little image, sending AI image to the Cloud,\\n{ts:328} analyzing it, getting it back, then deciding what to tell me. -... [AI Pin] You are sitting in front\\n{ts:333} of a camera and a laptop. The camera is on a tripod\\nand pointed at you. The laptop is open, and\\nyou are looking at it.\\n{ts:340} There are three pictures of\\ndogs on the wall behind you. There is a window to\\nthe left of the camera. There is a boom mic on\\nthe table in front of you.\\n{ts:347} There is a red carpet on the floor. - Great. The camera can also take pictures,\\n{ts:354} or up to 15 second videos, which it auto uploads while charging. It can also remember things\\nyou tell it to remember.\\n{ts:360} And all these things will\\nshow up in the Humane Center. So it's like this online web portal for all things connected to the pin.\\n{ts:367} There's no app, it's just the website. So there, you can see a whole\\nhistory of who you've called, and texted, and what you've listened to,\\n{ts:373} and what answers it gave to\\nyour most recent requests, and all the things you\\ntold it to remember. It is pretty well-rounded.\\n{ts:379} I think probably its best... tech demo feature though, is the translate back and forth. You got a two finger\\ngesture, you can go...\\n{ts:385} (AI Pin beeps) (Marques speaks in Spanish) (AI Pin beeps)\\n{ts:390} - [AI Pin] Where's the library? - So it auto detects the language,\\ntranslates it to English, and the person who speaks\\nback can translate back,\\n{ts:396} as long as you hold on the\\npin and listen to them. Pretty cool. This is all voice stuff though.\\n{ts:400} So if at any point you're in a loud area, or a very private area, and you don't wanna interact\\nout loud with your voice,\\n{ts:406} that's where this projector comes in. So it seems crazy, but\\nyou activate it like that, and then you just hold your\\nfinger out, your whole palm,\\n{ts:415} and it becomes a projector screen for the laser projector\\nbuilt into the pin. So it takes a little practice,... mentioning server timeouts, if you have a poor internet connection,\\n{ts:532} which happens to me all\\nthe time in this studio. So when they do most of the demos, like on their websites\\nand in their videos,\\n{ts:537} they'll ask a question,\\nand then they'll let go, and keep talking to fill the silence, so it's not awkward as\\nyou wait for an answer,\\n{ts:543} and realize how long it is. But even on this fast studio wifi here... (AI Pin beeps)\\n{ts:549} Who designed the Washington Monument? (AI Pin beeps) - [AI] Finding designer.\\n{ts:559} The Washington Monument was\\ndesigned by Robert Mills, a prominent 19th century\\nAmerican architect from South Carolina.\\n{ts:566} The construction was\\neventually completed by- - Okay. So you can just hold your hand up\\n{ts:571} to put your answer on your hand, and interrupt that it's talking so much. But even that was like a\\npretty good performance\\n{ts:578} for the AI Pin. In ideal, fast wifi conditions. But there are many, many times\\n{ts:584} when I feel like it... 's way slower, and it seems like it goes to the internet for almost everything.\\n{ts:589} I mean there's a few queries I guess might be local, like... (AI Pin beeps)\\n{ts:594} What time is it? (AI Pin beeps) - [AI Pin] 11:42 AM.\\n{ts:597} - Like that's pretty fast. If I ask the battery life, it can tell me that pretty fast.\\n{ts:600} But it feels like\\nbasically everything else is just shoveling it off to the Cloud, not computing on the device,\\nand it takes a while.\\n{ts:606} But it's also just wrong all the time. Like, I remember asking it\\ndays before the solar eclipse when the next eclipse\\nwas, and it said 2044.\\n{ts:615} I asked it, \\\"What's some\\ngood Asian food in the area?\\\" And over and over again it thought I said, \\\"What's the best ash?\\\"\\n{ts:622} For some reason? When is the next Nets game? (AI Pin beeps)\\n{ts:630} - [AI Pin] Finding next Nets game. The next Brooklyn Nets game\\nis on Sunday, April 14th, but no specific opponent... up and Google the answer in the time it takes me to get hopefully\\n{ts:1034} the right answer on the pin. It's just... Phones are OP.\\n{ts:1038} (AI Pin beeps) Look and tell me what this is. (AI Pin beeps)\\n{ts:1051} Or I'll just do this, I guess. Ah... It's a Cybertruck.\\n{ts:1057} - [AI Pin] The photo is of a Cybertruck. An electric pickup\\ntruck produced by Tesla. - Yup.\\n{ts:1065} Also, I gotta say, when\\nI say phones are OP, like screens in your hand. So sick.\\n{ts:1072} Just for the last like 10% of any UI, like you can get almost all the way there with just your voice interaction.\\n{ts:1078} But let's say you call an Uber, and you say, \\\"Take me to\\nthe studio from an Uber.\\\" Even if it could do that, which it can't,\\n{ts:1085} but let's say it could. And as you're waiting, you're like, \\\"I'm gonna just go grab a snack\\n{ts:1089} from this Starbucks on the corner.\\\"... {ts:1314} I've said a thousand times, like, my best ideas, golden rule, they always show up when\\nI can't write them down.\\n{ts:1321} Like when I'm about to fall asleep, or I'm in the shower, or driving, right? So I'm using the pin,\\n{ts:1328} I'm driving to the studio\\nand I have an idea. I'm not trying to write\\nit down on my phone while driving or pull over,\\n{ts:1335} but I had the pin, so\\nI'm driving and I just... (AI Pin beeps) \\\"Remind me of this cool ABC outro idea\\n{ts:1342} for the Humane review.\\\" (AI Pin beeps) And I just kept driving.\\n{ts:1346} And it wrote it down, and it saved it. - [AI Pin] Saving memory. - And when I go check the Humane-\\n{ts:1351} - [AI Pin] The outro idea\\nfor the Humane review has been saved. - The voice is kind of annoying.\\n{ts:1355} But now that's up in the Humane AI Center, so when I arrive at the studio, that thing that I told it to remember,",
        "published_at": "2024-04-14"
      },
      {
        "title": "I tested the Humane AI Pin - It's not good.",
        "url": "https://www.youtube.com/watch?v=0O2yTG3n1Vc",
        "snippet": "{ts:0} this is the Humane AI pin it's been blowing up the internet over the last\\n{ts:3} few months with the combined intelligence of sophisticated AI plus the entire internet all being brought to\\n{ts:8} you in a way that you can still be completely present in a moment and not bogged down by the hassle of working\\n{ts:13} around intrusive addictive phone applications and I just went Hands-On with it I spent about 4 hours using it\\n{ts:19} and talking to the CEO Iman and I don't think I've ever wanted to love a piece of technology so much and yet still be\\n{ts:27} unable to who's Mr who's the from YouTube finding YouTube video AR man also known as MOS is a popular YouTuber\\n{ts:41} with a focus on technology making him years old so here's how it works it Clips onto your clothing it stays there\\n{ts:49} on standby most of the time and then only when you decide that you want to engage with it do you place your finger\\n{ts:53} on this touchpad and you speak for example when do you think humans will settle on the moon humans are are\\n{ts:60} expected to return to the Moon in 2024 and have the first families on the Moon by 2084 okay so that... {ts:410} would you plan to pay it for the rest of your life probably not but at that point Humane is basically saying that your PIN\\n{ts:417} becomes a paperweight so fine it's very expensive but if its capability matches that then maybe it's justifiable well\\n{ts:425} what Imran the founder was saying to me is that the pin has the ability to run not just one but many of the top current\\n{ts:431} AI models so like GPT 4 for example which is a very powerful AI that does usually require its own paid\\n{ts:438} subscription for youus it has that on the go all the time which is definitely not to be sniffed at so one of the... {ts:445} things that he was saying he used it for is when he's driving his phone will be in his pocket his Focus will be on the\\n{ts:450} road but he has access to the entire internet of knowledge so he'll just decide I want to learn something about\\n{ts:456} sleep habits today for example and this pin can bring that knowledge in summarize it and speak it to you and\\n{ts:462} this is actually the first moment where I thought oh that's interesting when Risha my fiance does any kind of long\\n{ts:468} drive she often spends a good half an hour beforehand trying to find a good podcast to listen to during it and even\\n{ts:473} then they'll often Veer off topic or not be exactly what she was hoping for but this the world's information curated\\n{ts:480} exactly based on what you're asking to hear in any given moment well that could solve it plus the AI pin does understand\\n{ts:488} the flow of a conversation this isn't like old school Siri where you're just reintroducing the topic every single\\n{ts:493} time you bark a new command at it you can talk in a very human conversational way and it talks back so\\n{ts:501} my head started spinning with the possibilities this idea of a personal teacher wherever you want them but then... {ts:653} include fantastic marvelous talented tremendous and wonderful we'll go for Marvel\\n{ts:660} if human intonation and speed were the only issues though I'd be pretty happy to give Ain the benefit of the doubt\\n{ts:666} because longer term those are fixable things but I think the real problem with this product it it runs much deeper than\\n{ts:673} that for starters it hallucinates which has become this term to describe how AI can present false information as if it's\\n{ts:680} a fact so for example one of the advertised features is you hold a food in front of you and it tells you what is\\n{ts:685} in it like how much sugar or how many grams of protein but see when I asked it how many chicken nuggets there are in a\\n{ts:691} 20 chicken nugget share boox it said without a hint of caution the box contains fried chicken nuggets there are\\n{ts:698} 14 chicken nuggets in the Box interesting 14 well I think it's cuz it can only see\\n{ts:706} 14 yeah so how on Earth will you ever be able to trust a device's nutritional recommendations if it doesn't even know\\n{ts:713} how much of that food there is I mean I talked to Imran about this and he said well it... 's not a medical device and the\\n{ts:719} feature is kind of in beta and that's all fair enough but then what it is is an advertised feature either it needs to\\n{ts:725} get much much better very quickly which I don't think is going to happen because of the natural limitations of what this\\n{ts:731} thing can see or it needs to make you more aware of its limitations so that you know you shouldn't be taking what it\\n{ts:737} says at face value the idea in theory of let's say liking the look of this chair and for the PIN to be able to not just\\n{ts:743} tell you what it is but also save the answer to your notes is appealing but when you actually try and do that you\\n{ts:749} realize what the limitations of this form factor are like you can't see exactly what it's seeing so I asked this\\n{ts:755} exact question to it about the chair and it gave me a recommendation but then I later realized that the recommendation\\n{ts:760} it gave me was a different chair in the room and that's because when it gives you an answer you have no way of\\n{ts:766} affirming that it's the correct answer unlike when you do the same thing using Google lens on your phone where you can... {ts:771} make sure that you're capturing the right chair and then you can physically check that it has identified correctly\\n{ts:777} one thing that Imran talked about was the incoming AB to buy things using this but given that there's no real screen\\n{ts:783} here would you want to buy things on this like what if I meant to order two of something but the AI pin mishears me\\n{ts:789} and takes that as 20 what if it misunderstands the size or the color of what you're wanting and actually orders\\n{ts:794} an alternative variant there is so much that could go wrong that you'd really want to see an entire purchase page with\\n{ts:800} all the info and you can only do that on your phone but then also you have to talk to it because there is no physical\\n{ts:807} screen to type on your key input method has to default to speech and there are a lot of times I can think of where I\\n{ts:815} would not want to do that like what if you're in an art gallery or a library or more commonly for people a meeting what\\n{ts:821} if you're texting with your partner and you don't want to broadcast your intimate conversations any search... {ts:1129} my hands are definitely not free actually quite the opposite the laser does not re aim itself to wherever your\\n{ts:1134} hand is there is a specific spot where it fires you need to hold your hand there and you need to keep it as flat as\\n{ts:1140} possible your hand is basically your projector screen so the more creased you keep it the worse your picture quality\\n{ts:1145} is going to be I genuinely feel like doing this for 5 minutes is actually ironically much less comfortable than\\n{ts:1153} just holding your phone because you can hold your phone in any position you can support it on your lap or on a table and\\n{ts:1159} you can just keep moving it and yeah the Humane pin does have a surprising number of features considering there is no\\n{ts:1165} physical Hardware like being able to react to messages with emoji but then at that point where you're holding your\\n{ts:1171} hand out you're scrolling around and you're tapping multiple times surely there comes a point where it will\\n{ts:1176} actually just be faster to take your phone out and do it there and that brings me on to the gestures you know... {ts:1180} things like rolling your hand around I totally believe that they are things that you will get used to like I don't\\n{ts:1185} think it's fair to say that they're just not good after having used them once and also I totally get that you're not going\\n{ts:1190} to be using your hand screen as much as you would be using your phone screen but what you can't deny is that the total\\n{ts:1197} amount of effort required to per perform any given action is just higher with the pin like if you think about what it\\n{ts:1202} takes to hover over something with your phone is this if you think about what it takes to hover over something on the\\n{ts:1207} Humane pin it's this if you think about what it takes to click something it's that if you think about what it takes to\\n{ts:1213} click something over here it's that if you think about what it takes to go home one swipe if you think about what it\\n{ts:1219} takes to go home it's a full clench now why do I keep comparing it to the phone anyways we've already established that\\n{ts:1225} it's designed to be a separate device that isn",
        "published_at": "2024-04-11"
      },
      {
        "title": "Will it Hold? UX Designer Reviews Humane's AI Pin - Infinum",
        "url": "https://infinum.com/blog/ai-pin-ux-design-review/",
        "snippet": "**Presented as a fully screenless standalone device, the much-awaited AI Pin promises to revolutionize the way we interact with personal technology. Our UX designer reviews what we know so far.**\\n\\nLast November, the San Francisco startup founded by former Apple designers, Humane, introduced the AI Pin, a wearable device that acts as a mobile virtual assistant. The square device magnetically clips to your clothing or other surfaces and activates with a tap and voice command, or by displaying a laser ink display on your palm.\\n\\nHumane\u2019s AI Pin, scheduled for shipping in March, is pitched as a smartphone replacement and your daily assistant. It promises to seamlessly integrate itself into your life and help you get through the day while requiring no screen time consumption.\\n\\nHaving a virtual AI assistant that knows just what you need sounds appealing, but is the no-screen idea really feasible? What will the experience of using this completely new type of gadget be like in real life? In this article, we examine what we know about the AI Pin so far from a UX designer\u2019s perspective.\\n\\n## The AI Pin at a glance\\n\\nUnlike a smartphone, the AI Pin doesn\u2019t have apps. Instead, it offers \u201cAI experiences\u201d through different models activated at the user\u2019s request. The OS identifies what you need and picks the right tool for the job \u2013 it has access to language models from Microsoft and OpenAI, while AI-driven music experiences are powered by Tidal.\\n\\nThe device, priced at $699 with an additional monthly subscription of $24, runs on a Snapdragon processor with a dedicated Qualcomm AI Engine. It uses a Humane-branded version of T-Mobile\u2019s network and comes with an unlimited talk, text, and data plan, which truly makes it a standalone device. However, this also means you won\u2019t be able to take a call from your smartphone on it, like you could on a smartwatch.\\n\\nSome key features of the AI Pin include:\\n\\n- Web search, phone calls, and messaging\\n\\n- Email summary: summarizes your inbox, prioritizing important information\\n\\n- Laser ink display: projects information and a simple interface onto your palm\\n\\n- \u201cInterpreter\u201d feature: translates conversations in real-time, maintaining your intonation\\n\\n- Camera and image recognition: useful for various purposes, including keeping track of nutrition, and a shopping assistant in the future\\n\\n- Swappable battery: ensures 24/7 usage without the need for recharging\\n\\n- Privacy: no wake word or always-on listening. Activated by a tap and equipped with a \u201ctrust light\u201d indicating data collection... ## What sets the AI Pin apart?\\n\\nHumane\u2019s AI Pin is a new kind of wearable device that introduces artificial intelligence into everyday life. It works as your personal AI assistant, offering features unavailable through standalone apps or assistants like Siri. This assistant interacts smoothly with core system functions, such as contacts, emails, and calendars. It learns from every piece of information you feed it, from birthdays to favorite meals, delivering a personalized approach.\\n\\nThe AI Pin\u2019s set of features makes it a truly unique piece of technology in the existing smart device market. However, some of these features are already present in smartphones and smartwatches, and it wouldn\u2019t be surprising if some of its more advanced features find their way to these devices in the future.\\n\\nSmartphones and smartwatches already sync well with system functions and adapt to user preferences. As they evolve, the gap between these devices and AI Pin\u2019s functionalities could narrow. Still, the AI Pin\u2019s offering of an intuitive, personalized device stands out. Its UI emerges only when necessary, allowing you to fully immerse in new experiences or meaningful interactions without distractions.... ### Reshaping device interaction\\n\\nFrom a UX standpoint, interacting with the AI Pin can bring some challenges. The users will need to use their voice but also learn a new set of gestures.\\n\\nTo start with, voice communication with personal devices can feel awkward in public spaces or workplaces. It risks exposing private information and defying social norms. Additionally, voice recognition and AI response can be imperfect, requiring reiteration or prompt adjustments, something we find ourselves doing daily with chat-based AI models.\\n\\nThe other way of interacting with the Pin is by using gestures on the laser ink display on your palm. The display is activated by lifting and tilting your hand, and then you use gestures such as tilting and rolling your hand to browse songs or closing your fingers to make a selection. Closing your hand returns you to the homepage.\\n\\nSome may argue that gestures are a natural way of interaction, but the issue is that the industry hasn\u2019t reached a standard yet. For instance, pausing a song on the AI Pin involves a thumb-to-finger join, while a smartwatch might require a double tap.\\n\\nThis inconsistency creates a learning curve for the users, who may struggle to get the gesture right and navigate through the projection.\\n\\n**While the laser display itself looks impressive, there are concerns about how it will perform outdoors or other brightly lit conditions. This is an issue even smartphones and watches struggle with.**\\n\\nWith a laser projection, users might find themselves unable to read the display in bright sunlight.\\n\\nAnother potential issue is the curved and textured surface of the palm. An image can become distorted when projected onto a curved surface because parts of it can end up at a different distance from the projector. The parts further away from the projector can also exhibit some blurriness. The palm\u2019s texture can also affect the clarity of the projection \u2013 lines and patterns in the skin can compete with the image, hindering a clear view.\\n\\nFinally, there is also the issue of fitting information on a small surface. Users might find it difficult to find the information they need since it can only be displayed in small bits. This often leads to displaying less context, and the users might become tempted to switch to a device with a screen to get a full understanding, especially in noisy or social environments where they can\u2019t rely on voice alone.... ## Should we really go screenless?\\n\\nHumane\u2019s positioning of the Pin as a standalone device with the aim of replacing the smartphone is an intriguing concept, but unlikely to work for many people. The voice and laser projection alone have a lot of limitations \u2013 first of all, physical ones such as noisy environments and bright light. Then there are social and privacy concerns, from slight awkwardness to others overhearing your sensitive information.\\n\\nFrom a productivity perspective, performing some tasks using your voice may be much slower than using a screen, especially if you want to correct errors or you need to repeat commands. It is also important to stay aware that AI can \u201challucinate\u201d, misinterpreting or fabricating elements in its response. Verifying the accuracy of AI-produced information is easier on a device with a screen.\\n\\n**We should remember that visual media isn\u2019t just for entertainment or distraction. It\u2019s a critical communication tool and often key for executing daily tasks. Imagine trying to understand a complex infographic or a detailed picture via a voice description alone.**\\n\\nWhile the charm of a screenless future is compelling, we need a balanced approach. Letting go screens completely might not be practical or even desirable. Excessive screen time can be tackled without removing the screen entirely through ethical design choices, and the AI Pin can work alongside smartphones rather than replacing them.\\n\\nThere are a number of situations where this type of device could come in very handy. Consider cooking or working in sterile environments like hospitals \u2013 hands-free use would be of great help. The same goes for enhancing safety while performing complex tasks like driving or working in dangerous conditions. The AI Pin could also serve as a personal language tutor, and for those with visual impairments, it could be a game-changer.\\n\\nEssentially, the AI Pin could fill in the gaps, the use cases where a smartphone isn\u2019t the most efficient option, by offering a more convenient and accessible way to access information and control technology.\\n\\nSo far, it\u2019s uncertain whether Humane plans to offer options for connecting the AI Pin with other smart devices and what functional and privacy concerns that would raise. But its chances for successful adoption are far higher in collaboration with touchscreen devices rather than striving to become their replacement.... ## A glimpse into the future of personal technology\\n\\nHaving reviewed the information available to this point, we don\u2019t believe the AI Pin is going to replace smartphones. However, it opens new ways for us to engage with the digital world. Utilizing the technological advancements offered by AI, it builds a vision of a device that assists you but at the same time doesn\u2019t distract you from living your off-screen life.\\n\\nWhen designing products inspired by emerging technologies, sometimes the eagerness to utilize these new possibilities might overshadow our focus on user-centric design. That kind of approach risks creating solutions in search of problems rather than addressing genuine user needs.\\n\\nWe have yet to see how users will respond to the AI Pin, and we look forward to seeing what other companies will contribute to this evolving field.",
        "published_at": "2025-07-31"
      },
      {
        "title": "Apple Intelligence Foundation Language Models Tech Report 2025",
        "url": "https://machinelearning.apple.com/research/apple-foundation-models-tech-report-2025",
        "snippet": "We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: (i) a \u223c3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and (ii) a scalable server model built on a novel Parallel-Track Mixture-of-Experts (PT-MoE) transformer that combines track parallelism, mixture-of-experts sparse computation, and interleaved global\u2013local attention to deliver high quality with competitive cost on Apple's Private Cloud Compute platform. Both models are trained on large-scale multilingual and multimodal datasets sourced via responsible web crawling, licensed corpora, and high-quality synthetic data, then further refined with supervised fine-tuning and reinforcement learning on a new asynchronous platform. The resulting models support several additional languages while understanding images and executing tool calls. In public benchmarks and human evaluations, both the server model and the on-device model match or surpass comparably sized open baselines.\\nA new Swift-centric Foundation Models framework exposes guided generation, constrained tool calling, and LoRA adapter fine-tuning, allowing developers to integrate these capabilities with a few lines of code. The latest advancements in Apple Intelligence models are grounded in our Responsible AI approach with safeguards like content filtering and locale-specific evaluation, as well as our commitment to protecting our users' privacy with innovations like Private Cloud Compute.\\nThis paper provides technical details for Updates to Apple's On-Device and Server Foundation Language Models, introduced on June 9, 2025, in this post.",
        "published_at": "2025-07-17"
      },
      {
        "title": "Are Apple Intelligence features still inoperable?",
        "url": "https://discussions.apple.com/thread/255921154",
        "snippet": "Are Apple Intelligence features still ino\u2026 - Apple Community\\n\\n\udbc0\udc8e Go back to my question\\n\\nApple Intelligence\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points... # Are Apple Intelligence features still inoperable?\\n\\nWhen attempting to use Apple Intelligence services on my MacBook Pro M4 with MacOS Sequoia 15.2, I am unable to summarize emails (promotional, plain text, etc.) and receive an error that Apple is \\\"Unable to summarize this message.\\\" Websites in Safari similarly generate an error.\\n\\nWhen I enter my OpenAI ChatGPT Plus credentials, Apple is also unable to tap that service. OpenAI customer service believes \\\"the issue is related to the Apple OS system.\\\" They had me generate a Sysdiagnose file and provided a URL to submit it to Apple's Engineering team.\\n\\nAm I missing something really simple here when trying to use the Apple Intelligence tools? Or are these prevalent problems for all Mac users?\\n\\nMacBook Pro 14\u2033\\n\\nPosted on Jan 8, 2025 6:30 PM\\n\\nMe too (5)\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 16, 2025 9:49 AM in response to jsurdyk\\n\\nUpdate #2: Apple Support still unable to resolve the issue for me. I have reinstalled the MacOS without avail. Apple says it will continue investigating as it has no explanation yet for the (1) AI services not working or (2) the error reporting tools in the apps not working.... Still hoping...\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 9, 2025 10:39 AM in response to lkrupp\\n\\nUpdate: Apple Support was unable to resolve the issue for me and discovered in the process that feedback on Apple AI (Use Report a Concern to share feedback about Apple Intelligence - Apple Support ) isn't working across my apps either (e.g. mail, Notes, Pages, etc.). Apple Engineering is now investigating. If I learn of a fix, I'll share the remedy here for others who may have experienced the same problem I am encountering.\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nMar 2, 2025 7:46 AM in response to jsurdyk\\n\\nUpdate #3: Apple AI services still unavailable in updated MacOS 15.3.1. VPN removed, issues persisted. Error reporting still unavailable. ChatGPT Plus account integration also not working. No response from Apple Engineering yet. Will update again if any more OS updates and/or Apple Engineering guidance.\\n\\n[Edited by Moderator]\\n\\nlobsterghost1\\nCommunity+ 2025\\n\\nLevel 10\\n177,077 points\\n\\nJan 16, 2025 6:00 PM in response to jsurdyk\\n\\nA US purchased Mac with an M chip shouldn't have an issue downloading and running Apple Intelligence. I have seen where some people with Macs resolved this by turning off Private Browsing. Do you have that enabled? Do you use a VPN on your Mac? If you do, turn it off or even delete the VPN profile completely. Personally, I wouldn't use one on my MacBook Pro.... jsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 17, 2025 11:21 AM in response to lobsterghost1\\n\\nThanks for helping me dig deeper.\\n\\nI'm not using Private Browsing. I do have a Palo Alto Networks VPN. The failure of Apple AI and error reporting persist with it on or off. I can't really remove it since I need it for work: campus resources like library databases, servers at the university, and so on are not accessible without a VPN.\\n\\nIf VPN software is the issue, that's a significant fail. The student and instructional labor market in higher ed in the US alone is probably close to 1 million users (my university alone is likely ~ 45,000 users at the 50% Apple adoption rate). Add corporate (or cautious) people who use VPNs, and that seems like a massive oversight for a company with tremendous resources (and hardware margins) like Apple.\\n\\nI hope to get another update from Apple Engineering next week. I'll report back if they discover anything!\\n\\nlobsterghost1\\nCommunity+ 2025\\n\\nLevel 10\\n177,077 points\\n\\nJan 17, 2025 11:33 AM in response to jsurdyk\\n\\nI don't know if the VPN is the issue, but often they cause unintended consequences and Apple Intelligence could be one of those. Given that your school requires one, I'd reach out to the system admins at your school to see if they can help you. Apple working on one side, your school tech folks working on the other and somewhere in the middle someone will be able to fix your issue.... lkrupp\\n\\nLevel 7\\n21,463 points\\n\\nJan 8, 2025 7:15 PM in response to jsurdyk\\n\\n\\\"Or are these prevalent problems for all Mac users?\\\"\\n\\nNope, all is well for everyone else. So have you properly set up and enabled Apple Intelligence?\\n\\nHow to get Apple Intelligence - Apple Support\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 9, 2025 6:41 AM in response to lkrupp\\n\\nI hadn't seen much reporting on the broad failure of the Apple Intelligence features, so I was hesitant to post. My settings are below, and you can see examples of the errors I receive in Apple Mail and Apple Notes. The laptop is shutdown and restarted every day. Other than this feature being a complete fail, it works as expected in office, remote, and home locations. Nothing else seems affected.\\n\\nAny ideas on a next step welcome!\\n\\nSETTINGS\\n\\nEMAIL\\n\\nNOTES (using text from public LinkedIn post)\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 20, 2025 6:41 AM in response to lobsterghost1\\n\\nGood point: it may be helpful to have both sides working in parallel. The IT folks in my school haven't encountered any issues like mine with other faculty and staff who bought Macs recently, but I can certainly flag it for the campus level tech in case it's a rare issue (e.g. affects only me in my school but occurs more frequently elsewhere in the other 25 schools and colleges on our campus). More to come after any updates from either Apple Engineering or my campus. :)... jsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nMar 19, 2025 12:54 PM in response to jsurdyk\\n\\nUpdate #4. My colleagues on campus have identified the cause of the Apple Intelligence services not working! It appears to be linked to the use Cisco Secure Endpoint to manage my laptop. Removing limits on the device in Cisco's software enabled all of the features to work normally. Campus IT is investigating how to secure devices but also permit use of Apple Intelligence services.\\n\\nlobsterghost1\\nCommunity+ 2025\\n\\nLevel 10\\n177,077 points\\n\\nJan 16, 2025 3:24 PM in response to jsurdyk\\n\\nJust out of curiosity, where was your Mac purchased?\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 16, 2025 5:05 PM in response to lobsterghost1\\n\\nPurchased from Apple's online education store.\\n\\nlobsterghost1\\nCommunity+ 2025\\n\\nLevel 10\\n177,077 points\\n\\nJan 16, 2025 5:13 PM in response to jsurdyk\\n\\njsurdyk wrote:Purchased from Apple's online education store.\\nIn the US?\\n\\njsurdyk Author\\n\\nLevel 1\\n6 points\\n\\nJan 16, 2025 5:38 PM in response to lobsterghost1\\n\\nYes :)\\n\\nlobsterghost1\\nCommunity+ 2025\\n\\nLevel 10\\n177,077 points\\n\\nJan 20, 2025 6:52 AM in response to jsurdyk\\n\\nSomeone will figure this out for you! Good luck and hope it gets resolved, sooner than later.\\n\\nThis thread has been closed by the system or the community team.\\nYou may vote for any posts you find helpful, or search the Community for additional answers.... ## common.ce.dialogHeader\\n\\ncreatePost.popup.addVideo.url\\n\\nLorem ipsum dolor sit amet consectetur.\\n\\ncommon.ce.videoInputPlaceholder\\n\\ncreatePost.popup.addLink.text\\n\\nLorem ipsum dolor sit amet consectetur.\\n\\ncreatePost.popup.addLink.url\\n\\nLorem ipsum dolor sit amet consectetur.\\n\\ncommon.ce.dialogTitle\\n\\nLorem ipsum dolor sit amet consectetur.\\n\\ncommon.ce.dialogBodyPlaceholder\\n\\nLorem ipsum dolor sit amet consectetur.\\n\\ncommon.ce.dialogSave common.ce.dialogCancel",
        "published_at": "2025-01-08"
      },
      {
        "title": "Ep 567: Apple's AI Challenges - What Went Wrong with Siri?",
        "url": "https://www.youreverydayai.com/apples-ai-challenges-what-went-wrong-with-siri/",
        "snippet": "**The Cost of Catching Up**\\n\\nTalks with Anthropic and OpenAI underscore a potential reliance on third-party tech to rejuvenate Apple's AI functionalities. However, these negotiations are accompanied by soaring costs, reportedly requiring multibillion-dollar investments. This poses financial pressures and a need for parallel discussions with multiple vendors, emphasizing Apple's urgency to remain competitive in the AI space.\\n\\n**The Echo of Innovation Lost**\\n\\nThere's a stark juxtaposition between Apple\u2019s current AI endeavors and its competitors. Companies like Google and Microsoft continue to pioneer in the AI field, while Apple seemingly struggles to catch up. The consequence? A likely diminished position in an arena where they once stood as innovators.\\n\\n**The Road Ahead**\\n\\nApple's decisions signal a shift that may ripple through its future growth. The reliance on external AI capabilities raises questions about its innovation capacity and strategic vision. Without significant in-house developments, Apple risks losing ground to competitors firmly embedding AI as a core competency.\\n\\nAs Apple navigates this critical juncture, its ability to adapt and integrate externally developed AI solutions will be pivotal. This evolution might define the company\u2019s future standing in a tech landscape increasingly dominated by AI advancements.\\n\\n**Topics Covered in This Episode:**\\n\\n- Apple's Generative AI Struggles Analyzed\\n\\n- Bloomberg Report on Apple's AI Plans\\n\\n- Apple's AI Strategy Shift with Competitors\\n\\n- Siri Development Challenges & Delays\\n\\n- Apple's AI Failures & Class Action Lawsuits\\n\\n- Future of Apple's AI Innovation Discussed\\n\\n- Anthropic & OpenAI's Role in Apple's AI\\n\\n- Apple's AI Outsourcing Strategic Impact... Jordan Wilson [00:04:32]:\\n\\nSo let's just go straight to hot take y'all. Apple has reportedly spent millions with an s, millions of dollars a day trying to build their own generative AI systems in large language models. And they've failed to produce literally anything meaningful unless by meaningful, you know, combining two different gen emojis, using Apple's AI is, meaningful to you. Aside from multiple class action lawsuits, Apple has not produced a single useful thing. Yeah. Class action lawsuits aren't useful. It was just a joke there. But it's so bad.\\n\\nJordan Wilson [00:05:14]:\\n\\nIt is so bad. Apple's AI efforts are so bad. They actually put out what I, said was marketing disguise as research, saying that large language models essentially stick. Right? And that these new reasoning models that Apple has been unable to develop internally, well, they're not actually that good. Right? So, yeah, if you actually want that hot take from a couple of weeks ago, go listen to episode five forty three, which is Apple's weaponized research insights its illusion of thinking paper. Yeah. Literally, things have gotten so bad at Apple that they are putting out pretty bad research that immediately got debunked, by the scientific AI community. That's how bad it was.... Just like how when they, kind of rolled out their, certain aspects of their smarter Siri one point o, essentially, it kicks most queries to ChatGPT. It's like, yeah, you're gonna have to use ChatGPT for that. Right? So this potential deal would sideline Apple's own in house AI models completely. So it's not like they would, according to reports, be using a hybrid like they're kind of using now. Right? Right now, their own on device AI is handling some Siri queries, but most of them are just getting kicked to ChatGPT. So this was essentially a a stall tactic of more than a year, with this OpenAI partnership where, you know, essentially, we still have the same dumb non AI Siri, and it just kicks, most requests to, ChatGPT. But it it can't take advantage right now of of any of the information on your phone. You can't ask it.\\n\\nJordan Wilson [00:11:40]:\\n\\nYou know? Hey. You know? What did this person text me? You know, what's in my email? Right? It's funny. Actually, perplexity rolled out an iOS assistant that is better than Siri. Right? And, one thing that Apple kind of did to their credit, but I guess was also tipping their hat at where they were going as they opened up their on device or their edge AI, their small language model to third party developers, which I guess was another nod at saying, yeah. We really can't figure this all out internally. So let's, open up the reins after a year of keeping this in house and allowing third party developers to use essentially the, the AI that is on, Apple's iPhones. Right? So the AI capabilities. Right? So they have small language models, but for a year, they didn't open that up to anyone else.... Jordan Wilson [00:12:31]:\\n\\nSo this is just the latest, kind of departure, from Apple's legendary vertical integration strategy. It's not even there. Right? This is not the Apple that most of us have, known over the past, you know, decade or so. So let's dig in a little bit more on, what Apple's kind of desperation, you know, kind of the desperation level internally at Apple according to this report, from Bloomberg. So Mark Gurman revealed that Apple is requesting custom AI models from competitors. So they're like, yeah. Can you just kinda make this for us? It's not like they're like, hey. We're just gonna use this model you already have, and we're gonna go ahead and, you know, fine tune it or, you you know, work on it our ourselves.\\n\\nJordan Wilson [00:13:19]:\\n\\nThey're like, no. Can you just, like, make us something for us? Right, which obviously Apple would do any company that size, but it's it's it's telling, right, that they're not even able to just, you know, work with one of the, current models. Anthropics Claude has emerged as a leading candidate after some internal testing, but there are some pricing disputes more on that here in a minute. And Apple has demanded that models run on their infrastructure to preserve their privacy narrative. So, one thing Apple has, gotten right over the years is putting privacy first. And when it comes to AI, that is obviously of an utmost concern is, you know, what happens with all of my personal data that may be living, on my iPhone. So, you know, this could be another thing that causes even more delays. So like I said, the LLM Siri or sometimes people say the AI Siri or Siri two point o.... Jordan Wilson [00:16:11]:\\n\\nHalf baked pancakes, low key really good. Right? So even calling it half baked toy, I think might be giving, apple and Siri a little bit too much credit. So here's where it gets interesting. So it seemed like according to the report, if you're reading between the lines and we're gonna be, sharing that report in today's, newsletter, if you do wanna read it. So, it seemed like Anthropic was kind of a preferred, vendor for this maybe over OpenAI, which I found interesting. But again, that was me inferring and reading a little bit between the lines. And again, this is according to, unnamed sources. But again, this Bloomberg reporter is is stellar in his reporting.\\n\\nJordan Wilson [00:16:57]:\\n\\nBut it says that Apple is facing unprecedented cost for external dependency on their core feature. And the financial pressures right now are forcing, parallel backup negotiations with OpenAI. Because right now, it seems like Infropic and Apple are kind of might not be able to come to a, an agreement on pricing. Because right now, Infropic is reportedly saying that this would require a multibillion dollar yearly investment from Apple, and it would go up exponentially year over year. So, you know, reportedly, Anthropics is like, yo, this is gonna cost you many, many billions of dollars, and it's gonna get very expensive. Apple reportedly didn't like that, so they're also talking with OpenAI. So we'll see what actually happens here. And it also is worth noting that Anthropic does have a similar, kind of deal with Amazon Alexa.... Jordan Wilson [00:33:53]:\\n\\nSo the verdict, this is the latest Apple AI crisis, and I'm putting my stamp on this one. This proves Apple's innovation era is over. Alright. This company has transformed transformed, right? When Siri first came out, it it it was a very impressive piece of artificial intelligence. It's barely improved in the decade or so. It's been out. Right? And now because of their constant AI failures, they're forced to make their competitors richer and not get the valuable data that you would get by putting your own models out there for hundreds of millions or in Apple's cases, billions of users. Right? There's billions of Apple devices out there.\\n\\nJordan Wilson [00:34:46]:\\n\\nThat's another thing you can't overlook. Apple is not gonna have well, I mean, we'll see what what what the actual, arrangements are, but, presumably, they're not gonna have as much data as they would if they had their own large language models out there. That's why, like, AI success has all has been about users. Right? Which is why some companies like OpenAI, I think, are fine with losing money because they're gaining the valuable data, which helps them make more, more and better models. And I think the cultural and technical failures expose that Apple is officially cooked on generative AI. All right. You heard it here first. Y'all hot take Tuesday.",
        "published_at": "2025-07-15"
      },
      {
        "title": "New report about Apple's 10 main challenges ignores two main factors",
        "url": "https://appleinsider.com/articles/25/06/12/new-report-about-apples-10-main-challenges-ignores-two-main-factors",
        "snippet": "A new report breaks down issues from Apple Intelligence to tariffs, and says the problems are insurmountable. Why the report ignores the solutions Apple has always used effectively, we have no idea. Apple Park -- image credit: Apple Apple most certainly faces problems with Trump's tariffs and how they change at whim-speed, it definitely has foes including the European Commission, and at least some unhappy developers. A new report from Bloomberg claims that the company is currently facing ten major issues, and that there are no clear steps the company can take to address them. We're not going to delve into them too far, as we've already covered them ad infinitum. So has mainstream media, social networks, and that old lady that hangs out near that coffee shop down the street from you. What we will do, though, is give you a bullet list of what the report details. Apple is behind on Artificial Intelligence There is no Next Big Thing Apple Vision Pro is too expensive Google Search deal may end App Store changes and developer relations Global regulations and governmental scrutiny Tariffs and having to reshore manufacturing Tim Cook and most executives are at retirement age China sales are down iPhone users are not upgrading as quickly The numbering is Bloomberg's and there is no apparent reasoning behind the sequence. The ten can also be grouped into products, legal, and operational issues. None of these are new, and almost all of them have existed for years and years. Apple remains not doomed. Apple... 's product problems are evergreen The report stresses that iPhone sales are down in China, and that even in the US, there hasn't been the expected rush to upgrade to new models. The iPhone 16 range has not sparked a super-cycle, even if some users claim they only upgraded to get Apple Intelligence. This is all true, and right now there is no instant solution. But there's instant, and there's waiting three months -- even Bloomberg acknowledges that the next iPhone launch could change this. Similarly, the next Apple Vision Pro could help. There have been assorted rumors about a lower cost version to attract new buyers, and more Apple Glass spectacles-like headsets to combat Meta's products. Either or both could be true, and either or both would presumably help boost sales. What's also true, though, is that either or both will take time -- and that's where Apple has a strength few other firms do. Apple's not so secret weapon Apple can afford to wait out anything and anyone. It is consistently looking to the long game, and normally that plays out in the same way every time. It starts with Apple being accused of being late to some technology, then Apple comes along and upends the whole industry. It continues with Apple being accused of charging too much for its products, but it keeps on doing that and so far people keep buying. Apple will bring out a lower cost Apple Vision Pro and it will perhaps produce a range of different models. Then equally, while it is frustrating that Siri is currently worsening, you know Apple will get it and Apple Intelligence working. Once it has, other AI firms will copy it, and pundits will move on to claiming Apple is behind on something else. It... 's easy to see that Apple has the money to out wait its rivals, but the reason it got that money is that it has always done exactly this. While rivals announce early, Apple -- usually -- does not. Instead of throwing technology at the wall and hoping enough buyers figure out a use for it, Apple looks at that use case first. It designs products and services to meet a need it believes it has identified. Most of the time, so far, Apple has been right. But like always, like it was under Steve Jobs and like it is now under Tim Cook, there will be more missteps, and there will be other firms who get it right faster than Apple. Apple planned for Tim Cook to succeed Steve Jobs, it just didn't announce it. Image credit: Apple But right now, Apple is taking these knocks for what it hasn't released yet, and despite some questions over its handling of Apple Intelligence, it's as ever looking beyond the immediate future. Tim Cook's successor It's not as if Apple only looks to the future with its plans for the iPhone. The report's point that CEO Tim Cook will be 65 this year -- his birthday is November 1 -- is of course correct. So is the point that several of the senior executives are nearing retirement age, although some like Craig Federighi are only around 56. In all likelihood, Apple has already chosen Tim Cook... 's successor, given that the guy said that he wanted one more major project launch before he retired. There isn't a possibility that the entire succession operation for him and any other senior staff has not only been planned, but is currently underway. While that should be expected of any corporation and really any business, in this case it is another example of how Apple does things rather talking about them. Right back when Steve Jobs was ill, Apple was being lambasted for not having a succession plan -- and of course it did.",
        "published_at": "2025-06-12"
      },
      {
        "title": "The Agony and Ecstasy of Reviewing Humane's Ai Pin",
        "url": "https://www.inverse.com/tech/humane-ai-pin-in-depth-review",
        "snippet": "# Humane\u2019s Ai Pin Isn't Ready to Replace Your Phone, But One Day It Might\\n\\nThe Ai Pin is an ambitious device and blueprint for the future of mobile computing, but first-gen compromises keep it grounded in the present.\\n\\nMurphy\u2019s law states that \u201canything that can go wrong will go wrong.\u201d That pretty much sums up my first three days with Humane\u2019s Ai Pin.\\n\\nMusic from Tidal wouldn\u2019t stream. High-res versions of the photos I took and regular videos recorded with the Ai Pin wouldn\u2019t upload to my connected \u201cHumane.Center\u201d cloud portal. And the multi-modal artificial intelligence voice assistant that you engage with to answer your questions or remember \u201cnotes\u201d that you tell it, like a \u201csecond brain,\u201d felt brain-dead half the time, failing to answer questions it previously got correct.\\n\\nNot great for a product that is supposed to showcase how AI could make mobile computing even more personal, more ambient, and less disruptive than the smartphones and addictive apps we\u2019ve come to rely on.\\n\\nAfter many emails trying to troubleshoot all of the issues with my Ai Pin review unit, Humane co-founder and CEO Bethany Bongiorno invited me to the company\u2019s New York City office a second time to get a replacement. I left with two Ai Pins to test, but it turned out a factory reset was all that was needed to resolve the problems on my review unit.... Smartphones changed all of that, and now, companies like Humane and Rabbit claim AI is going to shift mobile computing from being app-based (where you input, tap, scroll, and swipe on things to get stuff done) to straight-up delivering info and doing a task for you. Bongiorno says AI is a faster \u2014 if not necessarily better \u2014 way to compute instead of poking at a smartphone display or an even tinier smartwatch screen. She and Chaudhri hired a lot of former Apple employees, including Ken Kocienda (aka the guy who invented the original iPhone\u2019s autocorrect keyboard), and they all seem to believe a head-worn computer like the Apple Vision Pro isn\u2019t the future they want to create and foist onto the next generations.\\n\\nThere is some irony in buying a $699 device with phone-like capabilities and paying $24 for a monthly Humane subscription plan with the goal of using your phone less.\\n\\nSpeed is essential for AI-powered experiences to resonate with consumers, and that\u2019s also the Ai Pin\u2019s biggest compromise. At launch, the Ai Pin\u2019s whole \u201cCosmos\u201d operating system and AI stack, comprised of the voice-based AI assistant and the Laser Ink Display projector, is slow to answer even basic questions. Tapping the touchpad with a single finger and then speaking to, or asking a question to the Ai Mic is easy after you learn the gesture controls, but it\u2019s the time spent waiting for the AI to respond that often frustrated me. Compared to Alexa, Google Assistant, and yes, even Siri, getting an answer to certain basic questions like \u201cWhat\u2019s the weather?\u201d using the Ai Pin can take as long as six seconds. That may not seem like a long wait, but when the other assistants can answer almost immediately, the Ai Pin feels like a turtle crawling while the hares race by, leaving a trail of dust.... When the Ai Pin isn\u2019t testing my patience with answer wait times, the AI often is confused or forgetful. For example, I asked the AI: \u201cWhat was the last article that Raymond Wong at\\n\\n*Inverse* wrote?\u201d Sometimes, it gave me the correct answer: \u201cThe last article written by Raymond Wong for *Inverse* was 'Spatial Personas Make Apple Vision Pro a Less Isolating...' published 7 days ago.\u201d Other times, when asked at a later time or another day, it simply doesn\u2019t know or remember that it correctly answered the question before. It answered back: \u201cThe latest article by Ray Wong at *Inverse* is not available in the provided search results\u201d and \u201cThere is no information available about the latest article by Ray Wong at *Inverse*. Is there anything else you'd like to know?\u201d\\n\\nThere\u2019s a reason why Humane uses a lowercase \u201ci\u201d to write AI in Ai Pin. \u201cTo signify we\u2019re in the early days of artificial intelligence,\u201d Bongiorno tells me. Clearly, the AI in the Ai Pin still has a ways to go.... The Ai Pin\u2019s AI isn\u2019t always missing \u2014 when it hits, it feels like a revelatory moment. The \u201cmagic\u201d of AI versus Alexa/Google Assistant/Siri is that you don\u2019t need to speak like a robot for it to understand what you\u2019re saying. You can also ask follow-up questions because AI is contextual and knows what you said earlier. This natural language processing (NLP) is what everyone is holding up as the next way to interact with computers. Just talk to it like you would to another human. Instead of saying to the Ai Pin, \u201cPlay the song \u2018Thunderstruck\u2019 by AC/DC\u201d you could say, \u201cPlay me a kickass anthem to get this party started.\u201d In theory, the Ai Pin\u2019s should be able to do that every time when asked, and the AI has successfully played that song for me when asked to set the vibe, but it can also fail as well. Bongiorno tells me a range of reasons, from server-side bugs at Humane or Tidal (the only music streaming service Ai Pin supports at launch) to even a poor wireless signal (either over LTE or Wi-Fi) can cause the AI to give bad answers or none at all. Throughout the majority of my week of testing, Humane said it had addressed several bugs that caused the AI to perform at less than optimal intelligence and responsiveness. The built-in speaker is by no means the best quality, and it does sound tinny at louder volume levels, but it\u2019s convenient walking in the park and getting ambient music at ear level without holding up my phone. You can also connect Bluetooth earbuds for private listening at any time.... When I kept badgering the AI, it caved and told me it had simulated the scene:\\n\\nThe information provided earlier was based on a simulated scene analysis and not actual visual observation. If there's anything else you'd like to know or discuss, feel free to ask.\\n\\nIf I were a person with a visual impairment, I wouldn\u2019t be able to rely on the Vision feature to accurately describe a scene. Clearly, Vision is labeled a beta feature for a reason.\\n\\nNearly 3,000 words into this review, you\u2019re probably wondering why I\u2019m just now getting to what it\u2019s like operating the Ai Pin \u2014 using its touchpad with one and two-finger taps, double-taps, tap and holds, and using hand gestures (selecting with a tap of your thumb and index finger, pushing and pulling to navigate menus like the PIN lock, tilting and rolling your hand to move in different directions and scroll up and down, and closing your hand to go back to the previous screen or back to the \u201chome\u201d screen that show the time, battery life, and wireless connection) with the sci-fi-like Laser Ink Display projector. I have a reason for that: Because as cool as the projector is \u2014 everyone gets a kick from seeing it in action \u2014 it\u2019s not meant to be used very much. It\u2019s for brief interactions where it might be inappropriate for the AI to speak out loud or you need confirmation for something such as the composition of a photo or video.... ## A Very First-Gen Preview of The Future\\n\\nThe early messaging for the Ai Pin seemed to tout it as a smartphone replacement. Humane walked that back, either because of vocal criticism or, as I\u2019ve found out for myself, because the hardware and AI just aren\u2019t able to do a lot of essential phone things either as reliably, faster, better, or even at all.\\n\\nTake the 13-megapixel ultra-wide camera. It\u2019s simply terrible. Photos look like they were taken with an iPhone 4 with poor dynamic range, no shadow detail, and overall bad sharpness. It doesn\u2019t matter if I take photos inside or outside, or in good lighting or bad lighting \u2014 they don\u2019t look good. I couldn\u2019t get anything resembling what Humane\u2019s been showing off. The chipset is using a four-year-old image signal processor, so that doesn\u2019t help matters.\\n\\nVideos are pretty bad, too, with awful stabilization that always results in really visibly jiggly footage.\\n\\nOn top of that, most of my captured photos and videos are poorly framed, usually tilted or aimed too low. I consider myself an above-average amateur photographer with a solid grasp of composition guidelines like the rule of thirds, but there\u2019s nowhere on my body where I can clip the Ai Pin and get a shot that I would later look at and love. That\u2019s partially the Ai Pin\u2019s fault because the camera is aimed slightly downwards and not straight ahead, and partially because I\u2019m 5\u20196\u201d (66 inches tall). Attaching the Ai Pin at just above my heart, that\u2019s 15 inches lower than the top of my head and 10 inches lower than my eye level (basically equivalent to a camera on top of a 51-inch tripod), or what my real POV would be and the height at which I typically hold up my phone to capture a photo or video. If you\u2019re taller, the Ai Pin will be at a higher height, but how your footage turns out will depend entirely on your height. That\u2019s not something Humane can fix in the second or third generation unless it has a camera that can aim upward or uses AI to auto-magically reframe a shot. I was really excited to see how the AI would be used to create the best shot with a mixture of auto-cropping, straightening, and image fusion. I\u2019m disappointed to see the camera is worse than a GoPro or photos taken with smartglasses like the ones from Meta and Ray-Ban.",
        "published_at": "2024-04-11"
      },
      {
        "title": "Humane Ai Pin Reviews Nightmare: Takeaways and Analysis",
        "url": "https://www.techsponential.com/reports/humanereviews",
        "snippet": "# Humane Ai Pin Reviews Nightmare: Takeaways and Analysis\\n\\n### Ai Pin Reviews and Humane\u2019s Response\\n\\nHumane is a well-funded startup with excellent pedigree for modern mobile electronics; its founders and many of its key engineers previously worked on the iPhone at Apple. My analysis of the Ai Pin when it emerged from stealth was somewhat skeptical of the stand-alone product positioning, but noted that if Humane\u2019s voice-driven, laser projection/gesture interface provided a uniquely valuable experience, the price point would not be an issue. Then, at MWC 2024, the company gave live demos inside the Qualcomm booth that showed off the promise of the concept.\\n\\nOver the past week, initial Humane Ai Pin reviews were released and were so universally terrible that they generated controversy over the role of product reviewers. However, this isn\u2019t a case of Marques Brownlee (MKBHD on YouTube) seeking to draw viewers with sensationalism by calling the Ai Pin, \u201cthe worst product I\u2019ve ever reviewed.\u201d TheVerge\u2019s David Pierce described it as \u201cnot even close,\u201d and there were similar reactions from Arun Maines (Mrwhosetheboss on YouTube), CNET\u2019s Scott Stein, and Bloomberg\u2019s Mark Gurman. Even Michael Fisher (MrMobile on YouTube), who has been pining for a Star Trek comm badge for decades, could not recommend the product.\\n\\nThe company's official response has been to thank reviewers for approaching the category optimistically and emphasizing pricing and execution problems, not the concept of an AI wearable (even though some did question whether new AI wearables can exist alongside AI phones and smartwatches). Humane says that it appreciates the feedback and that it is working to add functionality and fix the problems that reviewers have pointed out. This is the best approach the company could take at this point; attacking reviewers would just make things worse. Reviewers\u2019 responsibility is to their audience and the algorithm, not the manufacturer.... ### It Didn\u2019t Have to Be This Way\\n\\nOf course, it didn\u2019t have to be this way. Launching a new company in a new category is always going to be a challenge, but Humane made things harder for itself by courting hype, over-promising, and then releasing the product well before it had a minimally viable feature set and a product that worked properly. If nothing else, the reviewers\u2019 reactions should not have been a surprise if Humane had conducted a third-party mock review / viability process. (Full disclosure: Techsponential regularly provides this as a service. We are often asked to test products before launch under NDA and write a review for internal use that includes bugs encountered, whether the product is ready for launch, pricing, and marketing positioning recommendations. Reach out if you\u2019d like to schedule one.)\\n\\nThis is not an indictment of all 1.0 products. In order to get something out the door \u2013 and get revenue flowing in \u2013 companies often have to ship something before the vision for the product is fully realized. Amazon\u2019s Kindle Scribe launched without critical features for managing your notes, but even at launch it was a fine large format Kindle for reading, and the team at Amazon continued improving the software and it\u2019s a much better product today. Apple launched the Apple Vision Pro without much software support, but that is growing daily, and even on day one the Apple Vision Pro offered a superior video watching experience with extensive content, along with nearly a million 2D iPad apps for productivity. That begs the question: is the problem with Humane\u2019s Ai Pin that it shipped too soon, before it reached an MVP (Minimum Viable Product) state? Or is the problem that the AI accessory product category as a whole is doomed?... ### What Can Likely Be Fixed\\n\\nSome of the complaints about the Ai Pin are specific to this iteration of the product that could be fixed with software updates, hardware updates, or interface tweaks:\\n\\nAccording to all the reviewers, the Ai Pin regularly overheats.\\n\\nBattery life is so poor that Humane includes multiple batteries and a portable charger in the box.\\n\\nAI responses are sometimes unbearably slow.\\n\\nThe Pin requires frequent authentication that is difficult to enter with the projection interface.\\n\\nThe projection interface itself can only be used for short periods of time and gets easily washed out outdoors.\\n\\nCamera output is poor, photos can be skewed depending on how the Pin is angled on your clothing, and it isn\u2019t always obvious when taking photos what is in frame.\\n\\nDoing anything with content \u2013 including sharing or posting photos \u2013 must be mediated by Humane\u2019s website rather than an app on your phone.\\n\\nCommon tasks where having an AI assistant a tap away on your chest would be most useful -- like to-do entries and calendar integration \u2013 aren\u2019t supported.\\n\\nThere are very few services integrated with the Ai Pin. For example, Tidal is the only music service supported.\\n\\nNot all of these issues need to be fixed for the product to be successful, but all of them can be addressed with improvements to the hardware or software. Some of this is already on Humane\u2019s roadmap, with the company promising fixes to the overheating issue, calendar integration, and an API for third party services in future software updates. Others may require new iterations of the hardware.... ### What Might Also Be Fixable\\n\\nIn the least surprising conclusion from the reviews, today\u2019s AI provides answers that are sometimes just wrong. AI for its own sake is suspect as a value proposition today.\\n\\n*Any* product that is sold primarily for AI access needs to account for the state of the technology. This may change over time. Developers are working on ways for LLMs to internally fact check with trusted sources before responding, and AI is advancing so rapidly that it may just be a matter of time where you can ask Jarvis and trust the answer is correct. Or not. We\u2019ll see.\\n\\nPricing is a key concern. If the price was lower, the bar for utility would be lower as well. The Ai Pin is both a relatively expensive $700 device and requires an ongoing $24/month service subscription. If the Ai Pin could replace your phone, that pricing would not be an issue, but for an accessory, at the very least it pushes it into well-heeled early adopter territory. There is also profitability to consider; Humane is a well-funded startup, but still just a startup, not a division of a company that makes billions on advertising, software, or hardware. If Humane cuts pricing to spur demand, it will have to cut deep, and then its revenue numbers won't add up for investors.... ### What Isn\u2019t Going to Change\\n\\nHowever, some of the issues that reviewers highlighted are based on Humane\u2019s design and positioning of the Ai Pin, and these cannot be changed without altering what the Ai Pin is.\\n\\nAs an independent device, Humane\u2019s Ai Pin has its own phone number and does not work with any group messaging platform such as WhatsApp or iMessage. That limits how the Ai Pin can be used for communication, and means that the AI summary \u201ccatch-up\u201d feature misses many important notifications.\\n\\nA wearable without an interactive display requires voice, and there are lots of situations where voice doesn't work (such as loud environments) or is socially inappropriate (on public transportation, in meetings, dealing with anything personal public spaces, etc.). However, a pin-style wearable simply cannot support a display directly. Smart glasses, smartwatches, or using your phone\u2019s display are all ways around this, but then it\u2019s not a pin anymore. This doesn\u2019t mean that there is no market for this form factor, but the form factor does limit how many jobs the product can do. It almost demands that this form factor act not as a standalone device, but as an extension of something else: your phone.\\n\\nThere are many paths to get to AI, including your phone, earbuds, smart watches, smart glasses, smart cars, smart speakers, and smart appliances. However, the smartphone is the center of your digital life, and AI integration is necessarily going to have to live there. Phones are not going away. They are too useful, flexible, and deeply integrated into the digital and real world. That doesn't mean that a secondary device or a smart pin can't succeed, but it needs to piggyback on the phone and then provide use cases that the phone does not address.",
        "published_at": "2024-08-07"
      },
      {
        "title": "The Worst Product I've Ever Reviewed... For Now",
        "url": "https://www.youtube.com/watch?v=TitZV6k8zfA",
        "snippet": "{ts:0} - All right, so this is the Humane AI Pin. It is a brand new product,\\n{ts:7} and a really, really\\ninteresting form factor of an ultra futuristic wearable computer. So in a time of all these\\ncrazy gadgets and Vision Pro,\\n{ts:17} and wearable glasses, it's so sick that we get so many genuinely new first\\ngeneration products like this\\n{ts:23} to give a shot. Unfortunately, it's also\\nthe new worst product I think I've ever reviewed,\\nin its current state.\\n{ts:31} There's just so many things bad about it. It's so bad, in fact, that I think it's actually\\nkind of distracting\\n{ts:39} to like understand what\\nthe point of the device is as we go through it. So I'm gonna have to separate\\nit out for this video.\\n{ts:44} First, I'm gonna tell you what it is, and what it's supposed to do, and then I'll tell you what my experience\\n{ts:53} has actually been using it. (mellow instrumental music) So this thing is a\\nsmall, wearable computer,\\n{ts:63} with an AI inside, that can help you throughout your day. It... all the time with you.\\n{ts:289} So, you can ask it things. It doesn't have a wake word, it only turns the mic on and\\nlistens when you touch it.\\n{ts:294} So you can go... (AI Pin beeps) How tall is the Empire State Building?\\n{ts:298} (AI Pin beeps) And then when you let go, it starts sending that\\nquery off to the crowd.\\n{ts:302} The- - [AI Pin] The Empire State Building is 1,454 feet tall to the tip.\\n{ts:308} - The Cloud. And then gets you an\\nanswer, which is great. And it also is multimodal.\\n{ts:312} So that means it can look at the camera, and see things, and interact\\nwith the world around you. So...\\n{ts:317} (AI Pin beeps) Look and tell me what you see. (AI Pin beeps)\\n{ts:321} So it'll scan the room,\\nuse the Cloud again. That little noise was it\\ntaking a little image, sending AI image to the Cloud,\\n{ts:328} analyzing it, getting it back, then deciding what to tell me. -... [AI Pin] You are sitting in front\\n{ts:333} of a camera and a laptop. The camera is on a tripod\\nand pointed at you. The laptop is open, and\\nyou are looking at it.\\n{ts:340} There are three pictures of\\ndogs on the wall behind you. There is a window to\\nthe left of the camera. There is a boom mic on\\nthe table in front of you.\\n{ts:347} There is a red carpet on the floor. - Great. The camera can also take pictures,\\n{ts:354} or up to 15 second videos, which it auto uploads while charging. It can also remember things\\nyou tell it to remember.\\n{ts:360} And all these things will\\nshow up in the Humane Center. So it's like this online web portal for all things connected to the pin.\\n{ts:367} There's no app, it's just the website. So there, you can see a whole\\nhistory of who you've called, and texted, and what you've listened to,\\n{ts:373} and what answers it gave to\\nyour most recent requests, and all the things you\\ntold it to remember. It is pretty well-rounded.\\n{ts:379} I think probably its best... tech demo feature though, is the translate back and forth. You got a two finger\\ngesture, you can go...\\n{ts:385} (AI Pin beeps) (Marques speaks in Spanish) (AI Pin beeps)\\n{ts:390} - [AI Pin] Where's the library? - So it auto detects the language,\\ntranslates it to English, and the person who speaks\\nback can translate back,\\n{ts:396} as long as you hold on the\\npin and listen to them. Pretty cool. This is all voice stuff though.\\n{ts:400} So if at any point you're in a loud area, or a very private area, and you don't wanna interact\\nout loud with your voice,\\n{ts:406} that's where this projector comes in. So it seems crazy, but\\nyou activate it like that, and then you just hold your\\nfinger out, your whole palm,\\n{ts:415} and it becomes a projector screen for the laser projector\\nbuilt into the pin. So it takes a little practice,... mentioning server timeouts, if you have a poor internet connection,\\n{ts:532} which happens to me all\\nthe time in this studio. So when they do most of the demos, like on their websites\\nand in their videos,\\n{ts:537} they'll ask a question,\\nand then they'll let go, and keep talking to fill the silence, so it's not awkward as\\nyou wait for an answer,\\n{ts:543} and realize how long it is. But even on this fast studio wifi here... (AI Pin beeps)\\n{ts:549} Who designed the Washington Monument? (AI Pin beeps) - [AI] Finding designer.\\n{ts:559} The Washington Monument was\\ndesigned by Robert Mills, a prominent 19th century\\nAmerican architect from South Carolina.\\n{ts:566} The construction was\\neventually completed by- - Okay. So you can just hold your hand up\\n{ts:571} to put your answer on your hand, and interrupt that it's talking so much. But even that was like a\\npretty good performance\\n{ts:578} for the AI Pin. In ideal, fast wifi conditions. But there are many, many times\\n{ts:584} when I feel like it... 's way slower, and it seems like it goes to the internet for almost everything.\\n{ts:589} I mean there's a few queries I guess might be local, like... (AI Pin beeps)\\n{ts:594} What time is it? (AI Pin beeps) - [AI Pin] 11:42 AM.\\n{ts:597} - Like that's pretty fast. If I ask the battery life, it can tell me that pretty fast.\\n{ts:600} But it feels like\\nbasically everything else is just shoveling it off to the Cloud, not computing on the device,\\nand it takes a while.\\n{ts:606} But it's also just wrong all the time. Like, I remember asking it\\ndays before the solar eclipse when the next eclipse\\nwas, and it said 2044.\\n{ts:615} I asked it, \\\"What's some\\ngood Asian food in the area?\\\" And over and over again it thought I said, \\\"What's the best ash?\\\"\\n{ts:622} For some reason? When is the next Nets game? (AI Pin beeps)\\n{ts:630} - [AI Pin] Finding next Nets game. The next Brooklyn Nets game\\nis on Sunday, April 14th, but no specific opponent... up and Google the answer in the time it takes me to get hopefully\\n{ts:1034} the right answer on the pin. It's just... Phones are OP.\\n{ts:1038} (AI Pin beeps) Look and tell me what this is. (AI Pin beeps)\\n{ts:1051} Or I'll just do this, I guess. Ah... It's a Cybertruck.\\n{ts:1057} - [AI Pin] The photo is of a Cybertruck. An electric pickup\\ntruck produced by Tesla. - Yup.\\n{ts:1065} Also, I gotta say, when\\nI say phones are OP, like screens in your hand. So sick.\\n{ts:1072} Just for the last like 10% of any UI, like you can get almost all the way there with just your voice interaction.\\n{ts:1078} But let's say you call an Uber, and you say, \\\"Take me to\\nthe studio from an Uber.\\\" Even if it could do that, which it can't,\\n{ts:1085} but let's say it could. And as you're waiting, you're like, \\\"I'm gonna just go grab a snack\\n{ts:1089} from this Starbucks on the corner.\\\"... {ts:1314} I've said a thousand times, like, my best ideas, golden rule, they always show up when\\nI can't write them down.\\n{ts:1321} Like when I'm about to fall asleep, or I'm in the shower, or driving, right? So I'm using the pin,\\n{ts:1328} I'm driving to the studio\\nand I have an idea. I'm not trying to write\\nit down on my phone while driving or pull over,\\n{ts:1335} but I had the pin, so\\nI'm driving and I just... (AI Pin beeps) \\\"Remind me of this cool ABC outro idea\\n{ts:1342} for the Humane review.\\\" (AI Pin beeps) And I just kept driving.\\n{ts:1346} And it wrote it down, and it saved it. - [AI Pin] Saving memory. - And when I go check the Humane-\\n{ts:1351} - [AI Pin] The outro idea\\nfor the Humane review has been saved. - The voice is kind of annoying.\\n{ts:1355} But now that's up in the Humane AI Center, so when I arrive at the studio, that thing that I told it to remember,",
        "published_at": "2024-04-14"
      },
      {
        "title": "I tested the Humane AI Pin - It's not good.",
        "url": "https://www.youtube.com/watch?v=0O2yTG3n1Vc",
        "snippet": "{ts:0} this is the Humane AI pin it's been blowing up the internet over the last\\n{ts:3} few months with the combined intelligence of sophisticated AI plus the entire internet all being brought to\\n{ts:8} you in a way that you can still be completely present in a moment and not bogged down by the hassle of working\\n{ts:13} around intrusive addictive phone applications and I just went Hands-On with it I spent about 4 hours using it\\n{ts:19} and talking to the CEO Iman and I don't think I've ever wanted to love a piece of technology so much and yet still be\\n{ts:27} unable to who's Mr who's the from YouTube finding YouTube video AR man also known as MOS is a popular YouTuber\\n{ts:41} with a focus on technology making him years old so here's how it works it Clips onto your clothing it stays there\\n{ts:49} on standby most of the time and then only when you decide that you want to engage with it do you place your finger\\n{ts:53} on this touchpad and you speak for example when do you think humans will settle on the moon humans are are\\n{ts:60} expected to return to the Moon in 2024 and have the first families on the Moon by 2084 okay so that... {ts:410} would you plan to pay it for the rest of your life probably not but at that point Humane is basically saying that your PIN\\n{ts:417} becomes a paperweight so fine it's very expensive but if its capability matches that then maybe it's justifiable well\\n{ts:425} what Imran the founder was saying to me is that the pin has the ability to run not just one but many of the top current\\n{ts:431} AI models so like GPT 4 for example which is a very powerful AI that does usually require its own paid\\n{ts:438} subscription for youus it has that on the go all the time which is definitely not to be sniffed at so one of the... {ts:445} things that he was saying he used it for is when he's driving his phone will be in his pocket his Focus will be on the\\n{ts:450} road but he has access to the entire internet of knowledge so he'll just decide I want to learn something about\\n{ts:456} sleep habits today for example and this pin can bring that knowledge in summarize it and speak it to you and\\n{ts:462} this is actually the first moment where I thought oh that's interesting when Risha my fiance does any kind of long\\n{ts:468} drive she often spends a good half an hour beforehand trying to find a good podcast to listen to during it and even\\n{ts:473} then they'll often Veer off topic or not be exactly what she was hoping for but this the world's information curated\\n{ts:480} exactly based on what you're asking to hear in any given moment well that could solve it plus the AI pin does understand\\n{ts:488} the flow of a conversation this isn't like old school Siri where you're just reintroducing the topic every single\\n{ts:493} time you bark a new command at it you can talk in a very human conversational way and it talks back so\\n{ts:501} my head started spinning with the possibilities this idea of a personal teacher wherever you want them but then... {ts:653} include fantastic marvelous talented tremendous and wonderful we'll go for Marvel\\n{ts:660} if human intonation and speed were the only issues though I'd be pretty happy to give Ain the benefit of the doubt\\n{ts:666} because longer term those are fixable things but I think the real problem with this product it it runs much deeper than\\n{ts:673} that for starters it hallucinates which has become this term to describe how AI can present false information as if it's\\n{ts:680} a fact so for example one of the advertised features is you hold a food in front of you and it tells you what is\\n{ts:685} in it like how much sugar or how many grams of protein but see when I asked it how many chicken nuggets there are in a\\n{ts:691} 20 chicken nugget share boox it said without a hint of caution the box contains fried chicken nuggets there are\\n{ts:698} 14 chicken nuggets in the Box interesting 14 well I think it's cuz it can only see\\n{ts:706} 14 yeah so how on Earth will you ever be able to trust a device's nutritional recommendations if it doesn't even know\\n{ts:713} how much of that food there is I mean I talked to Imran about this and he said well it... 's not a medical device and the\\n{ts:719} feature is kind of in beta and that's all fair enough but then what it is is an advertised feature either it needs to\\n{ts:725} get much much better very quickly which I don't think is going to happen because of the natural limitations of what this\\n{ts:731} thing can see or it needs to make you more aware of its limitations so that you know you shouldn't be taking what it\\n{ts:737} says at face value the idea in theory of let's say liking the look of this chair and for the PIN to be able to not just\\n{ts:743} tell you what it is but also save the answer to your notes is appealing but when you actually try and do that you\\n{ts:749} realize what the limitations of this form factor are like you can't see exactly what it's seeing so I asked this\\n{ts:755} exact question to it about the chair and it gave me a recommendation but then I later realized that the recommendation\\n{ts:760} it gave me was a different chair in the room and that's because when it gives you an answer you have no way of\\n{ts:766} affirming that it's the correct answer unlike when you do the same thing using Google lens on your phone where you can... {ts:771} make sure that you're capturing the right chair and then you can physically check that it has identified correctly\\n{ts:777} one thing that Imran talked about was the incoming AB to buy things using this but given that there's no real screen\\n{ts:783} here would you want to buy things on this like what if I meant to order two of something but the AI pin mishears me\\n{ts:789} and takes that as 20 what if it misunderstands the size or the color of what you're wanting and actually orders\\n{ts:794} an alternative variant there is so much that could go wrong that you'd really want to see an entire purchase page with\\n{ts:800} all the info and you can only do that on your phone but then also you have to talk to it because there is no physical\\n{ts:807} screen to type on your key input method has to default to speech and there are a lot of times I can think of where I\\n{ts:815} would not want to do that like what if you're in an art gallery or a library or more commonly for people a meeting what\\n{ts:821} if you're texting with your partner and you don't want to broadcast your intimate conversations any search... {ts:1129} my hands are definitely not free actually quite the opposite the laser does not re aim itself to wherever your\\n{ts:1134} hand is there is a specific spot where it fires you need to hold your hand there and you need to keep it as flat as\\n{ts:1140} possible your hand is basically your projector screen so the more creased you keep it the worse your picture quality\\n{ts:1145} is going to be I genuinely feel like doing this for 5 minutes is actually ironically much less comfortable than\\n{ts:1153} just holding your phone because you can hold your phone in any position you can support it on your lap or on a table and\\n{ts:1159} you can just keep moving it and yeah the Humane pin does have a surprising number of features considering there is no\\n{ts:1165} physical Hardware like being able to react to messages with emoji but then at that point where you're holding your\\n{ts:1171} hand out you're scrolling around and you're tapping multiple times surely there comes a point where it will\\n{ts:1176} actually just be faster to take your phone out and do it there and that brings me on to the gestures you know... {ts:1180} things like rolling your hand around I totally believe that they are things that you will get used to like I don't\\n{ts:1185} think it's fair to say that they're just not good after having used them once and also I totally get that you're not going\\n{ts:1190} to be using your hand screen as much as you would be using your phone screen but what you can't deny is that the total\\n{ts:1197} amount of effort required to per perform any given action is just higher with the pin like if you think about what it\\n{ts:1202} takes to hover over something with your phone is this if you think about what it takes to hover over something on the\\n{ts:1207} Humane pin it's this if you think about what it takes to click something it's that if you think about what it takes to\\n{ts:1213} click something over here it's that if you think about what it takes to go home one swipe if you think about what it\\n{ts:1219} takes to go home it's a full clench now why do I keep comparing it to the phone anyways we've already established that\\n{ts:1225} it's designed to be a separate device that isn",
        "published_at": "2024-04-11"
      },
      {
        "title": "Will it Hold? UX Designer Reviews Humane's AI Pin - Infinum",
        "url": "https://infinum.com/blog/ai-pin-ux-design-review/",
        "snippet": "**Presented as a fully screenless standalone device, the much-awaited AI Pin promises to revolutionize the way we interact with personal technology. Our UX designer reviews what we know so far.**\\n\\nLast November, the San Francisco startup founded by former Apple designers, Humane, introduced the AI Pin, a wearable device that acts as a mobile virtual assistant. The square device magnetically clips to your clothing or other surfaces and activates with a tap and voice command, or by displaying a laser ink display on your palm.\\n\\nHumane\u2019s AI Pin, scheduled for shipping in March, is pitched as a smartphone replacement and your daily assistant. It promises to seamlessly integrate itself into your life and help you get through the day while requiring no screen time consumption.\\n\\nHaving a virtual AI assistant that knows just what you need sounds appealing, but is the no-screen idea really feasible? What will the experience of using this completely new type of gadget be like in real life? In this article, we examine what we know about the AI Pin so far from a UX designer\u2019s perspective.\\n\\n## The AI Pin at a glance\\n\\nUnlike a smartphone, the AI Pin doesn\u2019t have apps. Instead, it offers \u201cAI experiences\u201d through different models activated at the user\u2019s request. The OS identifies what you need and picks the right tool for the job \u2013 it has access to language models from Microsoft and OpenAI, while AI-driven music experiences are powered by Tidal.\\n\\nThe device, priced at $699 with an additional monthly subscription of $24, runs on a Snapdragon processor with a dedicated Qualcomm AI Engine. It uses a Humane-branded version of T-Mobile\u2019s network and comes with an unlimited talk, text, and data plan, which truly makes it a standalone device. However, this also means you won\u2019t be able to take a call from your smartphone on it, like you could on a smartwatch.\\n\\nSome key features of the AI Pin include:\\n\\n- Web search, phone calls, and messaging\\n\\n- Email summary: summarizes your inbox, prioritizing important information\\n\\n- Laser ink display: projects information and a simple interface onto your palm\\n\\n- \u201cInterpreter\u201d feature: translates conversations in real-time, maintaining your intonation\\n\\n- Camera and image recognition: useful for various purposes, including keeping track of nutrition, and a shopping assistant in the future\\n\\n- Swappable battery: ensures 24/7 usage without the need for recharging\\n\\n- Privacy: no wake word or always-on listening. Activated by a tap and equipped with a \u201ctrust light\u201d indicating data collection... ## What sets the AI Pin apart?\\n\\nHumane\u2019s AI Pin is a new kind of wearable device that introduces artificial intelligence into everyday life. It works as your personal AI assistant, offering features unavailable through standalone apps or assistants like Siri. This assistant interacts smoothly with core system functions, such as contacts, emails, and calendars. It learns from every piece of information you feed it, from birthdays to favorite meals, delivering a personalized approach.\\n\\nThe AI Pin\u2019s set of features makes it a truly unique piece of technology in the existing smart device market. However, some of these features are already present in smartphones and smartwatches, and it wouldn\u2019t be surprising if some of its more advanced features find their way to these devices in the future.\\n\\nSmartphones and smartwatches already sync well with system functions and adapt to user preferences. As they evolve, the gap between these devices and AI Pin\u2019s functionalities could narrow. Still, the AI Pin\u2019s offering of an intuitive, personalized device stands out. Its UI emerges only when necessary, allowing you to fully immerse in new experiences or meaningful interactions without distractions.... ### Reshaping device interaction\\n\\nFrom a UX standpoint, interacting with the AI Pin can bring some challenges. The users will need to use their voice but also learn a new set of gestures.\\n\\nTo start with, voice communication with personal devices can feel awkward in public spaces or workplaces. It risks exposing private information and defying social norms. Additionally, voice recognition and AI response can be imperfect, requiring reiteration or prompt adjustments, something we find ourselves doing daily with chat-based AI models.\\n\\nThe other way of interacting with the Pin is by using gestures on the laser ink display on your palm. The display is activated by lifting and tilting your hand, and then you use gestures such as tilting and rolling your hand to browse songs or closing your fingers to make a selection. Closing your hand returns you to the homepage.\\n\\nSome may argue that gestures are a natural way of interaction, but the issue is that the industry hasn\u2019t reached a standard yet. For instance, pausing a song on the AI Pin involves a thumb-to-finger join, while a smartwatch might require a double tap.\\n\\nThis inconsistency creates a learning curve for the users, who may struggle to get the gesture right and navigate through the projection.\\n\\n**While the laser display itself looks impressive, there are concerns about how it will perform outdoors or other brightly lit conditions. This is an issue even smartphones and watches struggle with.**\\n\\nWith a laser projection, users might find themselves unable to read the display in bright sunlight.\\n\\nAnother potential issue is the curved and textured surface of the palm. An image can become distorted when projected onto a curved surface because parts of it can end up at a different distance from the projector. The parts further away from the projector can also exhibit some blurriness. The palm\u2019s texture can also affect the clarity of the projection \u2013 lines and patterns in the skin can compete with the image, hindering a clear view.\\n\\nFinally, there is also the issue of fitting information on a small surface. Users might find it difficult to find the information they need since it can only be displayed in small bits. This often leads to displaying less context, and the users might become tempted to switch to a device with a screen to get a full understanding, especially in noisy or social environments where they can\u2019t rely on voice alone.... ## Should we really go screenless?\\n\\nHumane\u2019s positioning of the Pin as a standalone device with the aim of replacing the smartphone is an intriguing concept, but unlikely to work for many people. The voice and laser projection alone have a lot of limitations \u2013 first of all, physical ones such as noisy environments and bright light. Then there are social and privacy concerns, from slight awkwardness to others overhearing your sensitive information.\\n\\nFrom a productivity perspective, performing some tasks using your voice may be much slower than using a screen, especially if you want to correct errors or you need to repeat commands. It is also important to stay aware that AI can \u201challucinate\u201d, misinterpreting or fabricating elements in its response. Verifying the accuracy of AI-produced information is easier on a device with a screen.\\n\\n**We should remember that visual media isn\u2019t just for entertainment or distraction. It\u2019s a critical communication tool and often key for executing daily tasks. Imagine trying to understand a complex infographic or a detailed picture via a voice description alone.**\\n\\nWhile the charm of a screenless future is compelling, we need a balanced approach. Letting go screens completely might not be practical or even desirable. Excessive screen time can be tackled without removing the screen entirely through ethical design choices, and the AI Pin can work alongside smartphones rather than replacing them.\\n\\nThere are a number of situations where this type of device could come in very handy. Consider cooking or working in sterile environments like hospitals \u2013 hands-free use would be of great help. The same goes for enhancing safety while performing complex tasks like driving or working in dangerous conditions. The AI Pin could also serve as a personal language tutor, and for those with visual impairments, it could be a game-changer.\\n\\nEssentially, the AI Pin could fill in the gaps, the use cases where a smartphone isn\u2019t the most efficient option, by offering a more convenient and accessible way to access information and control technology.\\n\\nSo far, it\u2019s uncertain whether Humane plans to offer options for connecting the AI Pin with other smart devices and what functional and privacy concerns that would raise. But its chances for successful adoption are far higher in collaboration with touchscreen devices rather than striving to become their replacement.... ## A glimpse into the future of personal technology\\n\\nHaving reviewed the information available to this point, we don\u2019t believe the AI Pin is going to replace smartphones. However, it opens new ways for us to engage with the digital world. Utilizing the technological advancements offered by AI, it builds a vision of a device that assists you but at the same time doesn\u2019t distract you from living your off-screen life.\\n\\nWhen designing products inspired by emerging technologies, sometimes the eagerness to utilize these new possibilities might overshadow our focus on user-centric design. That kind of approach risks creating solutions in search of problems rather than addressing genuine user needs.\\n\\nWe have yet to see how users will respond to the AI Pin, and we look forward to seeing what other companies will contribute to this evolving field.",
        "published_at": "2025-07-31"
      },
      {
        "title": "Blog: Ethical Considerations of AI In Marketing",
        "url": "https://www.silverbackstrategies.com/blog/ai-marketing-ethics/",
        "snippet": "**Blog:** Ethical Considerations of AI In Marketing: Balancing Innovation with Responsibility\\n\\n#### Table of Contents\\n\\nRapid technological advancements in recent decades have significantly transformed business communication and marketing. Artificial Intelligence, or AI, has played a key role in this transformation, driving a significant shift in the marketing industry. However, mistrust in AI due to a lack of transparency and inconsistent results hinders its potential. Establishing an ethical framework for AI can address these concerns and drive improvement in the field.\\n\\nWhat are ethical frameworks for AI in marketing? And how can you, as an innovative and ethical marketer, implement them in your business? Let\u2019s take a look.... ## Key Ethical Issues in AI Marketing\\n\\nWhile there\u2019s much discussion concerning ethical issues in AI, especially regarding marketing, most of the dialogue can be summed up in 3 key points.\\n\\n#### Data Privacy and Security\\n\\nGiven the vast amounts of personal information processed when companies use AI, data privacy is one of the most significant concerns that comes up when talking of AI in marketing \u2013 and understandably so. Data breaches and misuse of personal data can lead to substantial harm to individuals and reputational damage to businesses. That\u2019s why regulations such as the EU\u2019s General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) mandate strict data protection measures and transparent data practices.\\n\\nEven without legal regulations, businesses can follow AI best practices in their marketing. These include anonymizing data, implementing robust encryption methods, and regularly auditing data security protocols to ensure compliance and safeguard consumer trust.\\n\\n#### Algorithm Bias and Fairness\\n\\nMarketers looking to implement AI into their practices must understand the bias inherent in the algorithms. Algorithmic bias in AI can result in unfair and discriminatory outcomes that disproportionately affect marginalized groups. For instance, biased algorithms may unfairly target or exclude certain demographics in your marketing campaigns \u2013 without you realizing it until angry consumers post on social media.\\n\\nTo identify and mitigate this concerning issue, companies can employ strategies such as adversarial training, fairness constraints, and regular bias audits. Diverse data sets and inclusive development teams also help in creating fairer algorithms.\\n\\n#### Transparency and Accountability\\n\\nThe third key ethical concern regarding AI in marketing is transparency. Mainly, that means identifying what content is AI-generated and what\u2019s crafted by humans. This transparency is key to building a trusting relationship between you and your audience. People want to know where the content they are receiving comes from so that they can judge and respond to it appropriately.\\n\\nThis isn\u2019t to say that content can never be powered by AI; many consumers have even reported preferring AI content over human content in specific instances. However, 63% of consumers would like to know\\n\\n*when* the content they engage with is AI-generated.\\n\\nThis is why organizations (especially marketers) must clearly communicate how AI systems make decisions and the data sources they utilize. Accountability mechanisms, such as independent audits and clear governance frameworks, must be used to uphold that organization\u2019s ethical standards and brand accountability.... ## Ethical Frameworks and Guidelines\\n\\nExisting ethical frameworks and guidelines for AI\u2014the 2021 UNESCO recommendations, for example\u2014emphasize the importance of transparency, accountability, fairness, and respect for user privacy. Frameworks like these provide marketers with a structured approach for responsibly developing and deploying AI technologies. For example, guidelines such as the ones from UNESCO highlight the need for clear data governance policies, regular audits, and the inclusion of diverse perspectives in AI development to mitigate biases and ensure fairness.\\n\\nFrom a marketing perspective, adhering to these principles allows businesses to enhance consumer trust, avoid regulatory pitfalls, and foster a more ethical AI ecosystem. What\u2019s more, comprehensive ethical guidelines, such as those recommended by industry leaders, serve as a blueprint for navigating the complex ethical landscape of AI. As a marketer, make sure your practices not only comply with legal standards, but also align with societal values and the brand values of your organization.\\n\\n## Best Practices for Ethical AI Implementation\\n\\nSo, how can an ethical marketer use AI in a way that meets evolving industry-standard guidelines and frameworks? In addition to the three key ethical issues we mentioned above \u2013 data privacy and security, algorithm bias and fairness, and transparency and accountability \u2013 you can start by implementing these best practice suggestions.\\n\\n**Ethical AI Governance:**Establish clear ethical guidelines and governance structures for AI use within your organization. Depending on the size of your organization, this may include setting up an ethics committee and defining AI-related roles and responsibilities, or be as simple as drafting a code of conduct your employees abide by. **Inclusive Design:**To incorporate varied perspectives and reduce biases, include more diverse individuals in the AI development process. This enhances the system\u2019s overall fairness and effectiveness. **User Consent and Control:**Give your audience and our users control over their personal information and keep them informed about how their data is used. This helps build trust in your brand. **Accountability Mechanisms:**Set up feedback loops and reporting systems to address any AI issues promptly. **Continuous Improvement:**Regularly update your AI systems to incorporate the latest ethical standards and technological advancements.\\n\\nThat last point is particularly important in AI marketing. By continuously assessing your AI systems, organizations can identify and rectify potential ethical issues before they escalate. A proactive approach ensures you remain compliant with evolving regulations and upholds consumer trust in AI applications in marketing.... ## Ethical AI Marketing Examples\\n\\nLet\u2019s examine two prominent real-world examples to get a better idea of how companies can ethically use AI in their practices.\\n\\n#### IBM\\n\\nIBM is a leading example of a company that successfully balances innovation with ethical responsibility in AI marketing. They\u2019ve implemented a comprehensive AI ethics framework that emphasizes transparency, fairness, and accountability. This framework includes regular bias audits, transparent communication of AI system capabilities and limitations, and unwavering adherence to data privacy standards. As a result, IBM has cultivated a formidable reputation for dependable AI solutions that elevate customer trust and loyalty while mitigating ethical risks.\\n\\n#### Microsoft\\n\\nMicrosoft has also demonstrated a commitment to ethical AI marketing by integrating responsible AI principles into its core business strategies. They established an AI ethics committee to oversee AI developments and maintain compliance with ethical standards. Additionally, Microsoft provides extensive resources and training for its employees on ethical AI practices. The outcomes so far have been positive, including increased consumer confidence and the successful deployment of AI technologies that respect user privacy and promote fairness.\\n\\n## The Future of Ethical AI in Marketing\\n\\nWhile it\u2019s clear that AI isn\u2019t going anywhere, marketers must prepare for the future of using this tool ethically. Here\u2019s what you need to know as we move forward.\\n\\n### Advances in AI Technology\\n\\nEvery day, new advancements in AI technology are poised to revolutionize marketing practices by enhancing personalization, improving predictive analytics, and automating customer interactions. For instance, AI-driven algorithms can analyze vast amounts of data to create highly tailored marketing campaigns that increase customer engagement and conversion rates.\\n\\n### Evolving Ethical Standards\\n\\nAs AI evolves, so do the ethical standards to address new challenges. Industry organizations and regulatory bodies continue to play a role in shaping these standards by establishing guidelines for transparency, fairness, and accountability. Initiatives such as the European Union\u2019s AI Act aim to set stringent requirements for the ethical use of AI systems. These evolving standards help create a framework that balances innovation with consumer protection.\\n\\n### Preparing for the Future\\n\\nTo stay ahead of ethical challenges in AI, marketers must prioritize continuous learning and adaptation. This involves staying updated on the latest ethical guidelines, participating in industry forums, and seeking out educational opportunities related to AI ethics. Equally important, companies must implement robust internal policies and practices to ensure ethical AI use, which we mentioned earlier. An environment of ethical awareness and responsibility allows marketers to navigate the rapidly changing AI landscape effectively and sustainably.... ## Balance Innovation and Ethical Responsibility With Silverback Strategies\\n\\nSilverback Strategies has always prioritized innovation and ethical responsibility in our client services. From data analysis to content creation, we leverage AI only to enhance our client deliverables, not complete the work itself, and\\n\\n*always *with full human oversight. We strive for complete transparency and inclusiveness in all our services so our clients know they can trust us.\\n\\nContact us today to learn more about our services and how we can help you ethically incorporate AI into your marketing strategies.\\n\\n### Related Insights\\n\\n### Fundamentals: 5 Proven Tactics for Home Improvement Marketers\\n\\nread more\\n\\n### How a Google URL Parameter Wiped out $3B in Reddit\u2019s Valuation, and What Marketers Should Learn From It\\n\\nread more",
        "published_at": "2024-07-02"
      },
      {
        "title": "Ethical Considerations in AI-Driven Marketing - Bird",
        "url": "https://bird.marketing/blog/digital-marketing/guide/ai-automation-digital-marketing/ethical-considerations-ai-marketing/",
        "snippet": "As\\n\\n**Artificial Intelligence (AI)** becomes increasingly integrated into digital marketing, it is transforming how businesses engage with customers, make decisions, and optimize their strategies. From AI-powered personalization to predictive analytics, AI-driven marketing offers numerous benefits for efficiency, targeting, and scalability. However, the widespread use of AI in marketing also raises important **ethical concerns**\u2014particularly around data privacy, transparency, algorithmic bias, and the balance between automation and human oversight.\\n\\nIn this article, we will explore the ethical considerations that businesses must address when using AI in marketing and provide best practices for ensuring that AI-driven marketing strategies are both effective and ethical.... ## Key Ethical Concerns in AI-Driven Marketing\\n\\n### 1. Data Privacy and Consent\\n\\nOne of the most significant ethical challenges in AI-driven marketing is the issue of\\n\\n**data privacy**. AI-powered tools rely heavily on user data to deliver personalized experiences, target ads, and make predictive recommendations. However, the collection and use of personal data raise concerns about how that data is stored, shared, and used, especially in the context of regulations like the **General Data Protection Regulation (GDPR)** and the **California Consumer Privacy Act (CCPA)**.\\n\\nEthical marketing requires businesses to ensure that they are transparent about how they collect and use customer data. Users should be informed about the types of data being gathered, how it will be used, and how long it will be retained. Additionally, businesses must obtain\\n\\n**explicit consent** from users before collecting personal information, especially when using AI-driven tools for personalization or targeting.\\n\\nFor example, businesses should offer users clear opt-in mechanisms for tracking cookies, personalized ads, or email marketing, and give them the option to opt out or request deletion of their data.\\n\\n### 2. Algorithmic Bias\\n\\n**Algorithmic bias** is another significant ethical concern in AI-driven marketing. AI algorithms are trained on historical data, and if that data contains biases\u2014whether related to race, gender, socioeconomic status, or other factors\u2014the AI model may unintentionally perpetuate those biases. This can result in unfair treatment or exclusion of certain customer groups in marketing campaigns.\\n\\nFor instance, if an AI system is trained on data that reflects historical gender stereotypes in advertising, it may inadvertently reinforce those stereotypes by targeting ads differently to men and women. Similarly, AI used in credit scoring or loan approval processes has been criticized for reinforcing racial biases by disproportionately rejecting applicants from minority communities.\\n\\nTo mitigate algorithmic bias, businesses must ensure that their AI models are trained on\\n\\n**diverse and representative data** and are regularly audited for fairness. Implementing fairness checks and bias detection mechanisms helps identify and address biases before they negatively impact customers.... ### 3. Lack of Transparency and Explainability\\n\\nAI-driven marketing often involves complex algorithms that make decisions based on vast amounts of data. However, the\\n\\n**lack of transparency** around how these algorithms work can raise ethical concerns, particularly when consumers are unaware of how their data is being used or why they are being targeted with specific ads or recommendations.\\n\\nFor example, if an AI system recommends certain products or content based on a user\u2019s past behavior, the user may not understand why they are seeing those particular recommendations. This lack of transparency can erode trust in the brand and lead to concerns about manipulation or exploitation.\\n\\nTo address this issue, businesses should strive for\\n\\n**algorithmic transparency** by explaining how AI-driven recommendations or decisions are made. Providing users with clear information about why they are being shown specific ads or personalized content helps build trust and ensures that AI-driven marketing is more transparent and ethical.\\n\\n### 4. Over-Automation and Loss of Human Touch\\n\\nWhile AI can automate many aspects of marketing\u2014such as content creation, ad targeting, and customer support\u2014it\u2019s important to avoid\\n\\n**over-automation** that removes the human element from customer interactions. Customers value personalized, empathetic interactions, and fully automating every touchpoint can result in a loss of the **human touch** that is essential for building strong relationships.\\n\\nFor instance, AI-powered chatbots are effective for handling routine inquiries, but when dealing with complex or emotional issues, customers may prefer to speak with a human agent. Over-automation can lead to frustration if customers feel that they are not being listened to or that their unique needs are not being addressed.\\n\\nBusinesses should strike a balance between automation and human oversight, ensuring that AI is used to enhance, rather than replace, genuine customer interactions.... ### 5. Ethical Use of Personalization\\n\\nAI-driven\\n\\n**personalization** is a powerful tool for improving customer experiences and driving conversions, but it must be used ethically. Over-personalization\u2014where customers feel that a brand knows too much about them\u2014can lead to discomfort or even feelings of being spied on. Ethical personalization requires businesses to find the right balance between offering relevant content and respecting customers\u2019 privacy and boundaries.\\n\\nFor example, personalized product recommendations based on a user\u2019s browsing history are generally seen as helpful, but using highly sensitive personal data (such as health or financial information) for marketing purposes without explicit consent can be seen as intrusive.\\n\\nBusinesses should ensure that personalization strategies are\\n\\n**respectful** of customer privacy, avoid using overly sensitive data, and give users control over how their data is used.... ## Best Practices for Ethical AI-Driven Marketing\\n\\n### 1. Prioritize Data Privacy and Security\\n\\nTo ensure ethical AI-driven marketing, businesses must prioritize\\n\\n**data privacy** and **security** by complying with relevant regulations like GDPR and CCPA. This involves implementing robust data protection measures, such as encryption, anonymization, and secure storage of customer data. Businesses should also clearly communicate their data privacy policies to customers, ensuring that they understand how their data is being used and stored.\\n\\nFor example, businesses can use\\n\\n**cookie consent banners** that give users the option to accept or reject the use of tracking cookies for personalized ads. Additionally, companies should regularly review and update their data security practices to prevent data breaches.\\n\\n### 2. Implement Ethical AI Audits\\n\\nRegular\\n\\n**ethical audits** of AI systems are essential for identifying and mitigating algorithmic bias, ensuring fairness, and maintaining transparency. Businesses should audit their AI models to check for unintended biases that may result in discriminatory outcomes, especially in areas like ad targeting, credit scoring, or customer segmentation.\\n\\nFor example, an ethical AI audit might involve testing an algorithm\u2019s outputs across different demographic groups to ensure that it treats all users fairly. If bias is detected, businesses can retrain their AI models using more diverse datasets or adjust the algorithm to ensure that it makes equitable decisions.... ### 3. Maintain Human Oversight\\n\\nWhile AI-driven marketing offers many benefits, businesses should maintain\\n\\n**human oversight** to ensure that automated decisions align with ethical standards and brand values. For example, marketers should regularly review AI-generated content, ad targeting decisions, or product recommendations to ensure that they are appropriate and respectful of customers\u2019 needs.\\n\\nHuman oversight is particularly important when dealing with sensitive issues or complex customer interactions. For instance, AI-powered chatbots should have clear escalation paths to human agents when a customer\u2019s inquiry requires a more personal touch.\\n\\n### 4. Be Transparent with Customers\\n\\nBuilding trust with customers requires transparency about how AI-driven marketing works. Businesses should clearly explain how their AI systems operate, why customers are being shown specific ads or recommendations, and how their data is being used. Providing users with\\n\\n**explainable AI** helps demystify the technology and ensures that customers feel comfortable engaging with AI-powered experiences.\\n\\nFor example, businesses can include short descriptions or FAQs on their websites that explain how AI algorithms personalize content or make recommendations. This transparency helps build trust and ensures that AI is used in an ethical and responsible manner.\\n\\n### 5. Give Customers Control Over Their Data\\n\\nEmpowering customers to control how their data is used is a key aspect of ethical AI-driven marketing. Businesses should offer clear\\n\\n**opt-in and opt-out** options for personalized ads, data tracking, and marketing communications. Additionally, customers should be able to request access to their data or have it deleted if they no longer wish to engage with the brand.\\n\\nFor example, businesses can provide users with the option to update their marketing preferences, choose which types of communications they want to receive, or adjust how much of their personal data is used for personalization purposes.... ## Challenges of Ethical AI in Marketing\\n\\nWhile ethical AI practices offer significant benefits, businesses face several challenges when implementing them:\\n\\n### 1. Balancing Personalization and Privacy\\n\\nStriking the right balance between offering\\n\\n**personalized experiences** and respecting customer privacy can be difficult. Over-personalization or the misuse of sensitive data can lead to customer discomfort or backlash, so businesses must carefully consider which types of data to use and how to use it responsibly.\\n\\n### 2. Complexity of Algorithmic Transparency\\n\\nExplaining complex AI algorithms to customers in a way that is both clear and understandable can be challenging. Businesses need to find ways to make their AI systems more transparent while maintaining the technical integrity of their algorithms.\\n\\n## Conclusion\\n\\nAs AI continues to play a larger role in\\n\\n**digital marketing**, businesses must navigate the ethical challenges that come with using AI-driven tools and strategies. From **data privacy** and **algorithmic bias** to the need for **transparency** and **human oversight**, ethical considerations are essential to building trust, ensuring fairness, and creating positive customer experiences. By implementing ethical AI practices\u2014such as regular audits, transparent communication, and customer control over data\u2014businesses can leverage the power of AI to enhance their marketing efforts while maintaining high ethical standards.",
        "published_at": "2024-10-08"
      },
      {
        "title": "What Are the Ethical Challenges of AI in Marketing?",
        "url": "https://www.stack-ai.com/articles/what-are-the-ethical-challenges-of-ai-in-marketing",
        "snippet": "# What Are the Ethical Challenges of AI in Marketing?\\n\\nMay 29, 2025\\n\\n##### Paul Omenaca\\n\\nCustomer Success at Stack AI\\n\\nArtificial intelligence (AI) is revolutionizing the marketing landscape, enabling unprecedented levels of personalization, automation, and data-driven decision-making. From predictive analytics to AI-powered chatbots, the integration of AI in marketing strategies is reshaping how businesses engage with consumers and optimize campaigns. However, as AI\u2019s influence grows, so do the ethical challenges of AI in marketing. These challenges are not merely technical hurdles; they touch on fundamental questions of privacy, fairness, transparency, and societal impact.\\n\\nFor marketing professionals, CIOs, and enterprise leaders, understanding the ethical challenges of AI in marketing is essential. The stakes are high: mishandling these issues can erode consumer trust, invite regulatory scrutiny, and damage brand reputation. As AI systems become more autonomous and complex, the need for robust ethical frameworks and responsible innovation becomes ever more urgent. This article explores the multifaceted ethical challenges of AI in marketing, offering insights and guidance for organizations seeking to harness AI\u2019s power while upholding ethical standards.\\n\\n## Navigating the New Frontier: Why AI Ethics Matter in Marketing\\n\\nThe adoption of AI in marketing is accelerating at a rapid pace. Enterprises are leveraging AI to analyze vast datasets, predict consumer behavior, automate content creation, and deliver hyper-personalized experiences. While these capabilities offer significant competitive advantages, they also introduce new ethical dilemmas. The sheer scale and opacity of AI-driven marketing systems can amplify risks related to privacy, bias, manipulation, and accountability.\\n\\nFor IT professionals and business leaders, the ethical challenges of AI in marketing are not abstract concerns\u2014they are practical issues that impact daily operations, customer relationships, and long-term business sustainability. Addressing these challenges requires a proactive, multidisciplinary approach that balances innovation with responsibility.... ## Section 1: The Core Ethical Challenges of AI in Marketing\\n\\n### Privacy and Data Protection\\n\\nOne of the most prominent ethical challenges of AI in marketing is the collection, analysis, and use of personal data. AI systems thrive on data, often requiring access to sensitive information such as browsing history, purchase behavior, location, and even biometric data. While this data enables powerful personalization, it also raises significant privacy concerns.\\n\\n**Informed Consent**\u2013 Many consumers are unaware of the extent to which their data is collected and used by AI-driven marketing platforms. Obtaining genuine informed consent is challenging, especially when privacy policies are lengthy and opaque. **Data Security**\u2013 The aggregation of large datasets increases the risk of data breaches, exposing consumers to identity theft and other harms. **Regulatory Compliance**\u2013 Laws such as GDPR and CCPA impose strict requirements on data handling. Non-compliance can result in hefty fines and reputational damage.\\n\\nFor organizations seeking to build trust, implementing robust privacy practices and transparent data governance is non-negotiable. For more on how AI can be used responsibly in customer engagement, see AI-powered customer scoring tools.\\n\\n## Section 2: Algorithmic Bias and Discrimination\\n\\n### Fairness in Automated Decision-Making\\n\\nAI algorithms are only as unbiased as the data they are trained on. In marketing, biased algorithms can lead to discriminatory outcomes, such as excluding certain demographic groups from targeted campaigns or offering preferential treatment based on race, gender, or socioeconomic status.\\n\\n**Historical Bias**\u2013 Training data often reflects existing societal biases, which AI systems can inadvertently perpetuate or even amplify. **Opaque Decision-Making**\u2013 Many AI models operate as \u201cblack boxes,\u201d making it difficult to understand or challenge their decisions. **Vulnerable Populations**\u2013 AI-driven marketing can disproportionately impact vulnerable groups, leading to exclusion or manipulation.\\n\\nAddressing algorithmic bias requires ongoing monitoring, diverse data sources, and the inclusion of ethical considerations in model development. Enterprises should invest in bias detection tools and ensure that their AI systems are regularly audited for fairness.... ## Section 3: Transparency and Explainability\\n\\n### The Need for Explainable AI\\n\\nTransparency is a cornerstone of ethical AI in marketing. Consumers and regulators increasingly demand to know how AI systems make decisions that affect them. However, the complexity of modern AI models often makes explainability a significant challenge.\\n\\n**Black Box Models**\u2013 Deep learning and other advanced techniques can produce highly accurate results, but their inner workings are often inscrutable. **Accountability**\u2013 When AI-driven marketing decisions lead to negative outcomes, it can be difficult to assign responsibility or provide recourse. **Consumer Trust**\u2013 Lack of transparency undermines trust, making consumers wary of engaging with AI-powered services.\\n\\nTo foster trust and accountability, organizations should prioritize the development and deployment of explainable AI models. This includes providing clear information about how data is used and how decisions are made. For a deeper dive into building transparent AI workflows, explore AI workflow automation solutions.\\n\\n## Section 4: Manipulation and Autonomy\\n\\n### The Ethics of Persuasion\\n\\nAI\u2019s ability to analyze and predict consumer behavior enables highly effective marketing strategies. However, this power also raises ethical questions about manipulation and consumer autonomy.\\n\\n**Behavioral Targeting**\u2013 AI can identify psychological triggers and vulnerabilities, enabling marketers to influence decisions in subtle, sometimes exploitative ways. **Dark Patterns**\u2013 Some AI-driven interfaces are designed to nudge users toward specific actions, such as making a purchase or sharing more data, often without their full awareness. **Autonomy and Consent**\u2013 The line between persuasion and manipulation can be thin, especially when AI systems are designed to maximize engagement or revenue at the expense of user well-being.\\n\\nEthical marketing requires respecting consumer autonomy and avoiding tactics that exploit cognitive biases or emotional vulnerabilities. Organizations should establish clear guidelines for responsible AI-driven persuasion.... ## Section 5: Societal Impact and Accountability\\n\\n### Beyond the Individual: Broader Ethical Considerations\\n\\nThe ethical challenges of AI in marketing extend beyond individual consumers to encompass broader societal impacts.\\n\\n**Job Displacement**\u2013 Automation of marketing tasks can lead to job losses, raising questions about corporate responsibility and the future of work. **Social Inequality**\u2013 AI-driven marketing can reinforce existing inequalities by privileging certain groups over others, both as consumers and as businesses. **Environmental Impact**\u2013 The computational resources required for large-scale AI systems contribute to environmental concerns, such as increased energy consumption.\\n\\nEnterprises must consider the societal implications of their AI strategies and strive to create value that benefits all stakeholders. This includes investing in workforce reskilling, promoting diversity and inclusion, and adopting sustainable AI practices. For organizations interested in leveraging AI for positive impact, see enterprise AI solutions.\\n\\n## Take Action: Building an Ethical AI Marketing Strategy\\n\\nThe ethical challenges of AI in marketing are complex and evolving, but they are not insurmountable. By adopting a proactive, principled approach, organizations can harness the benefits of AI while minimizing risks and upholding their ethical responsibilities.\\n\\n**Key steps for enterprises and IT leaders:** **Develop a Code of Ethics**\u2013 Establish clear ethical guidelines for AI development and deployment. **Foster Multidisciplinary Collaboration**\u2013 Involve stakeholders from diverse backgrounds, including ethicists, technologists, marketers, and consumers. **Invest in Training and Awareness**\u2013 Provide ongoing education on AI ethics for employees at all levels. **Implement Robust Governance**\u2013 Regularly audit AI systems for compliance, fairness, and transparency. **Engage with Stakeholders**\u2013 Solicit feedback from consumers, regulators, and advocacy groups to ensure that AI strategies align with societal values.\\n\\nTo learn more about how your organization can implement ethical AI solutions in marketing, contact our team for a consultation.... ## Frequently Asked Questions\\n\\n**1. What are the main ethical challenges of AI in marketing?**\\n\\nThe main challenges include privacy and data protection, algorithmic bias, lack of transparency, manipulation of consumer behavior, and broader societal impacts such as job displacement and inequality.\\n\\n**2. How can companies ensure AI-driven marketing is ethical?**\\n\\nBy developing ethical guidelines, investing in bias detection, ensuring transparency, and engaging stakeholders in the design and deployment of AI systems.\\n\\n**3. Why is transparency important in AI marketing?**\\n\\nTransparency builds trust, enables accountability, and allows consumers to understand how their data is used and how decisions are made.\\n\\n**4. What is algorithmic bias, and why does it matter in marketing?**\\n\\nAlgorithmic bias occurs when AI systems produce unfair or discriminatory outcomes due to biased training data or flawed models. In marketing, this can lead to exclusion or unfair targeting of certain groups.\\n\\n**5. How does AI in marketing impact consumer privacy?**\\n\\nAI systems often require large amounts of personal data, raising concerns about consent, data security, and potential misuse.\\n\\n**6. Can AI in marketing be manipulative?**\\n\\nYes, AI can be used to exploit psychological triggers and influence consumer decisions in ways that may not always align with their best interests.\\n\\n**7. What role does regulation play in ethical AI marketing?**\\n\\nRegulations like GDPR and CCPA set standards for data protection and privacy, requiring organizations to handle consumer data responsibly.\\n\\n**8. How can organizations address job displacement caused by AI in marketing?**\\n\\nBy investing in workforce reskilling, creating new roles related to AI oversight, and fostering a culture of continuous learning.\\n\\n**9. What is explainable AI, and why is it important?**\\n\\nExplainable AI refers to systems whose decisions can be understood and interpreted by humans, which is crucial for accountability and trust.\\n\\n**10. Where can I learn more about implementing ethical AI in my organization?**\\n\\nYou can explore resources on AI workflow automation, enterprise AI solutions, or contact our team for expert guidance.\\n\\nBy addressing the ethical challenges of AI in marketing head-on, organizations can not only mitigate risks but also build stronger, more trustworthy relationships with their customers and society at large.\\n\\n##### Make your organization smarter with AI.\\n\\nDeploy custom AI Assistants, Chatbots, and Workflow Automations to make your company 10x more efficient.\\n\\nArticles",
        "published_at": "2025-06-10"
      },
      {
        "title": "What Are the Ethical Issues of AI Marketing?",
        "url": "https://bigwave.co.uk/blog/what-ethical-issues-ai-marketing/",
        "snippet": "Many businesses and marketers now are now integrating AI marketing systems into their daily work, to assist with tasks such as scheduling, data analysis or automation. As AI marketing is used more regularly in the workplace, it is important, now more than ever, that the ethical concerns of AI in marketing are taken into consideration.\\n\\nH2-Understanding the Ethics of AI Marketing\\n\\nAdopting a set of general social values that apply to a workplace setting is vital in ensuring that professional lines are not crossed when using AI, and these values and principles should be followed when setting up or using AI. Consideration should be taken to ensure that creative rights, professional integrity, and human rights are upheld throughout, just as we have done before the creation of AI.\\n\\nWith the growth of AI, the United Nations and research communities have created a framework for professionals to follow. A notable example is the UNESCO Recommendation on the Ethics of Artificial Intelligence, introduced in November 2021. This recommendation serves as a global standard for AI ethics.\\n\\nAlthough there are some existing AI regulations at regional and national levels, the rapid progress of AI suggests that more government regulations are likely to emerge in the future.\\n\\n## The Significance of AI Ethics\\n\\nAI has already begun to pay a huge role in the world of marketing, across all channels and sectors in the industry, business have begun to implement it.\\n\\nJust one example of the importance of AI in marketing is its use within social media marketing. According to The 2023 State of Social Media: AI and Data Take Centre Stage report, business leaders anticipate a surge in AI investments in the upcoming years. 90% of business leaders surveys in the report where aware that the success of their business will rely on effective analysing and reacting to data collected from social media marketing, to which 97% expected AI to place a huge role in assisting in the analysing of social media data and predicting trends.\\n\\nAlthough AI can be a fantastic tool for all areas of marketing, it does come with its limitations Misusing AI or disregarding ethical considerations can result in harm to brand reputation, product malfunctions, legal disputes, and regulatory issues.... ## What Are the Ethical Concerns Of AI?\\n\\n### Data Privacy\\n\\nA major ethical concern that has been brought to the attention of marketers is customers\u2019 data privacy. Adhering to data privacy has been a key discussion in marketing over the past decade, with some of the biggest brands, such as Facebook, being questioned on the ethical use of customer and user data.\\n\\nAI relies entirely on data analysis and using machine learning algorithms, therefore when using AI, it is important that data safeguarding strategies are put in place to ensure there are no unintentional breaches of privacy or unethical methods of collecting data.\\n\\n### H3-Algorithm Bias\\n\\nAI-driven marketing also presents ethical concerns related to algorithmic bias and fairness. This occurs when algorithms meant to deliver personalised content unintentionally reinforce bias and treats individuals in a morally objectionable way, leading to unequal or unpleasant user experiences. The data used to train these algorithms might reflect historical inequalities and cultural biases, or social prejudices.\\n\\nTo counter algorithmic bias, marketers can adopt strategies like using diverse data collection and validation methods. Crafting campaigns that appeal to a broader audience can also help. Regularly monitoring and reviewing algorithms can aid in identifying and rectifying unintended biases. Openly communicating about AI usage can enhance user trust.\\n\\n### Property and Plagiarism\\n\\nGenerative AI creates concerns regarding intellectual property and plagiarism. There is a possibility that AI algorithms, when trained on copyrighted material, could inadvertently generate works that replicate copyrighted content without proper authorisation.\\n\\nTo uphold intellectual property rights and uphold principles of fair use, both content creators and generative AI developers must navigate this complex ethical and legal landscape.\\n\\n### Ethical Influencer Marketing\\n\\nThe integration of AI into advertising and influencer marketing necessitates ethical contemplation in these domains too. Enterprises should guarantee that promotional material is sincere, transparent, and aligned with user inclinations. When collaborating with influencers, brands should emphasise genuineness and openness, explicitly revealing compensated affiliations to uphold credibility with their followers.... ## Using Human Oversight to Ensure Ethical Use of AI In Marketing\\n\\nThe best way to ensure that AI is used ethically is to continue human oversight and to use AI as an assistive tool rather than letting it do your job for you. A partnership between AI and marketers can be successful if we are diligently monitoring this emerging technology and ensuring we uphold the ethical values we set out.\\n\\n## How the Bigwave Team Can Help You\\n\\nAt Bigwave we have been excited to integrate AI into our business and we see\\n\\nThe Bigwave team consists of seasoned marketing professionals with extensive experience and expert knowledge. This team is adept at crafting comprehensive marketing campaigns and strategies from inception to completion. Through the combined efforts of our creative teams, website department, and marketers, we can achieve a level of success in marketing campaigns that surpasses what AI could ever achieve.\\n\\nFor more information on how Bigwave can help you, book a call today.",
        "published_at": "2024-03-22"
      },
      {
        "title": "The ethical use of AI in advertising",
        "url": "https://iapp.org/news/a/the-ethical-use-of-ai-in-advertising",
        "snippet": "## Related stories\\n\\nConsiderations for children's privacy, safety in AI-generated marketing\\n\\nMarketing sits in a gray zone under EU AI Act\\n\\nNotes from the Asia-Pacific region: Australia eSafety Commissioner launches social media age restrictions hub\\n\\nEU Data operational impacts: The Data Act's interplay within the EU digital rulebook\\n\\nThe 2025 Brazilian DPO: Navigating high risks with limited runways\\n\\nADVERTISEMENT\\n\\nADVERTISEMENT\\n\\nADVERTISEMENT\\n\\nC. Kibby\\n\\nIAPP staff\\n\\n8 Minute Read\\n\\nArtificial intelligence is reshaping the advertising industry, enabling unprecedented levels of personalization, efficiency and audience targeting. The IAPP's AI Governance Profession Report 2025 shows that across sectors, 16% of companies use AI for personalizing experiences and 16% use it for customer interactions. Among marketers, 69% have already integrated AI into their marketing operations, with nearly 20% allocating more than 40% of their budget to AI-driven campaigns.\\n\\nHowever, as AI becomes increasingly embedded in advertising strategies, it also raises significant ethical concerns, from data privacy risks to algorithmic bias and the potential for consumer manipulation.\\n\\nThese challenges cannot be addressed by technology alone \u2014 they require a collaborative approach among stakeholders who shape the advertising ecosystem, including regulators, advertisers, technology companies, civil society organizations and consumers themselves. By fostering transparency, fairness and human oversight, a stakeholder-driven approach can help align AI-powered advertising with ethical principles and societal values.... ADVERTISEMENT\\n\\nMany entities across the advertising sector have built responsible AI use policies that identify and counteract potential risks associated with using AI in their organizations. In a survey of AI risks that sampled entities ranging from trade organizations like the Association of National Advertisers to large marketing companies like Salesforce to self-regulatory agencies like the Children's Advertising Review Unit, some risks popped up again and again: algorithmic bias, hallucinations, data privacy risks, confusion over whether something is AI-generated and intellectual property concerns.\\n\\nAlgorithmic bias, when an algorithm generates unfair or discriminatory outputs, can harm businesses in several ways. For example, marketing campaigns may be mistargeted based on inaccurate assumptions or businesses may make flawed product decisions about things customers do not actually want. Hallucinations, where an AI generates outputs that are false or fabricated, similarly produce results that can be anywhere from useless to misleading. The most robust policies combat these possibilities both proactively and reactively.\\n\\nMarketers can protect against potential algorithmic bias and hallucinations at each step of AI deployment, starting with training the AI on a high-quality, high-quantity dataset. \\\"Biased data and biased models lead to biased results,\\\" Jennifer Chase, chief marketing officer and vice president of SAS wrote in an article for Forbes. AI models trained on broad, well-audited datasets are more likely to accurately predict the real world. To this end, multiple companies have created tools that make obtaining and vetting databases easier. Google has released Dataset Search, a large repository of datasets that are freely available on the web. Amazon's SageMaker Ground Truth offers human input at multiple points in the training process, such as giving human feedback on the quality of a model's responses or labeling data to more easily train an AI.... Policies from companies like Salesforce and PricewaterhouseCoopers stress the importance of building guardrails into the AI before deployment and testing and retesting outputs after deployment. For instance, Salesforce's hallucination reduction policies restrict a model's output to a specified scope, and their mindful friction practice introduces \\\"pauses in the user experience to ensure intentional human engagement at critical junctures.\\\" PwC's Responsible AI playbook recommends training employees to know \\\"how to verify GenAI's outputs, create channels to report suspect results, and establish a risk-based system to review these outputs.\\\"\\n\\nEven when an AI's inputs are good quality, training AI is a continual process, so auditing an AI's outputs can show if the model needs to be updated or corrected. Some marketing policies require regular evaluations using tools like TensorFlow's Fairness Indicators or IBM's AI Fairness 360, which check for skewed data. Human viewpoints can also provide valuable insight; it can be easy to spot larger errors, but experts can identify subtle hallucinations or bias and help to correct them.\\n\\nA report and recommendation from the International Advertising Bureau collected advice from such experts, many of whom advocate for vigilant analysis of the AI to avert hallucinations or bias. Noticing flaws in a model does not necessarily indicate malintent \u2014 they can happen even \\\"where perfectly well-meaning models deployed by very smart people learned to do things they were not intended to do, (which can) cause brand damage.\\\"... Another way to mitigate the risk of hallucinations or bias is to limit how AI is used. The EU AI Act defines some AI uses as higher risk than others and imposes more stringent requirements for higher-risk applications. Recognizing this concern, some marketing policies advise against using AI to determine if an individual is eligible for employment, credit, health care, housing or other decisions with legally significant effects. 2X Marketing's\\n\\n__policy__ bars employees from using AI for human resource-related matters like recruitment and hiring, while consumer goods giant Unilever's policy requires that \\\"any decision that has a significant life impact on an individual should not be fully automated.\\\" Such limitations and human oversight can help recognize potential issues before a consumer ever interacts with an AI.\\n\\nEvery phase of an AI's life cycle \u2014 from training to deployment \u2014 depends on data: the datasets that train it, the inputs it consumes, and the feedback loops that refine its model. Each of those stages can expose an individual's personal information, whether from proprietary customer records in a training corpus, sensitive information a customer submits to a chatbot, or usage logs that go into model updates. Given just how much data an AI needs, these risks can seem daunting, but lawmakers, regulators and professionals alike are developing structured ways to evaluate and mitigate these concerns.... Weaving technical controls and governance processes through every stage of the AI life cycle, from data collection to data curation to model training to deployment and beyond, builds a more resilient system. By adopting these principles, the advertising industry can ensure that AI-driven marketing remains ethical, consumer-friendly and aligned with broader societal values.\\n\\n**Tips for businesses of all sizes**\\n\\nBased on the key principles earlier laid out, there are many good practices that any sized business can observe when using AI:\\n\\nEstablish clear guidelines and policies for the use of AI in marketing.\\n\\nTrain employees on ethical AI practices.\\n\\nImplement appropriate data governance procedures.\\n\\nDiligently monitor AI systems and conduct audits.\\n\\nProtect consumer rights and welcome productive feedback.\\n\\nVerify and fact-check all content, regardless of origin.\\n\\n**Why it matters**\\n\\nBy prioritizing the ethical use of AI in marketing, businesses have a great opportunity to cultivate trust with their consumers. And the ethical use of AI in marketing is not only instrumental for fostering consumer trust, but also for making the most out of the technology itself as businesses are able to align their AI systems with social norms and values.\\n\\nFurthermore, with uncertainty around the future of third-party cookies and other foundational advertising methods, the adtech industry can benefit by supplanting their existing methods with AI. Potential uses for AI in marketing continue to multiplying exponentially, ranging from generating ad copy and images to analyzing campaign metrics from anonymized datasets to automating customer service and beyond; indeed, more uses seem to pop up every day.... However, precisely because AI has so many potential uses, adhering to ethical standards and having infrastructure can help limit those uses to what is necessary or helpful to a business. When you have a hammer, everything can look like a nail, so it's wise to identify what problems AI can help with and how exactly businesses can use it to solve those problems.\\n\\nKeeping these principles in mind also aids in future-proofing organizational practices against the whirlwind of shifting legislation, regulations and rules. Adhering to best practices helps businesses to anticipate future compliance requirements, and having governance infrastructure in place can aid in adapting when those compliance requirements change.\\n\\nAI continues to redefine the landscape of advertising, so ensuring its ethical deployment will be critical in preserving consumer trust and upholding industry standards. By adhering to principles like fairness, transparency, privacy protection and human oversight, businesses can not only mitigate risks but also harness AI's potential responsibly.... As AI-driven marketing becomes increasingly sophisticated, a thoughtful, proactive approach will be key to responding to the whirlwind of technological and regulatory changes that define the field of AI right now. Establishing solid, organization-wide principles builds resilience and fosters a future where innovation thrives without compromising ethical standards or consumer rights.\\n\\n*C. Kibby is a Westin Research Fellow for the IAPP.*\\n\\n*Special thanks to Aly Apacible-Bernardo, former legal research associate for the IAPP, for her research contributions during the drafting of this article.*\\n\\nThis article is eligible for Continuing Professional Education credits. Please self-submit according to CPE policy guidelines.Submit for CPEsInterested in writing for us? Visit our Contributor Guidelines Page",
        "published_at": "2025-05-21"
      },
      {
        "title": "Rabbit R1: Limited AI capabilities and controversy.",
        "url": "https://informoverload.com/rabbit-r1-limited-ai-capabilities-and-controversy/",
        "snippet": "##\\n\\nDespite the buzz surrounding the Rabbit R1, a deep dive into its capabilities reveals some critical limitations that raise questions about its efficacy as a cutting-edge AI assistant. While the R1 boasts bespoke code and a unique user experience, its functionality falls short of the expectations set by its $200 price tag. This article explores the challenges and controversies surrounding the Rabbit R1, shedding light on its true potential.\\n\\n### An Unflattering Comparison\\n\\nEarly reviews of the Rabbit R1 have drawn parallels to the underwhelming reception of the $700 Humane AI Pin, signaling a trend of disappointment among tech enthusiasts. Tech blogger Mishaal Rahman\u2019s experiment with running Rabbit\u2019s OS on a Pixel 6 phone revealed glaring deficiencies in the R1\u2019s performance. Despite limited access to Rabbit\u2019s features, the experiment highlighted the device\u2019s inability to seamlessly integrate with Android systems, casting doubt on its practical utility.\\n\\n### Cloud-Based Operation\\n\\nRabbit\u2019s CEO, Jesse Lyu, defended the R1\u2019s unconventional design, emphasizing its cloud-based operation and firmware modifications. The statement clarified that the R1 is not a standalone Android app; rather, it relies on cloud servers to execute its AI models. This distinctive approach, while innovative, raises concerns about the device\u2019s dependence on external infrastructure and its susceptibility to connectivity issues.... ### A Puzzling User Experience\\n\\nInitial tests of the Rabbit R1 revealed a puzzling user experience characterized by limited functionality and erratic performance. The device\u2019s rudimentary screen and subpar resolution hindered seamless interaction, as users struggled to navigate its features effectively. Furthermore, the R1\u2019s questionable accuracy in tasks such as identifying colors and locations underscored its lack of precision and reliability.\\n\\n### Operational Challenges\\n\\nConnecting the Rabbit R1 to external apps like Spotify posed significant challenges, exacerbated by the device\u2019s reliance on voice commands and a single physical button for control. The cumbersome user interface and erratic responses further compounded the operational difficulties, making everyday tasks like skipping songs unnecessarily complex. Such operational hurdles detract from the user experience and limit the R1\u2019s practicality in real-world scenarios.\\n\\n### Looking Ahead\\n\\nAs the Rabbit R1 navigates its early stages of market penetration, critical evaluations of its performance highlight areas for improvement and innovation. The device\u2019s affordability and open-source software present opportunities for future enhancements and refinements that could address its current shortcomings. While the R1\u2019s initial reception has been mixed, its potential to evolve into a more robust AI assistant remains a compelling prospect for tech enthusiasts and consumers alike.\\n\\n*Image/Photo credit: source url*",
        "published_at": "2024-05-01"
      },
      {
        "title": "The UX Fails of AI Tech: Rabbit R1 & Humane AI Pin",
        "url": "https://www.youtube.com/watch?v=0MsLtAQaiDU",
        "snippet": "{ts:0} all right rabbit R1 the I canot device I cannot access your calendar on the R1\\n{ts:7} device can I assist with something else I cannot send emails I am not able to read the text in the image out loud I\\n{ts:13} cannot determine the exact length of the reflecting pool but cannot identify or name any individuals but I cannot\\n{ts:20} generate audio or speak the text I cannot determine or state how much the energy drink costs I cannot open door\\n{ts:26} Dash on the R1 device I cannot open YouTube on the this could be for a lot of different reasons it could be\\n{ts:32} connection issues because Cloud connection is massive here it could be time consumption of the ask it could be\\n{ts:40} that the user didn't set up it right and this is exactly the expectation for these type of devices where we think\\n{ts:46} we're going to make something if a person doesn't want to use it certain way or if they are using it a different\\n{ts:52} way or giving some sort of feedback that it doesn't work it's user problem a to provide specific directions I cannot set\\n{ts:59} time if you need a reminder you can save a note in the rabbit hole I cannot for the... {ts:139} them would be challenged today in this very day is the IM maturity of a technology the delays the feedback or\\n{ts:148} lack of a feedback or even focus focusing or over focusing on the feedback instead of\\n{ts:153} affordances is a massive issue poor variability again massive this is ux part right as well because you need to\\n{ts:162} wear certain things to be able to pull it off not from fashion sense but from very logistical sense you also probably\\n{ts:170} need to consider if it's hidden or like at what angle and things of that nature this is ergonomics and this is human\\n{ts:177} factors it's how the actual humans would use a newly built device free previous experience I think everybody had\\n{ts:185} experience by now with Alexa Google Assistant I don't know what it's called anymore cuz I haven't tried it in so\\n{ts:191} long and it's telling as well you obviously your expectations are built up upon that too and anything which\\n{ts:198} requires Hardware which is super difficult as it is plus Taps into that existing interaction uh methods and\\n{ts:207} technology and the expectations from the Behavior side informs the attitudes from a consumer you always want to make it... {ts:214} better and it isn't there is massive delays and delays always mean bad design there has to be even if a feedback\\n{ts:223} giving a loader or telling that it's going to take a few minutes is way too long especially for a simpl s tasks for\\n{ts:230} it to be desirable complexity and trustiness this is another one it will be possible to customize our experience\\n{ts:238} with blah blah blah blah blah blah same as rabbit R1 you almost have to do an extra step to onboard yourself and there\\n{ts:245} are even demos of rabbit R1 where people were basically are told no by device your calendar on the R1 device can I\\n{ts:254} assist with something else I cannot send emails I am not able to read the text in the image out loud I cannot determine\\n{ts:261} the exact length of the reflecting pool but cannot identify or name any individuals but I cannot generate audio\\n{ts:267} or speak the text I cannot determine or state just not set up and if a device even if\\n{ts:273} my let's say a smartwatch whatever tells me hey you have to download an app or you have to use something else for me to... {ts:279} work this is a big ask it's a probably one of the biggest asks which you need to design for very very carefully you\\n{ts:286} know you could argue that it's the only way to do so today but in that case it's just isn't ready for the market it's\\n{ts:294} still at that kind of like a proof of concept State it's very clear that to adopt it for actual War a person has to\\n{ts:301} want it so bad that they're going to force themselves to create habits to practice it and use it because the\\n{ts:307} interaction is so limiting Alexa and others are used generally in homes where a certain level of privacy exists not\\n{ts:314} the case of these devices not to mention the issue of data collection and privacy that's true Kevin but also to challenge\\n{ts:320} you a bit I think both of them are coming with privacy first I don't know how much of it is marketing but at least\\n{ts:326} on their websites or at least one of those value ads quote unquote features they are stating that the privacy and\\n{ts:335} and data security is up most priority that's like a number one thing basically I think both of them at least rabbit are... {ts:471} or templates or boiler plates of what we had to actually create that you know ID or industrial design the actual design\\n{ts:477} engineering for this Sim ation and things of that nature they obviously had some sort of Ip behind it before they\\n{ts:483} produced and launched it the actual llms and software obviously took a while and I'm think they are still on that Journey\\n{ts:490} too for obvious reasons to make it right it's $199 per device one off and this is\\n{ts:497} something which I discussed with Dan saffer an experience design podcast make sure to check it out because it's\\n{ts:503} dedicated on design for AI and I think one of the things which he highlighted was the actual visibility things but\\n{ts:510} viability more so generative AI type of services is cheap for you as a user but it's not cheap to run for the maker this... {ts:517} is the invisible part which nobody thinks about because to actually sustain that and to tell a person that whenever\\n{ts:524} you want something you can ask that rabbit R1 and it's going to use the generative AI model and it's going to\\n{ts:529} use cloud-based interfacing and it's going to exchange the data life is a big promise and a big bat to take because\\n{ts:537} someone has to pay for it you should pay2 00 bucks you likely are paying less for the device and software you they\\n{ts:545} basically are going in debt until they can entify it just like let's say any other service like uber was so cheap now\\n{ts:553} it is not because over time they had to get that money back like what would be the future cost of it and you could\\n{ts:559} argue why would I care if I'm ux designer you should care a lot because that's exactly what ux strategy is like\\n{ts:565} you have to care because people are going to ask it like the user who's going to adopt it is going to ask why is\\n{ts:571} it so cheap and is it going to be free as a go because that... 's what's going to require a commitment and a lot of a\\n{ts:577} people are speculating at that the stated plan is that there will be a store where users can upload the rabbit\\n{ts:585} AI macros they create and then other users will pay to purchase those so there's some sort of peer-to-peer\\n{ts:591} exchange and Marketplace type of mechanics where people going to buy things from each other I know this is a\\n{ts:598} designer just conceptualizing it but saying this should have been an app spot on it could have been version one could\\n{ts:606} have been an app to test with a superb app and then introducing Hardware as a secondary device once the actual\\n{ts:613} Hardware can keep up with it and there is enough ability to Port building in the world is\\n{ts:619} 2717 ft and in that case what is the actual point and I'm asking everyone on the chat what is the actual point of a\\n{ts:626} hardware if you could actually container it and keep it just as a software I know it's less flashy it doesn't look as good\\n{ts:634} it doesn't not going to get as much attention and perhaps VC money too few affordances especially for someone who... {ts:640} would adopt it outright like people have to go through so many trials and errors as evident from those demos to figure\\n{ts:647} out how to use this or what's a what's what we can achieve it and what we absolutely cannot achieve it what's the\\n{ts:653} spectrum of the range of actual interactions which would give some sort of feedback it's too early this is the\\n{ts:659} the PO level hardware and Engineering if you ask me and ux for that matter R1 said it wanted to move on from App based\\n{ts:670} devices yeah they wanted to but you have to do it right d it's really good point like you know the intention is clear\\n{ts:677} like you can't argue with that we definitely had good Vision but this is not a product it's still a prototype of\\n{ts:685} what it could be it's not experience ready it's made as if it's a software project and as if money is endless and\\n{ts:694} as such we can make more changes and as if you're going to do countless iterations but having worked with\\n{ts:700} Hardware which is another spin Hardware is extremely hard and generations of Hardware if you take this fat pan\\n{ts:710} amazing pen by the way highly recommend it it",
        "published_at": "2024-05-28"
      },
      {
        "title": "Challenges Faced by the Rabbit R1 AI Gadget",
        "url": "https://aibrew.news/articles/challenges-faced-by-the-rabbit-r1-ai-gadget",
        "snippet": "# Challenges Faced by the Rabbit R1 AI Gadget\\n\\nThe Rabbit R1, an AI gadget, struggles to provide timely and accurate responses, leading to frustration and limited utility for users, despite its stylish design and interesting features.Tweet\\n\\n6.0Flakes score\\n\\nImpact\\n\\n4\\n\\nClarity\\n\\n7\\n\\nEthical\\n\\n2\\n\\nInfluence\\n\\n3\\n\\nRelevance\\n\\n3\\n\\nEngagement\\n\\n2\\n\\nInnovation\\n\\n5\\n\\nCredibility\\n\\n6\\n\\nRead moreSources\\n\\n## Takeaway points by AI\\n\\n- The Rabbit R1 AI gadget often fails to deliver timely and accurate responses, reducing its effectiveness.\\n\\n- Users experience frustration due to the device's performance issues, despite its appealing design and features.\\n\\n- The gadget's limitations in utility are significant, overshadowing its aesthetic and innovative aspects.\\n\\n- Investigations into the device's performance suggest improvements in AI algorithms could enhance functionality.\\n\\n- The article implies that addressing these technical shortcomings is crucial for increasing user satisfaction and device adoption.",
        "published_at": "2024-05-03"
      },
      {
        "title": "Rabbit r1 - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Rabbit_r1",
        "snippet": "The **Rabbit r1** is a personal assistant device developed by tech startup Rabbit Inc and co-designed by Teenage Engineering. It is designed to perform various functions, including browsing the web and playing music, using voice commands and touch interaction, allowing AI to be used to provide services commonly associated with smartphones, such as ordering food delivery. The device runs an operating system based on Android, and its AI services are powered by ChatGPT.\\n\\nRabbit Inc was started by Jesse Lyu Cheng.\\n\\n## Hardware\\n- **Display**: A 2.88-inch touchscreen for interactive user input.\\n- **Input**: push-to-talk button to activate voice commands; scroll wheel; Gyroscope; Magnetometer; Accelerometer; GPS.\\n- **Camera**: 8 MP single camera, with a resolution of 3264x2448, allowing for the connected external AI to use computer vision.\\n- **Audio**: Equipped with a speaker and dual microphones for audio interaction.\\n- **Connectivity**: Supports Wi-Fi and cellular connections via a SIM card slot to access internet services.\\n- **Processor**: Runs on a 2.3GHz MediaTek Helio P35 processor.\\n- **Memory**: Contains 4GB of RAM for operational tasks.\\n- **Storage**: Offers 128GB of internal storage for data.\\n- **Ports**: Utilizes a USB-C port for charging and data connections.... ## Software\\n\\nThe Rabbit r1 runs on Rabbit OS, based on the Android Open Source Project (AOSP), specifically version 13. Lyu has claimed that Rabbit OS runs with a \\\"very bespoke AOSP.\\\"\\n\\nThe device employs a large action model (LAM) designed to perform actions and assist with tasks like web searches, streaming music, and transportation services. Perplexity.ai, an AI search engine, is one of the Large Language Models (LLM) used to respond to user queries and execute commands. The personal assistant is also capable of various actions such as ordering a cab or playing music from Spotify. This is through the \\\"connections\\\" system on the account management site, which the assistant calls \\\"rabbits\\\".\\n\\nRabbit issued 15 software updates within the first four months after releasing r1. On July 11, 2024, Rabbit launched the \\\"beta rabbit\\\" advanced search and conversation assistant to \\\"give more thoughtful responses to complex questions that require multiple steps of research and deeper reasoning\\\".... ## Reception\\n\\n### Funding\\n\\nRabbit raised $20 million in funding from Khosla Ventures, Synergis Capital and Kakao Investment in October 2023. The company announced an additional $10 million in funding in December 2023.\\n\\n### Sales\\n\\nFollowing its announcement at the 2024 Consumer Electronics Show, 130,000 units were sold. On August 13, 2024, Rabbit announced that sales of r1 had expanded to the entire European Union (except Malta) and United Kingdom. On August 21, 2024, sales of r1 expanded to Singapore.\\n\\n### Reviews\\n\\nThe r1 was met with strong criticism immediately after Rabbit began shipping the device. Some reviews questioned what the device was able to do that a smartphone could not, while comparing it to the similar Humane Ai Pin. YouTuber Marques Brownlee called the device \\\"barely reviewable\\\". *Android Authority'*s Mishaal Rahman managed to install Rabbit r1's software on a Pixel 6a smartphone, after a tipster shared an APK file. *The Verge* echoed the claims made by Rahman. In response, Lyu published statements confirming its use of Android, but denying that the r1 is an Android app. Mashable called its Vision features impressive, but said that \\\"these praise-worthy features are overshadowed by buggy performance\\\".* Ars Technica* wrote a blog post claiming \\\"the company is blocking access from bootleg APKs\\\". TechCrunch gave a slightly more positive review, calling the device a \\\"fun peep at a possible future\\\", but could not \\\"advise anyone to buy one now.\\\"\\n\\nShortly after the launch of r1, Rabbit began a weekly cadence of software updates to address much of the criticism from the early reviews, including \\\"battery and GPS performance, time zone selection, and more\\\". Digital Trends said the Magic Camera feature \\\"takes the most mundane, ordinary, and badly composed photos and makes something fun and eye-catching from them.\\\" Mashable said the \\\"beta rabbit\\\" feature \\\"makes Rabbit R1 more conversational and intelligent\\\".... ## Controversies\\n\\n### GAMA project\\n\\nRabbit Inc has garnered attention due to allegations surrounding its funding and the company's past projects. The company came under scrutiny when Stephen Findeisen, known as Coffeezilla on YouTube, published a video in May 2024, alleging that Rabbit Incorporation was \\\"built on a scam\\\". Rabbit Incorporation, initially named Cyber Manufacturing Co, rebranded just two months before launching the Rabbit R1. The company, under its former name, raised $6 million in November 2021 for a project called GAMA, described as a \\\"Next Generation NFT Project.\\\" Jesse Lyu, the CEO of Rabbit Incorporation, referred to GAMA as a \\\"fun little project.\\\"\\n\\nCoffeezilla, who investigates influencer scams, highlighted old Clubhouse recordings of Jesse Lyu discussing the GAMA project. In these recordings, Lyu emphasized the substantial funding behind GAMA and its potential to be a revolutionary, carbon-negative cryptocurrency. Coffeezilla questioned the whereabouts of the funds raised for GAMA, estimating that approximately $1 million in refunds to investors remained unresolved. He suggested that the rebranding to Rabbit Incorporation and the shift to developing the Rabbit R1 were attempts to divert from the GAMA project's issues.\\n\\nIn response to Coffeezilla's inquiries, Rabbit Incorporation stated that the $6 million raised was used for the GAMA project. The company said that NFTs cannot be refunded unless the owner agrees to \\\"burn\\\" them on the blockchain. Rabbit Incorporation also said that the GAMA project was open-sourced and returned to the community, aligning with community feedback. They also mentioned that efforts to buy back NFTs were made to counteract malicious trading and maintain market stability.... ### Security\\n\\nIn June 2024, Engadget reported that the Rabbitude team, a community reverse engineering project, had gained access to the r1's codebase revealing that r1's software contained several hardcoded API keys in its code for ElevenLabs, Microsoft Azure, Yelp, and Google Maps, potentially allowing unauthorized access to r1 responses, including those containing the users' personal information. For a short time, Rabbit immediately began revoking and rotating those secrets and confirmed that the code was leaked by an employee who had \\\"been terminated and remains under investigation\\\".\\n\\nIn July 2024, the company revealed that all user chats and device pairing data were logged on the r1 with no ability to delete them. This meant that lost or stolen devices could be used to extract user data. The company stated that it addressed the issue by introducing a factory reset option and limited the data stored on the r1, as well as preventing paired devices from reading data.\\n\\n## See also\\n- Humane Inc. \u2013 maker of the AI Pin consumer artificial intelligence device\\n\\n## References\\nCategories: - Consumer electronics\\n- Machine learning\\n- Applications of artificial intelligence\\n- Android (operating system) devices",
        "published_at": "2024-01-19"
      },
      {
        "title": "Why did the Rabbit R1 struggle to deliver?",
        "url": "https://dataconomy.com/2024/09/26/why-did-the-rabbit-r1-struggle-to-deliver/",
        "snippet": "The Rabbit R1 that was picked as a revolutionary AI gadget after its splash at CES 2024 turned out to give a painful lesson in the AI hardware dynamics. Although R1 started well with a vision announced by its founder Jesse Lyu this social media application has stagnated, and as of five months after its launch only 5,000 of the registered 100,000 users actually use R1.\\n\\nSpeaking with\\n\\n*Fast Company*, Lyu admitted that the device was rushed into the market even when it cannot fully compete with major giants such as Apple or Google. However, the false start and the string of let downs and technical issues have turned Rabbit R1 into one of the biggest AI hardware failures of the year.... The inability of the Rabbit R1 to succeed speaks volumes of the state of the AI hardware segment. Another problem was that it never came close to fulfilling the functions just announced, including its massively publicized Large Action Model (LAM). At CES, the R1 was presented as a universal tool that must solve all sorts of problems \u2014 from logging into a website to booking a flight or ordering food \u2014 with voice commands only. However, the reviewers and early users reported that these functions were either not fully implemented, or buggy.... In response the Rabbit team had to dedicate time to address these issues and released 16 firmware updates to try and fix the issues. Such updates were made to try and fix the failures of the R1 but for many users the harm was already done. During the first months following application release, many early users got disappointed and the number of DAU significantly declined. The problem is Rabbit R1 has no unique market to target because the device is complicated and needs time in order to learn commands, while smartphones are also incorporating AI capabilities as their features, which in effect threaten the existence of Rabbit R1.... ## A broader struggle in AI hardware\\n\\nCurrently, Rabbit R1\u2019s difficulties are not unique \u2013 this issue lies at the heart of many AI hardware development processes. As corporations strive to capture what the future of intelligent devices will be, they are faced with incredibly difficult and complex practical and infrastructural problems of how to implement encasements that encompass all of form and function while optimizing for the user\u2019s experience.\\n\\nAnother fine example includes the recent case of AI Pin developed by the Humane to remove all the wrong pins but was also a flop. Originally capitalized at $850 million, Humane\u2019s product was being brought back more than it was being sold. Same as in the case of Rabbit R1, Humane\u2019s AI Pin promised many things but could not live up to expectations.... ## Can the R1 be redeemed?\\n\\nDespite the bad experience with Rabbit R1 on its inception, Jesse Lyu seems hopeful for the automobile. The company is still refining Large Action Model; the next version of LAM is set to go live in beta on October 1. The author likes to think that this update will fix many of the problems users encountered with the first release. The LAM has also been upgraded, with LYu\u2019s team working on allowing it to move through websites and complete tasks such as adding products to a cart or even booking a flight.\\n\\nAs per the feedback information received from the beta users, the new LAM system of WIP is slower, systematic and buggy but this is an improvement from the previous system.... However, challenges remain. This leads to the third problem of the LAM system, along with its strong dependency on working with third-party websites, there are always questions regarding compatibility. LAM potentially leaves Rabbit R1 vulnerable to being shut down if large sites such as amazon or google decided to block the LAM from accessing their systems.... It remains to be seen as to whether standalone AI gadgets such as the Rabbit R1 can effectively challenge AI built into smartphones. Smartphones such as iPhone 16 and Sumsung S24 already come with advanced AI abilities which can perform most of the LAM tasks which Rabbit boasts of. Lyu has also reaffirmed that Rabbit is not simply about phones but has aspirations of a standardized system that should be installable with equal ease in Linux, Windows, macOS and so on. But if consumers are indeed willing to care enough as to invest in another device, which is the portable smart speaker at that, let alone when they already have in their hands AI-powered smartphones that also boast significant levels of audio quality?... In conclusion, Rabbit R1\u2019s evolution is oriented to the formation of turning points inherent in the formation of a new industry. Despite the firsthand experience in overcoming criticism as well as defending themselves from the criticism Lyu and his team crafted a tough path towards rehabilitation and redemption. The AI hardware industry is full of potential but is also full of risks; there are pitfalls that, when properly understood, should be avoided in practice but are currently causing tension between practicality and idealism.\\n\\n**Featured image credit: Rabbit**",
        "published_at": "2024-09-26"
      },
      {
        "title": "Apple Intelligence - Good or Worthless?",
        "url": "https://www.youtube.com/watch?v=Vih8v34uJXA",
        "snippet": "##### May 01, 2025 (0:11:59)\\nApple Intelligence Features, Wins, Losses and What's Next - Apple Intelligence promised to bring the best version of AI with privacy in mind to iOS 18 and iPhone.  Apple delivered quite a few Apple Intelligence features with iOS 18.1, iOS 18.2, iOS 18.3 and iOS 18.4, but not everything promised.  In this video we recap the Apple Intelligence Features, Device Support, What Feature I actually use and talk about what is next for Apple Intelligence in the future using iPad Pro M4 and iPhone 16 Pro Max.  #iOS18 #Apple #iPhone\\n\\n\\n\u231a\ufe0f Watch Band I am using - https://www.tkqlhce.com/click-100632277-15143421\\n\\nRecent Videos:\\niOS 18.4 is Out! - What\u2019s New? - https://youtu.be/ZYMAJRefv_U\\niOS 18.3.2 is Out! - What\u2019s New? - https://youtu.be/fjoT94HWyPk\\niOS 18.3.1 is Out! - What\u2019s New? - https://youtu.be/hyYcHyh27Dc\\niOS 18.3 is Out! - What\u2019s New? - https://youtu.be/LqhJUiDJ5oQ\\niOS 18.2 is Out! - What\u2019s New? - https://youtu.be/GerQekxzY-Y\\niOS 18.1 is Out! - What\u2019s New? - https://youtu.be/5-Hj5CFROIk\\niOS 16.1 Sequoia is Out! - What\u2019s New? - https://youtu.be/IDCAbP1R7Y8\\niOS 17.6.1 Re-Release is Out! - What\u2019s New? - https://youtu.be/P5iAfkaSI6Q\\n100% Battery Health Has Changed - Dropping Fast - https://youtu.be/o7dwwY6tNkw... {ts:0} Hi everyone, Aaron here for zolotete and Apple intelligence has been one of the\\n{ts:4} biggest frustrations in recent memory from Apple for multiple reasons. I thought we would go over the wins and\\n{ts:9} losses of Apple Intelligence so far and what to expect in the future. Now, the first big disappointment with Apple\\n{ts:15} Intelligence is the devices that it actually supports. It only supports iPhones with 8 GB of RAM. That means if\\n{ts:22} you had an older phone that supports iOS 18 with iPhone XS Max or something else, even the iPhone 15, you don't get the\\n{ts:30} options and you never will, unfortunately. So, that's something that Apple decided based off of 8 gigs of RAM\\n{ts:36} and many of those features will never see older devices. That's a bit unfortunate, forcing people to upgrade\\n{ts:42} if they want those devices. Also, iPhone 16 was supposedly designed for Apple intelligence. However, it didn't get\\n{ts:49} many of those features when it first was released. And the overall sort of release was odd with this. If we go to... {ts:55} the iPhone 16 Pro, for example, you'll see that it says built for Apple Intelligence now, but no longer designed\\n{ts:61} for Apple Intelligence. So, they're changing some of the marketing, and again, this is due to some of the lack\\n{ts:66} of features. Now, at WWDC 2024, Apple showed some pretty impressive demos of what things could do, such as photos\\n{ts:74} cleanup, major Siri upgrades, and much more. I thought we'd recap the features quickly, go over what I actually use and\\n{ts:81} what I don't use and what we can expect. Now, Apple Intelligence started with iOS 18 and the overall feature roll out in\\n{ts:88} stages instead of releasing all at once. With Apple Intelligence, the first features had to do with things such as\\n{ts:94} call recording. However, this isn't technically an Apple Intelligence feature, but Apple originally listed it\\n{ts:100} on their website with Apple Intelligence. So whether or not it really is Apple intelligence, it's\\n{ts:105} probably just recording on the phone. But either way, they listed it that way. Of course, the biggest change was Siri... {ts:328} display performance and more. But sometimes you have to check this and make sure it's accurate. Of course, we\\n{ts:333} can create our own images as well using image wand here. You could circle something that's in the frame and create\\n{ts:338} something or you can just add it directly here saying describe an image. And you'll see again it's very buggy and\\n{ts:346} something that they keep having issues with. And this is throughout all versions of iOS. So, if we try it again,\\n{ts:351} let's just put something here. We'll circle it. And even though there's not anything here, we can describe a change\\n{ts:356} or an image. And again, it doesn't work. So, there's all sorts of odd bugs, but again, you could circle an image that's\\n{ts:362} in here already and then create something. And then they updated things such as priority notifications as well\\n{ts:368} as type to Siri in the control center. So, different options they've added throughout the time of having this. So,\\n{ts:373} if you want to add the controls for type to Siri, Apple intelligence with talk to Siri and visual intelligence buttons as... {ts:511} it look as real as you want or look like a sketch or a cartoon, Apple doesn't allow for you to change that. So\\n{ts:518} basically what you get is what you see here. Some of them look good, such as this lighthouse, but it doesn't really\\n{ts:524} show anything realistic. And that's their point, I'm sure, but it's something that I don't find very useful\\n{ts:530} for myself. Let me know if you think it's useful or you use it or do you use maybe chat GPT and their options as\\n{ts:536} well. Of course, Apple promised a lot more that isn't there yet. Siri 2.0 is what most people were excited about\\n{ts:543} where it could understand context of what's going on on your phone privately and then sort of give you information\\n{ts:549} based on that. Apple's idea for Siri with context was pretty great. Maybe you could find out when you need to pick up\\n{ts:555} your mother from the airport and it would understand the airline they're coming in on. Check if there's any\\n{ts:560} delays, what gate they're arriving at, and also know where you... 're located and how long it takes you to get to the\\n{ts:566} airport based on local traffic and tell you what time to leave. All of that information could work privately, and\\n{ts:572} it's something that looked great, but we haven't seen that work yet. So, those are things we could look forward to in\\n{ts:577} the future that look to be delayed till at least iOS 19, either in the fall release or possibly not until 2026, as\\n{ts:584} late as iOS 19.4 or later. So, these are things that Apple promised that just never arrived. I understand they're hard\\n{ts:591} to make and sort of develop, but you'll see other companies using servers to do this with more sort of horsepower behind\\n{ts:598} them with server farms and everything else. And we haven't seen that because of privacy and other concerns. Now, I\\n{ts:604} really appreciate the privacy concerns and the focus on that. But again, I don't think people care as much as long\\n{ts:610} as it's maybe tied to an account and others can't see it. So, I'm not sure. It depends on the person, of course. But... {ts:616} that would be great to have Siri with context. And we haven't seen it yet. Of course, device support is definitely\\n{ts:621} something people are sad about and angry about, even hoping it comes to older devices, and it's just not going to come\\n{ts:627} to older devices as it requires more RAM. In fact, future updates are expected to have iPhone 17 with at least\\n{ts:634} 12 gigs of RAM. So, I don't think we're going to see it on older devices. Now, Apple could have some great ideas in the\\n{ts:639} future for Apple Intelligence and hopefully makes up for this at WWDC 2025, but at this point, we're pretty\\n{ts:646} disappointed. They haven't really given everything they've promised. And many people are angry that they bought their\\n{ts:652} iPhone 16 or 16 Pro for Apple intelligence features that aren't there yet. Many of them are, but again, it's\\n{ts:658} not rolled out around the world yet. So, lots of big losses this year when it comes to the overall disappointment of\\n{ts:663} Apple Intelligence. So, I thought we",
        "published_at": "2025-05-01"
      },
      {
        "title": "An Honest Review of Apple Intelligence... So Far",
        "url": "https://www.youtube.com/watch?v=haDjmBT9tu4",
        "snippet": "## Marques Brownlee\\n##### Nov 22, 2024 (0:17:49)\\nReviewing the Apple Intelligence features out so far. Not included in this video: Natural language search in Photos, memory movies, Siri product knowledge and context memory, Mail summaries, Writing Tools Describe Your Change, Image Wand.\\n\\nGet both the MKBHD Carry-on & Commuter backpack together at http://ridge.com/MKBHD for 30% off\\n\\nThat Wallpaper! From outrunyouth: https://geni.us/lER207\\n\\nMKBHD Merch: http://shop.MKBHD.com\\n\\nTech I'm using right now: https://www.amazon.com/shop/MKBHD\\n\\nIntro Track: Jordyn Edmonds http://smarturl.it/jordynedmonds\\nPlaylist of MKBHD Intro music: https://goo.gl/B3AWV5\\n\\niOS 18.2 features shown here are in developer beta, so not completely finalized.\\n\\n~\\nhttp://twitter.com/MKBHD\\nhttp://instagram.com/MKBHD\\nhttp://facebook.com/MKBHD... {ts:3} All right. We got to talk about Apple intelligence.\\n{ts:5} So, Apple's made this promise, this huge thing is coming that's going to change everything across their whole lineup. They've been talking about it for a while, and I think that promise is starting to fade.\\n{ts:16} This was first announced at WWDC 2024. That was nearly six months ago, and it's still not completely out yet. The new iPhone's launched in September with exactly zero\\n{ts:26} Apple intelligence features, but then some software updates have started to push out, and eventually it's supposed to be finished and in everyone's hands by March 2025. That's a lot of buildup.\\n{ts:38} So what I want to do now is review every single Apple intelligence feature that's out so far. And then also get into whether the promise\\n{ts:47} that they're actually making is even good in the first place. So first up, writing tools. So all of these features, unless otherwise specified, are on iPhone, iPad and Mac.\\n{ts:57} So no Apple Intelligence features at all on the Vision Pro. their most faturistic platform. That's already kind of fascinating.\\n{ts:65} But the writing tools, you may have heard about these since they... {ts:199} So no matter how long or how short the messages are, whether it's just a text or maybe a group chat has absolutely blown up and you missed 100 messages. It's going to try to summarize all that\\n{ts:209} into one or two lines. The thing is, once I enable it and start using it, it basically seems like the notifications that I'm getting are almost never benefited\\n{ts:218} from being summarized or shortened. Like I've never gotten four text messages that are perfectly summarized into a single one.\\n{ts:228} And I'm sure it's possible There are going to be some instances where it works for people, but it's not just me. I've seen lots of examples online and there's plenty of memes, too, of Apple's\\n{ts:235} notifications, summaries doing some sometimes hilarious work, some brutal stuff. So it works and I guess it's good for a laugh once in a while, but yeah, this is a feature I straight up turned off.\\n{ts:246} Then Jen Moji. So, okay, believe it or not, there was some hype for this one.\\n{ts:252} And once again, it's basically exactly what it sounds like. It's it's letting you generate any emoji using AI. Anything you want.... {ts:389} a chef hat and some fireworks to something, then it will be a little more likely to actually pull through for you. So\\n{ts:396} yeah, good thing it says it's in beta and may create unexpected results. This is yet another app that they've added to my phone that I predict that I will probably never use again after making this video.\\n{ts:407} So then, priority notifications. So, okay, now, this is one that I think had some promise, or at least I'm in the target demographic for it because\\n{ts:415} as an iPhone and Android user, you start to notice that Apple's weakness has, for a long time been notification management. If it was just kind of had a fire hose and notifications coming in all the time.\\n{ts:425} So priority notifications surfaces certain notifications above the rest when you're in a focus mode that reduces notifications. But this should also work in the mail app to\\n{ts:435} put AI identified high priority messages up at the top plus some other categories. So if you use the default mail app, which I don't, but a lot of people do, then this could be helpful. Something Gmails had for many years.\\n{ts:447} And the reduced notifications mode also specifically tries to do a good job of only letting important notifications through, but keeping the rest quiet. So then the Photos app... {ts:703} has a lot more capabilities and maybe even a little bit more trust these days than Bixby had back then, and it's certainly more well integrated. But yeah, so it's not something mind blowing or groundbreakingly\\n{ts:714} new, but it is ideally more accurate and more capable than before. Maybe they're going to continue to build on top of this in the future. But then there is Chati PT integration, the sort\\n{ts:723} of last but not least new thing, that's Siri, worse with ChatPT. I think a lot of people thought there was a lot more to Siri, like right off the back because it has this new animation. And you see the new Siri animation so you think it's the new Siri, but\\n{ts:736} most of the new Siri stuff isn't here yet. But the chi PT stuff is. So if you ever make a request or ask a question that's\\n{ts:743} out of the normal scope of Siri, maybe asked for a recipe or you ask for it to make a trip itinerary or something big, then it recognizes it and it can prompt you\\n{ts:753} if you want to ask Chatchi PT instead, and if you confirm, then it pulls fromhatchi PT to respond. This is all free.... {ts:761} You don't need an account for this. Apple has promised all sorts of masking so your data is not used for training models. Open AI doesn't get to collect any of this information about you through the requests.\\n{ts:771} But you can also sign into your chatPT account if you want to keep a history of your queries or use higher end models or even go over the daily limit of free queries.\\n{ts:782} There's even actually a button to upgrade to chat GPT plus built into iOS now, so it's pretty well considered. So yeah, the new Siri animation might be fooling some people, but really it's\\n{ts:792} other than being able to type to Siri more easily, there's really not a whole lot actually new yet with Siri. But that brings me to the rest of the things that aren't here yet\\n{ts:802} still, that are coming soon with software updates. That list is right here. There are more Apple intelligence features that are in the works coming soon.\\n{ts:812} And honestly, Siri is the main one I'm interested in because it's supposed to be able to take in app actions. It should be able to reach into apps and take action inside of\\n{ts:821} them, which I think could be awesome. I think developers could all update their apps to work... {ts:828} really well with it, and it could be really useful. It could differentiate Siri to actually make it useful again. But yeah, that's still coming.\\n{ts:836} But yeah, then from there, my take is the rest of the AI stuff really not super amazing or compelling to me just to be real.\\n{ts:846} Like the writing tools, that seems like a nice safe use of generative AI. That's the thing they're sort of talking about the most, but I don't even find myself needing to rewrite things that often.\\n{ts:856} And like I said, I'm not in the target demographic to use the image playgrounds all that much or genis all the time. The visual intelligence is definitely super useful like three\\n{ts:865} or four times a year for me, like when some interesting plant or dog or whatever is in front of me and I want to just figure out what it is. But that's actually funny.\\n{ts:873} Do you remember the clip from the Apple key note of that person who walks up to a dog? And instead of asking the person walking the dog, what kind of dog it is, they just go, hey, can I take a picture of your dog?... 've seen. It's better than Google's.\\n{ts:1034} It's really impressive. I think the visual intelligence stuff has potential to be really good, but honestly, the best thing I think we've gotten from Apple Intelligence,\\n{ts:1042} because all this stuff is running on device, is bumping up the base memory in everything. There's more ram in every iPhone now and the bass memory on every Mac is 16 gigs now, which made the bass Mac mini an incredible deal.\\n{ts:1054} So shout out to Apple Intelligence for that. Either way, hopefully a lot more coming.\\n{ts:1060} Thanks for watching. Get you guys the next one. Peace.",
        "published_at": "2024-11-22"
      },
      {
        "title": "Apple Intelligence",
        "url": "https://www.apple.com/apple-intelligence/",
        "snippet": "# Apple Intelligence\\n\\nAI for the rest of us.\\n\\nBuilt into your iPhone, iPad, Mac, and Apple Vision Pro* to help you write, express yourself, and get things done effortlessly.** Designed with groundbreaking privacy at every step.\\n\\nApple Intelligence simplifies your everyday communication and helps you stay focused. Communicate across languages with Live Translation. Strike just the right tone with Writing Tools. And minimize distractions with prioritized notifications.\\n\\nCreate fun, original images with Image Playground right in your apps or its own dedicated app. You can try out styles like animation, illustration, and sketch and discover additional ChatGPT styles. Turn a rough sketch into a related image that complements your notes with Image Wand. Craft a custom memory movie in the Photos app. And make images inspired by your friends using Genmoji.\\n\\n3\\n\\nLearn more about what\u2019s in front of you, whether you\u2018re out and about or using your iPhone. Instantly turn a poster into a Calendar event. Summarize what you\u2019re viewing. Ask questions, like recipe ideas for what\u2019s in your fridge. And search seamlessly across your favorite apps, like finding where to buy a cool outfit you see online.\\n\\n5\\n\\nSiri can assist you in everyday moments to get tasks done. You can speak or type to Siri whenever you need it. It can help you learn something new about your Apple products, and can tap into ChatGPT\u2019s broad world knowledge when appropriate. Plus, Apple Intelligence comes to the Shortcuts app to accelerate your workflows.... Apple Intelligence is designed to protect your privacy at every step. It\u2019s integrated into the core of your iPhone, iPad, and Mac through on-device processing. So it\u2019s aware of your personal information without collecting your personal information. And with groundbreaking Private Cloud Compute, Apple Intelligence can draw on larger server-based models, running on Apple silicon, to handle more complex requests for you while protecting your privacy.\\n\\nWith ChatGPT from OpenAI integrated into Siri, Writing Tools, visual intelligence, Image Playground, and Shortcuts, you get even more expertise when it might be helpful for you \u2014 no need to jump between tools.\\n\\nYou control when ChatGPT is used and will be asked before any of your information is shared. Anyone can access ChatGPT for free, without creating an account. ChatGPT subscribers can connect accounts to access paid features within these experiences.\\n\\nFind the right iPhone, iPad, or Mac for you.\\n\\nInnovative design for ultimate\\n\\nperformance and battery life.\\n\\nThe thinnest iPhone ever.\\n\\nWith the power of pro inside.\\n\\nEven more delightful.\\n\\nEven more durable.\\n\\nAmazing performance.\\n\\nDurable design.\\n\\nEverything you love.\\n\\nIncluding the price.\\n\\nThe ultimate iPad experience with the\\n\\nmost advanced technology.\\n\\nSerious performance in a\\n\\nthin and light design.... The full iPad experience in\\n\\nan ultraportable design.\\n\\nM4 chip\\n\\nStrikingly thin and fast so you can\\n\\nwork, play, or create anywhere.\\n\\nM5, M4 Pro, or M4 Max chip\\n\\nThe most advanced Mac laptops for\\n\\ndemanding workflows.\\n\\nM4 chip\\n\\nA stunning all\u2011in\u2011one desktop for\\n\\ncreativity and productivity.\\n\\nM4 or M4 Pro chip\\n\\nThe mini-est, most affordable Mac\\n\\nwith mighty performance.\\n\\nM4 Max or M3 Ultra chip\\n\\nPowerful performance and extensive\\n\\nconnectivity for pro workflows.\\n\\nM2 Ultra chip\\n\\nA pro workstation with PCIe expansion for\\n\\ndemanding workflows.\\n\\nThe Foundation Models framework, along with App Intents, APIs, and frameworks, are built with privacy at the center. Any app can tap into the on-device models that power Apple Intelligence, and the features you build work offline. And it\u2019s all at no cost per request. App developers can easily integrate features like Siri, Writing Tools, and Image Playground.",
        "published_at": "2025-07-29"
      },
      {
        "title": "Apple Intelligence gets even more powerful with new ...",
        "url": "https://www.apple.com/newsroom/2025/06/apple-intelligence-gets-even-more-powerful-with-new-capabilities-across-apple-devices/",
        "snippet": "# Apple Intelligence gets even more powerful with new capabilities across Apple devices\\n\\nDevelopers can now access the Apple Intelligence on-device foundation model to power private, intelligent experiences within their apps\\n\\n**CUPERTINO, CALIFORNIA**Apple today announced new Apple Intelligence features that elevate the user experience across iPhone, iPad, Mac, Apple Watch, and Apple Vision Pro. Apple Intelligence unlocks new ways for users to communicate with features like Live Translation; do more with what\u2019s on their screen with updates to visual intelligence; and express themselves with enhancements to Image Playground and Genmoji.\\n\\n1Additionally, Shortcuts can now tap into Apple Intelligence directly, and developers will be able to access the on-device large language model at the core of Apple Intelligence, giving them direct access to intelligence that is powerful, fast, built with privacy, and available even when users are offline. These Apple Intelligence features are available for testing starting today, and will be available to users with supported devices set to a supported language this fall.\\n\\n\u201cLast year, we took the first steps on a journey to bring users intelligence that\u2019s helpful, relevant, easy to use, and right where users need it, all while protecting their privacy. Now, the models that power Apple Intelligence are becoming more capable and efficient, and we\u2019re integrating features in even more places across each of our operating systems,\u201d said Craig Federighi, Apple\u2019s senior vice president of Software Engineering. \u201cWe\u2019re also taking the huge step of giving developers direct access to the on-device foundation model powering Apple Intelligence, allowing them to tap into intelligence that is powerful, fast, built with privacy, and available even when users are offline. We think this will ignite a whole new wave of intelligent experiences in the apps users rely on every day. We can\u2019t wait to see what developers create.\u201d... Users can access visual intelligence for what\u2019s on their screen by simply pressing the same buttons used to take a screenshot. Users will have the choice to save or share their screenshot, or explore more with visual intelligence.\\n\\n**Apple Intelligence Expands to Fitness on Apple Watch**\\n\\nWorkout Buddy is a first-of-its-kind workout experience on Apple Watch with Apple Intelligence that incorporates a user\u2019s workout data and fitness history to generate personalized, motivational insights during their session.\\n\\n5\\n\\nTo offer meaningful inspiration in real time, Workout Buddy analyzes data from a user\u2019s current workout along with their fitness history, based on data like heart rate, pace, distance, Activity rings, personal fitness milestones, and more. A new text-to-speech model then translates insights into a dynamic generative voice built using voice data from Fitness+ trainers, so it has the right energy, style, and tone for a workout. Workout Buddy processes this data privately and securely with Apple Intelligence.\\n\\nWorkout Buddy will be available on Apple Watch with Bluetooth headphones, and requires an Apple Intelligence-supported iPhone nearby. It will be available starting in English, across some of the most popular workout types: Outdoor and Indoor Run, Outdoor and Indoor Walk, Outdoor Cycle, HIIT, and Functional and Traditional Strength Training.\\n\\nelapsed 00:00... remaining -01:16\\n\\nLive Streaming\\n\\n**Apple Intelligence On-Device Model Now Available to Developers**\\n\\nApple is opening up access for any app to tap directly into the on-device foundation model at the core of Apple Intelligence.\\n\\nWith the Foundation Models framework, app developers will be able to build on Apple Intelligence to bring users new experiences that are intelligent, available when they\u2019re offline, and that protect their privacy, using AI inference that is free of cost. For example, an education app can use the on-device model to generate a personalized quiz from a user\u2019s notes, without any cloud API costs, or an outdoors app can add natural language search capabilities that work even when the user is offline.\\n\\nThe framework has native support for Swift, so app developers can easily access the Apple Intelligence model with as few as three lines of code. Guided generation, tool calling, and more are all built into the framework, making it easier than ever to implement generative capabilities right into a developer\u2019s existing app.\\n\\n**Shortcuts Get More Intelligent**\\n\\nShortcuts are now more powerful and intelligent than ever. Users can tap into intelligent actions, a whole new set of shortcuts enabled by Apple Intelligence. Users will see dedicated actions for features like summarizing text with Writing Tools or creating images with Image Playground.... Now users will be able to tap directly into Apple Intelligence models, either on-device or with Private Cloud Compute, to generate responses that feed into the rest of their shortcut, maintaining the privacy of information used in the shortcut. For example, a student can build a shortcut that uses the Apple Intelligence model to compare an audio transcription of a class lecture to the notes they took, and add any key points they may have missed. Users can also choose to tap into ChatGPT to provide responses that feed into their shortcut.\\n\\n**Additional New Features**\\n\\nApple Intelligence is even more deeply integrated into the apps and experiences that users rely on every day:\\n\\n- The most relevant actions in an email, website, note, or other content can now be identified and automatically categorized in\\n\\n**Reminders**. **Apple Wallet**can now identify and summarize order tracking details from emails sent from merchants or delivery carriers. This works across all of a user\u2019s orders, giving them the ability to see their full order details, progress notifications, and more, all in one place.\\n\\n- Users can create a poll for anything in\\n\\n**Messages**, and with Apple Intelligence, Messages can detect when a poll might come in handy and suggest one. In addition, Backgrounds in the Messages app lets a user personalize their chats with stunning designs, and they can create unique backgrounds that fit their conversation with Image Playground.... These features build on a wide range of Apple Intelligence capabilities that are already available to users:\\n\\n**Writing Tools**can help users rewrite, proofread, and summarize the text they have written. And with Describe Your Change, users can describe a specific change they want to apply to their text, like making a dinner party invite read like a poem. **Clean Up**in Photos allows users to remove distracting elements while staying true to the moment as they intended to capture it. **Visual intelligence**builds on Apple Intelligence and helps users learn about objects and places around them instantly. **Genmoji**allow users to create their own emoji by typing a description. And just like emoji, they can be added inline to messages, or shared as a sticker or reaction in a Tapback. **Image Playground**gives users a way to create playful images in moments, with concepts like themes, costumes, accessories, and places. And they can add their own text descriptions, and create images in the likeness of a family member or friend using photos from their photo library. **Image Wand**can transform a rough sketch into a polished image that complements a user\u2019s notes. **Mail summaries**give users a way to view key details for an email or long thread by simply tapping or clicking Summarize. **Smart Reply**provides users with suggestions for a quick response in Mail and Messages.... - The\\n\\n**Reduce Interruptions**Focus surfaces only the notifications that might need immediate attention.\\n\\n**A Breakthrough for Privacy in AI**\\n\\nDesigned to protect users\u2019 privacy at every step, Apple Intelligence uses on-device processing, meaning that many of the models that power it run entirely on device. For requests that require access to larger models, Private Cloud Compute extends the privacy and security of iPhone into the cloud to unlock even more intelligence so a user\u2019s data is never stored or shared with Apple; it is used only to fulfill their request. Independent experts can inspect the code that runs on Apple silicon servers to continuously verify this privacy promise, and are already doing so. This is an extraordinary step forward for privacy in AI.\\n\\n**Availability**\\n\\nAll of these new features are available for testing starting today through the Apple Developer Program at developer.apple.com, and a public beta will be available through the Apple Beta Software Program next month at beta.apple.com. Users who enable Apple Intelligence on supported devices set to a supported language will have access this fall, including all iPhone 16 models, iPhone 15 Pro, iPhone 15 Pro Max, iPad mini (A17 Pro), and iPad and Mac models with M1 and later, with Siri and device language set to the same supported language: English, French, German, Italian, Portuguese (Brazil), Spanish, Japanese, Korean, or Chinese (simplified). More languages will be coming by the end of this year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese. Some features may not be available in all languages or regions, and availability may vary due to local laws and regulations. For more details, visit apple.com/apple-intelligence.\\n\\nShare article... ## Media\\n\\n\\n\\nText of this article\\n\\n\\n\\nImages in this article\\n\\n- Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.\\n\\n- Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified).\\n\\n- Live Translation in Phone and FaceTime is available for one-on-one calls in English (U.S., UK), French (France), German, Portuguese (Brazil), and Spanish (Spain).\\n\\n- The ability to add an event to Calendar with visual intelligence is available in English on all iPhone 16 models, iPhone 15 Pro, and iPhone 15 Pro Max.\\n\\n- Workout Buddy will be available on Apple Watch Series 6 or later, Apple Watch SE (2nd generation), and Apple Watch Ultra and Ultra 2 with an Apple Intelligence-supported iPhone starting in English.\\n\\n## Press Contacts\\n\\nNadine Haija\\n\\nApple\\n\\nAnna Tabet\\n\\nApple\\n\\nApple Media Helpline",
        "published_at": "2025-06-09"
      },
      {
        "title": "Apple Intelligence features show promise yet lack delivery",
        "url": "https://standard.asl.org/33883/arts/apple-intelligence-features-show-promise-yet-lack-delivery/",
        "snippet": "Since late 2022, advancements in the field of artificial intelligence, such as the release of OpenAI\u2019s ChatGPT and Dall-E, have sparked widespread discussion across the world. In the past year, multinationals and large corporations have bought into the AI zeitgeist, integrating new features in their products and even developing their own models. Apple, the global tech giant, has inevitably jumped on the bandwagon, introducing its own AI software: Apple Intelligence.\\n\\nWhen the iPhone 16 was released in September 2024, it was heralded as the first iPhone built from the ground up for Apple Intelligence, according to Apple. Subsequently, almost all of the marketing material for the iPhone 16 emphasized the new wave of AI features rather than the usual jargon concerning hardware upgrades.\\n\\nDespite this massive push towards AI, customers in the U.K. had to wait three months before being able to benefit from these features. This raised questions and caused frustration among consumers as they wondered why it had taken so long for Apple to release Apple Intelligence.\\n\\nThe new features released by Apple are promising. They are innovative, and, with further improvements, will hopefully make a name for themselves in the Apple ecosystem. However, their choice to market Apple Intelligence with the iPhone 16 was deceptive and subpar when compared to Apple\u2019s previous advertising/marketing strategies. According to Apple, Apple Intelligence features include Genmoji, Image Playground, Writing Tools and notification summaries.... **Genmoji\\n\\n**\\n\\nI was most excited about Genmoji. While it may seem as if there are already an exhaustive number of emojis, this feature allows you to create your own emojis from a text prompt. Some of the results highlighted in the initial showcase from Apple June 10, 2024 included \u201ca squirrel DJ\\n\\n*\u201d*and \u201ca smiley relaxing wearing cucumbers.\u201d Genmojis can only be created in a messaging app: users simply type their prompt into the text box, and it will generate multiple Genmojis to choose from. It is an attractive and well-designed feature with radiant colors and animations.\\n\\nThere are constraints on what you can create, but these are not readily explained in the program. If you were to type in something that violated the restrictions, instead of informing you, it simply states, \u201cNo Results,\u201d similar to if you were to type in a prompt that made no sense. For the most part, the Genmojis are crisp and pertinent, mimicking the familiar emoji style and format. However, a few Genmojis still carry that uncanny feeling typical of AI-generated images.\\n\\nAs with all Apple products, what makes Genmoji so appealing is its usability. It integrates smoothly with the existing emoji interface and the instructions are straightforward. Ultimately, I would give Genmoji a four out of five.... **Image Playground\\n\\n**\\n\\nGenmoji is not the only image-generation tool Apple now offers. Image Playground provides users the opportunity to create their own AI images similar to Midjourney or OpenAI\u2019s DallE. Available either in its own app or integrated into messaging software, much like Genmoji, Image Playground allows users to enter multiple separate prompts and watch as the software combines them to produce a final image.\\n\\nA known issue with AI image generators is the phenomenon of selection bias, where biases around race and gender can be perpetuated. According to Bloomberg, journalists found that images created by the AI tool Stable Diffusion often depicted higher-paying occupations with white males, while lower-paying jobs were associated with people of color. Apple has introduced a clever workaround to this problem by forcing users to specify characteristics like skin tone and gender when asked to make an image that includes a person. This, however, does not entirely solve the perpetuation of biases through AI models, and in order to better fix this issue, a more accurate data set to train AI on would be essential.\\n\\nDespite the many positives of Image Playground, I struggle to see a real need for it. The images all share a similar animated style and offer little in terms of personality. For now, at least, it is very much like a playground \u2014 a program to mess around with for a couple of minutes before you get bored and move on to something else. It is possible that this feature will serve a more defined purpose in the future. But, for now, I would give Image Playground a two out of five as it lacks utility.... Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse ac tortor sed\u2026\\n\\n**Writing Tools\\n\\n**\\n\\nWriting Tools is an AI writing solution designed for emails and notes, with two main components. The first is a proofreading and rewrite function. This tool checks for spelling and grammatical errors in existing text and can also rewrite a message to mimic a certain tone or style. The proofreading feature is effective and was able to pick up all of the errors in the sample emails I tested. I was also impressed with how it rewrote emails. Users can choose from three different styles \u2014 concise, friendly and professional. Each worked very well.\\n\\nThe second component of Writing Tools is the Compose feature, which integrates ChatGPT. Using ChatGPT, users can compose recipes, invitations and more or less anything. All in all, Writing Tools is a practical feature that has a wide variety of potential applications. I look forward to seeing how it will evolve in the future. I would award Writing Tools a five out of five for its usefulness and potential for growth.\\n\\n**N** **otification summaries\\n\\n**\\n\\nThe Notification Center has undergone a number of changes in recent years. It has improved its organization by attaching timestamps to messages and grouping notifications together. It is a very effective feature, and with notification summaries, Apple Intelligence hopes to make it even more streamlined. Notification summaries are fairly self-explanatory. As the name suggests, it takes messages or notifications from apps, games and messengers and summarizes them into brief overviews.... Each summary is accompanied by a small icon to indicate it is AI-generated. As with all Apple Intelligence features, notification summaries are entirely optional. It works by taking keywords and phrases from multiple text messages and condensing them into one or two-sentence summaries.\\n\\nHowever, I found the potential for AI hallucinations too high to rely on these summaries. AI hallucinations occur when generative AI models generate incorrect information, according to the International Business Machines Corporation. These hallucinations can be very problematic because there are often no clear indicators as to whether or not the AI is lying.\\n\\nDespite Apple\u2019s positive intentions, these summaries often hindered my understanding, forcing me to tap on the notifications to clarify what was being said. Overall, I would give this feature a three out of five. While it offers usefulness, the potential for errors outweighs any good it could do in saving you time.\\n\\nThe features discussed above are, hopefully, just the start of a long line of innovations and improvements in Apple Intelligence technology. Judging from its flaws, Apple Intelligence still appears to be quite primitive. Errors are common, which is understandable when a new technology hits the market, but when a technology has been hyped to the extent that Apple Intelligence was, consumer tolerance for error is less. With the full release of Apple Intelligence due in spring 2025, it is worth asking whether Apple should have waited for the release of the iPhone 17 instead.",
        "published_at": "2025-02-12"
      },
      {
        "title": "AI in the workplace: A report for 2025 - McKinsey",
        "url": "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work",
        "snippet": "##### Superagency in the workplace: Empowering people to unlock AI\u2019s full potential(47 pages)\\n\\n**Artificial intelligence has arrived in the workplace** and has the potential to be as transformative as the steam engine was to the 19th-century Industrial Revolution. 1 With powerful and capable large language models (LLMs) developed by Anthropic, Cohere, Google, Meta, Mistral, OpenAI, and others, we have entered a new information technology era. McKinsey research sizes the long-term AI opportunity at $4.4 trillion in added productivity growth potential from corporate use cases. 2\\n\\nTherein lies the challenge: the long-term potential of AI is great, but the short-term returns are unclear. Over the next three years, 92 percent of companies plan to increase their AI investments. But while nearly all companies are investing in AI, only 1 percent of leaders call their companies \u201cmature\u201d on the deployment spectrum, meaning that AI is fully integrated into workflows and drives substantial business outcomes. The big question is how business leaders can deploy capital and steer their organizations closer to AI maturity.\\n\\nThis research report, prompted by Reid Hoffman\u2019s book\\n\\n*Superagency: What Could Possibly Go Right with Our AI Future*, 3 asks a similar question: How can companies harness AI to amplify human agency and unlock new levels of creativity and productivity in the workplace? AI could drive enormous positive and disruptive change. This transformation will take some time, but leaders must not be dissuaded. Instead, they must advance boldly today to avoid becoming uncompetitive tomorrow. The history of major economic and technological shifts shows that such moments can define the rise and fall of companies. Over 40 years ago, the internet was born. Since then, companies including Alphabet, Amazon, Apple, Meta, and Microsoft have attained trillion-dollar market capitalizations. Even more profoundly, the internet changed the anatomy of work and access to information. AI now is like the internet many years ago: The risk for business leaders is not thinking too big, but rather too small.\\n\\nThis report explores companies\u2019 technology and business readiness for AI adoption (see sidebar \u201cAbout the survey\u201d). It concludes that employees are ready for AI. The biggest barrier to success is leadership.... ### Beyond the tipping point\\n\\nIn our survey, nearly all employees (94 percent) and C-suite leaders (99 percent) report having some level of familiarity with gen AI tools. Nevertheless, business leaders underestimate how extensively their employees are using gen AI. C-suite leaders estimate that only 4 percent of employees use gen AI for at least 30 percent of their daily work, when in fact that percentage is three times greater, as self-reported by employees (Exhibit 2). And while only a total of 20 percent of leaders believe employees will use gen AI for more than 30 percent of their daily tasks within a year, employees are twice as likely (47 percent) to believe they will (see sidebar \u201cWho is using AI at work? Nearly everyone, even skeptical employees\u201d).\\n\\nThe good news is that our survey suggests three ways companies can accelerate AI adoption and move toward AI maturity.\\n\\nImage description begins:... For example, two of the sunrays represent two separate sentiments, \u201chas extensive familiarity with gen AI\u201d and \u201chas at least some familiarity with gen AI.\u201d The Doomer archetype shows 16 percent with extensive familiarity and 71 percent with at least some familiarity. The Gloomer archetype demonstrates significantly higher percentages: 42 percent with extensive familiarity and 94 percent with at least some. The Bloomer archetype shows 55 percent with extensive familiarity and 96 percent with at least some, and the Zoomer archetype shows 67 percent with extensive familiarity and 96 percent with at least some.\\n\\nThe exhibit further illustrates employees\u2019 comfort levels with using gen AI results, belief in the net benefits of gen AI within the next five years, and plans to utilize gen AI more in their personal lives. In the Doomer archetype, 47 percent say they are comfortable using gen AI results, 54 percent believe in gen AI\u2019s net benefit within the next five years, and 49 percent plan increased personal use of gen AI. The Gloomer archetype shows markedly higher percentages in these three areas: 79 percent, 82 percent, and 77 percent respectively. The Bloomer and Zoomer archetypes present even higher percentages across these three metrics; for instance, 91 percent of Zoomers are comfortable using gen AI results, 87 percent believe in gen AI\u2019s net benefit within five years, and 85 percent plan to increase their personal use of gen AI.... Image description begins:\\n\\nThe exhibit shows US C-suite executive sentiment toward the pace of development and release of gen AI tools within their organizations, in the form of two segmented bar charts.\\n\\nThe first bar chart presents the overall perception of the pace, where 47 percent of respondents find the pace to be too slow, while 45 percent feel it is about right, and a smaller 9 percent consider it too fast. The second bar chart delves into the top reasons behind the perceived slow pace of gen AI tool development and release in executives\u2019 organizations, focusing on the responses from those who indicated that development was too slow. The most prominent reason cited is talent skill gaps, accounting for 46 percent of these responses. Resourcing constraints followed closely, with 38 percent of respondents identifying this as a key factor. Complex approval process and technical complexity each receive 8 percent of the responses. Source: McKinsey US CxO survey, Oct-Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool.\\n\\nImage description ends.\\n\\nBusiness leaders are trying to meet the need for speed by increasing investments in AI. Of the executives surveyed, 92 percent say they expect to boost spending on AI in the next three years, with 55 percent expecting investments to increase by at least 10 percent from current levels. But they can no longer just spend on AI without expecting results. As companies move on from the initial thrill of gen AI, business leaders face increasing pressure to generate ROI from their gen AI deployments.... ### AI investments vary by industry\\n\\nDifferent industries have different AI investment patterns. Within the top 25 percent of spenders, companies in healthcare, technology, media and telecom, advanced industries, and agriculture are ahead of the pack (Exhibit 12). Companies in financial services, energy and materials, consumer goods and retail, hardware engineering and construction, and travel, transport, and logistics are spending less. The consumer industry\u2014despite boasting the second-highest potential for value realization from AI\u2014seems least willing to invest, with only 7 percent of respondents qualifying in the top quartile, based on self-reported percentage of revenue spend on gen AI. That hesitation may be explained by the industry\u2019s low average net margins in mass-market categories and thus higher confidence thresholds for adopting costly organization-wide technology upgrades.\\n\\nImage description begins:\\n\\nThe scatterplot exhibit depicts how companies\u2019 gen AI spend does not match the economic potential in their industries. The exhibit illustrates that several industries with a high economic potential from gen AI are not yet spending significantly on the technology. It shows the relationship between the industry share of overall survey respondents and the industry share of top-quartile gen AI spending. On both axes, the top value is set to 35 percent. The size of each circle represents the economic potential from gen AI in billions of dollars for each industry.... ### There\u2019s a lot of headroom in some functions\\n\\nOur research finds that the functional areas where AI presents the greatest economic potential are also those where employee outlook is lukewarm. Employees in sales and marketing, software engineering, customer service, and R&D contribute roughly three-quarters of AI\u2019s total economic potential, but the self-reported optimism of employees in these functions is middling (Exhibit 14). It may be the case that these functions have piloted AI projects, leading employees to be more realistic about AI\u2019s benefits and limitations. Or perhaps the economic potential has made them worry that AI could replace their jobs. Whatever the reasons, leaders in these functions might consider investing more in employee support and elevating the change champions who can improve that sentiment.\\n\\nImage description begins:\\n\\nThe exhibit is made up of a scatter plot and a separate bar chart visualizing the relationship between the potential economic value from gen AI and the share of employees with a positive outlook on gen AI, categorized by business function. The exhibit illustrates that the functions with the employees most optimistic about gen AI are not the functions with the greatest potential economic value from gen AI.\\n\\nThe scatter plot displays business functions: sales and marketing, software engineering, customer service, R&D, legal, risk, and compliance, operations, HR, strategy, supply chain, finance, procurement, and IT. Each function is represented by a data point, with its horizontal position indicating the percentage of employees expressing a positive outlook on gen AI, and its vertical position representing the potential economic value of gen AI in those functions, in trillions of dollars. Sales and marketing shows the highest potential economic value and around 50 percent of employees with a positive outlook. Software engineering is the function with second-highest economic potential from gen AI, with again about 50 percent of employees in that function reporting being optimistic about gen AI. Customer service and R&D also show about 50 percent of employees with a positive outlook on gen AI, but a much lower potential economic value. Several functions, such as operations, HR, Strategy, and IT, cluster together with low potential economic value and similarly middling employee optimism. Employes in IT, finance, and procurement are the most optimistic about gen AI, with about 70 percent of employees reporting positive sentiment, but these functions represent low economic potential from gen AI.",
        "published_at": "2025-01-28"
      },
      {
        "title": "It's Time for a 2025 AI Heat Check: Is it Delivering or 'Overhyped'?",
        "url": "https://www.uctoday.com/collaboration/its-time-for-a-2025-ai-heat-check-is-it-delivering-or-overhyped/",
        "snippet": "Almost three years into the post-ChatGPT AI explosion, the technology continues to be the defining trend in not only communications and collaboration but also the business world at large.\\n\\nYou can\u2019t move an inch for big and bold promises right now, from copilots to take the admin off your plate to assistants to make meetings smarter, bots to boost productivity, and AI platforms to elevate the fundamentals of workflows. Yet for all the noise, quieter, more urgent questions are emerging in the minds of IT leaders and tech execs: What\u2019s actually real, and where\u2019s the tangible value?\\n\\nBehind the dazzling demos and slick marketing, many teams are still labouring in pilot purgatory. Shadow AI is creeping in under the radar, and diligent governance far too frequently feels like an afterthought. While vendors race to ship AI features at speed, CIOs are being asked to justify spending, mitigate risk, and somehow transform potential into real business value, without the luxury of patience or longer-term strategic plans.\\n\\nSo, where are we in the AI hype cycle? Have we hit peak expectation? Or are we finally entering the phase where AI delivers something concrete?\\n\\nTo find out,\\n\\n**UC Today** canvassed its panel of analysts and experts from across the unified communications and collaboration space to take stock, frankly and pragmatically, of where things stand. As major AI announcements from all the big players in recent weeks indicate, including Microsoft at its Build showcase and a seismic Zoom partnership revealed at Google I/O, the hype isn\u2019t going away anytime soon. But the more compelling story is what happens next.... ## Where AI Actually Stands for Organisations, From Pilot Fatigue to Production Pressure\\n\\n**Blair Pleasant, President and Analyst at COMMFusion**, recently wrote a report breaking down exactly this topic and is understandably conflicted in her assessment: \u201cLet me start by saying: I\u2019m very pro-AI. I\u2019ve seen some amazing use cases, especially in healthcare, that show how transformative it can be. But I\u2019m also concerned that it\u2019s become overhyped.\u201d\\n\\nCompanies are rushing to deploy it without proper strategies, and I think we\u2019ll see some poor and even dangerous implementations in the coming months and years.\u201d\\n\\nPleasant suggested that the industry itself is complicit, with the numbers posted by vendors and analysts often inflated wildly. She highlights claims like \u201c98 percent of contact centres are using AI\u201d or \u201c90 percent of small businesses are using it daily,\u201d but most small businesses she talks to don\u2019t even understand what AI is, let alone use it meaningfully. One worrying outcome from this discourse might be that these inflated stats pressure companies into adopting AI prematurely.\\n\\n\u201cAt customer conferences, I always speak to the users, not just the ones on stage,\u201d Pleasant added. \u201cMost are still in the early stages: doing POCs and rolling it out to a department or two. Very few have fully deployed AI solutions.\u201d... \u201cI also surveyed consultants and resellers recently. One said that when vendors speak off the record, they admit AI adoption is much slower than hoped. Many clients don\u2019t know how to begin or are afraid of getting it wrong. Another noted that large enterprises are further along, while smaller firms are lagging, often just using AI features embedded in vendor tools.\u201d\\n\\nPleasant\u2019s essential argument is that AI\\n\\n*can* be great, and many companies *are* using it, but it needs to go well beyond merely drafting emails or writing blogs. Before it can genuinely fulfil its potential, it needs to be truly integrated into business workflows, changing how companies operate at a fundamental level.\\n\\nMeanwhile, the hype is driving a sense of urgency that isn\u2019t always matched with readiness. Companies are deploying without strategy, security, or guardrails.\u201d\\n\\n\u201cJust last week, my local government launched a legal chatbot,\u201d Pleasant said. \u201cThe terms of service were laughable. It basically said, \u2018We make no guarantees, and we\u2019re not responsible for any bad info this chatbot gives you.\u2019 That\u2019s the reality. Everyone\u2019s covering themselves legally because mistakes are inevitable.\u201d\\n\\n\u201cDon\u2019t rush in just because your CEO says, \u2018We need AI.\u2019 Make sure you have a thoughtful strategy, solid security, and proper governance in place.\u201d... ## AI Washing, Governance Gaps and the Risk of Rushing In\\n\\nThe rest of the panel is similarly mixed on AI\u2019s current position on the hype cycle.\\n\\n\u201cI think it really depends on the type and size of the organisation,\u201d suggested\\n\\n**Derrick Kelly, VP of Solutions Enablement at AVI-SPL**. \u201cWe\u2019ve had successful global deployments with large enterprises, well-planned, phased, and properly supported. On the other hand, we also see organisations just starting to ask basic questions.\u201d\\n\\n\u201cThere\u2019s a lot of opportunity, but that includes both legitimate implementations and people trying to sell AI before companies are ready. When that happens, and deployments go wrong, it can set the industry back. Those stories travel fast.\u201d\\n\\nKelly outlined that the successful rollouts AVI-SPL has observed have involved careful planning, stakeholder consultation, and a phased approach, rather than as a knee-jerk reaction to the hype: \u201cBut that\u2019s true of any technology; you have to do it right, or the results will suffer.\u201d\\n\\n**Melody Brue, Vice President and Principal Analyst at Moor Insights and Strategy**, agrees that organisations currently feel like they are wielding a hammer and looking for a nail, using AI for the sake of it instead of solving real problems.... \u201cWhen surveys say \u201990 per cent of companies use AI,\u2019 that might just mean someone used ChatGPT once to ask a question, not that AI is driving business transformation,\u201d Brue said.\\n\\nWe\u2019re in a typical hype cycle: overpromise, underdeliver, followed by a massive investment wave. CEOs are saying this\\n\\nmustbe a multi-trillion-dollar market; otherwise, the hundreds of billions already invested have gone to waste.\u201d\\n\\nHowever, Brue asserted that while the expectations might be out of control, that doesn\u2019t mean there isn\u2019t still incredible substance underpinning it.\\n\\n\u201cThere\u2019s hype, but it\u2019s also pushing investment, innovation, and momentum,\u201d Brue highlighted. \u201cMicrosoft\u2019s Work Trend Index talks about \u2018frontier firms\u2019 leading the way. Those efforts need support from the top and champions at every level.\u201d\\n\\n\u201cI just came back from ServiceNow\u2019s Knowledge conference, and I got the same message there. Yes, jobs will be replaced, but others will be created. People saying \u201cAI will take all our jobs\u201d are underestimating human adaptability. AI only knows what humans have taught it. If people stop feeding it ideas, it runs out of steam.\u201d\\n\\n\u201cStill, there\u2019s a lot of \u2018AI-washing\u2019 going on. I saw a post recently where someone shared an iPhone screen protector marketed as \u2018AI-optimised.\u2019 That\u2019s when you know the hype is out of control.\u201d... ## What IT Leaders Could Really Gain From AI Next: Value Over Vanity\\n\\nFor\\n\\n**Craig Durr, Chief Analyst and Founder of The Collab Collective**, this stage of the hype cycle marks the \u201ctrough of despair,\u201d as in the gulf between expectations and reality.\\n\\nHowever, he also offered a positive angle around AI\u2019s progress: \u201cThe most successful AI I see is what I call \u2018boring AI\u2019, used in places like contact centres. You can measure things like time-to-resolution or outcomes that impact real business metrics. Zendesk, for instance, is starting to base licensing on outcome-based performance.\u201d\\n\\nKelly agreed that the long-term value lies in total customer experience.\\n\\n\u201cAI can help unify everything from logistics and reporting to real-time translation in UC&C,\u201d he expanded. \u201cAs tools mature and investment continues, we\u2019ll see deeper integration. Agentic AI is the next buzzword, sure, but pairing that with \u2018boring\u2019 automation, like moving a customer interaction through the full process without manual intervention, can be powerful.\u201d\\n\\nAI should assist humans, not replace them. Companies that plan with that in mind will see the biggest gains.\u201d\\n\\nDurr stressed that these types of deployments, whether in customer experience and the contact centre or in the business world more broadly, often come from pressure at the top: \u201cCEO says, \u2018What\u2019s our AI plan?\u2019 CTO says, \u2018We\u2019ve got it,\u2019 and CFO says, \u2018What\u2019s the ROI?\u2019 The teams that find success are solving boring, measurable problems.\u201d\\n\\nBrue agreed, drawing parallels with what Bill McDermott calls \u201csoul-crushing work\u201d. \u201cThat\u2019s where we\u2019ll first see impact, eliminating repetitive tasks so humans can focus on higher-value work,\u201d she elaborated.\\n\\n\u201cEventually, AI will be embedded in everything, like online access or SaaS models,\u201d Durr continued. \u201cThe pressure to justify it will fade. But for now, yes, we\u2019re still in the hype phase, like that absurd \u2018AI-optimised\u2019 iPhone case.\u201d\\n\\n\u201cTo sum up: yes, use AI, but do it properly,\u201d Pleasant bookended the conversation. \u201cMake sure you have strategy, security, and guardrails. Don\u2019t just jump in because you\u2019re afraid of being left behind or just because your neighbour\u2019s doing it.\u201d\\n\\n\u201cAnd don\u2019t just slap an \u2018AI\u2019 label on everything!\u201d Brue added.",
        "published_at": "2025-06-02"
      },
      {
        "title": "AI Agents in 2025: Expectations vs. Reality",
        "url": "https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality",
        "snippet": "It\u2019s impossible to take two steps across the tech media landscape without stumbling over an article hailing 2025 as the year of the AI agent. Agents, we\u2019re told, will transform the way work is done, impacting every facet of our lives, personal and professional.\\n\\nWe\u2019d barely surfaced from a landslide of NFT and crypto hype that characterized the early 2020s, and the metaverse bubble that followed, before media voices began singing the praises of generative AI (gen AI) in the wake of releases such as OpenAI\u2019s GPT model family, Anthropic\u2019s Claude and Microsoft\u2019s Copilot.\\n\\nWhile the chorus hasn\u2019t moved on entirely, the focus in 2025 has shifted from large language models (LLMs) to advancements in the ostensibly autonomous artificial intelligence (AI) agents ushering in the future of work.\\n\\nDespite a momentary surge in gen AI interest around Deepseek\u2019s R1, which promised significant performance improvements over ChatGPT, the dominant innovation narrative in 2025 is the AI agent.\\n\\nMedia coverage highlights the promises of innovation, automation and efficiency agents will bring, but how much of the conversation is click-hungry hype?\\n\\nThe ad-supported media world thrives on clicks, and it\u2019s reasonable to expect sensational, attention-grabbing headlines crafted to garner yours. But what can we realistically expect from agentic AI in 2025, and how will it affect our lives?... With regard to 2025 being the year of the agent, Danilevsky is skeptical. \u201cIt depends on what you say an agent is, what you think an agent is going to accomplish and what kind of value you think it will bring,\u201d she says. \u201cIt's quite a statement to make when we haven't even yet figured out ROI (return on investment) on LLM technology more generally.\u201d\\n\\nAnd it\u2019s not just the business side that has her hedging her bets. \u201cThere's the hype of imagining if this thing could think for you and make all these decisions and take actions on your computer. Realistically, that's terrifying.\u201d\\n\\nDanilevsky frames the disconnect as one of miscommunication. \u201c[Agents] tend to be very ineffective because humans are very bad communicators. We still can't get chat agents to interpret what you want correctly all the time.\u201d\\n\\nStill, the forthcoming year holds a lot of promise as an era of experimentation. \u201cI'm a big believer in [2025 as the year of the agent],\u201d says Hay excitedly.\\n\\nEvery large tech company and hundreds of startups are now experimenting with agents. Salesforce, for example, has released their Agentforce platform, which enables users to create agents that are easily integrated within the Salesforce app ecosystem.\\n\\n\u201cThe wave is coming and we're going to have a lot of agents. It's still a very nascent ecosystem, so I think a lot of people are going to build agents, and they're going to have a lot of fun.\u201d... This narrative assumes that today\u2019s agents meet the theoretical definition outlined in the introduction to this piece. 2025\u2019s agents will be fully autonomous AI programs that can scope out a project and complete it with all the necessary tools they need and with no help from human partners. But what\u2019s missing from this narrative is nuance.\\n\\nHay believes that the groundwork has already been laid for such developments. \u201cThe big thing about agents is that they have the ability to plan,\u201d he outlines. \u201cThey have the ability to reason, to use tools and perform tasks, and they need to do it at speed and scale.\u201d\\n\\nHe cites 4 developments that, compared to the best models of 12 to 18 months ago, mean that the models of early 2025 can power the agents envisioned by the proponents of this narrative:\\n\\nBetter, faster, smaller models\\n\\nChain-of-thought (COT) training\\n\\nIncreased context windows\\n\\nFunction calling\\n\\n\u201cNow, most of these things are in play,\u201d Hay continues. \u201cYou can have the AI call tools. It can plan. It can reason and come back with good answers. It can use inference-time compute. You\u2019ll have better chains of thought and more memory to work with. It's going to run fast. It\u2019s going to be cheap. That leads you to a structure where I think you can have agents. The models are improving and they're getting better, so that's only going to accelerate.\u201d... And while Hay is hopeful about the potential for agentic development in 2025, he sees a problem in another area: \u201cMost organizations aren't agent-ready. What's going to be interesting is exposing the APIs that you have in your enterprises today. That's where the exciting work is going to be. And that's not about how good the models are going to be. That's going to be about how enterprise-ready you are.\u201d\\n\\nThe \u201cnew normal\u201d envisioned by this narrative sees teams of AI agents corralled under orchestrator uber-models that manage the overall project workflow.\\n\\nEnterprises will use AI orchestration to coordinate multiple agents and other machine learning (ML) models working in tandem and using specific expertise to complete tasks.\\n\\nGajjar views this prediction not only as credible, but likely. \u201cWe\u2019re at the very beginning of this shift, but it\u2019s moving fast. AI orchestrators could easily become the backbone of enterprise AI systems this year\u2014connecting multiple agents, optimizing AI workflows and handling multilingual and multimedia data,\u201d she opines. However, she cautions against rushing in without appropriate safeguards in place.\\n\\n\u201cAt the same time, scaling these systems will need strong compliance frameworks to keep things running smoothly without sacrificing accountability,\u201d warns Gajjar. \u201c2025 might be the year we go from experiments to large-scale adoption, and I can\u2019t wait to see how companies balance speed with responsibility.\u201d... Danilevsky shares Ashoori\u2019s view and notes that the adoption of agents in the workplace will not come without growing pains. \u201cYou're still going to have cases where as soon as something gets more complex, you're going to need a human.\u201d While business leaders may be tempted to cut short-term costs by eliminating jobs, agent use \u201c...is going to settle down much more into an augmented sort of role. You're supposed to constantly have a human, and the human is being helped, but the human makes the final decisions,\u201d says Danilevsky, describing her human-in-the-loop (HITL) vision for AI.\\n\\nHay sees a pathway towards sustainable AI adoption at work. \u201cIf we do this right, AI is there to augment humans to do things better. If AI is done correctly, then it frees us up to do more interesting things.\u201d But at the same time, he can imagine another version of the future where AI is prioritized too highly. \u201cThere is a real risk that when done badly and wrongly, that we end up with humans augmenting the AI as opposed to the other way around.\u201d\\n\\nGajjar also cautions against leaning too heavily on AI. \u201cI don\u2019t see AI agents replacing jobs overnight, but they\u2019ll definitely reshape how we work. Repetitive, low-value tasks are already being automated, which frees people up for more strategic and creative work. That said, companies need to be intentional about how they introduce AI. Governance frameworks\u2014like those focused on fairness, transparency and accountability\u2014are going to be key.\u201d... \u201cThe current AI boom is absolutely FOMO-driven, and it will calm down when the technology becomes more normalized,\u201d predicts Danilevsky. \u201cI think that people will start to understand better what kinds of things work and don't.\u201d \u201cThe focus should also be on integrating AI agents into ecosystems where they can learn and adapt continuously, driving long-term efficiency gains,\u201d adds Gajjar.\\n\\nDanilevsky is quick to ground expectations and recenter the conversation on demonstrable business needs. \u201cEnterprises need to be careful to not become the hammer in search of a nail,\u201d she begins. \u201cWe had this when LLMs first came on the scene. People said, \u2018Step one: we\u2019re going to use LLMs. Step two: What should we use them for?\u2019\u201d\\n\\nHay encourages enterprises to get agent-ready ahead of time. \u201cThe value is going to be with those organizations that take their private data and organize that in such a way so that the agents are researching against your documents.\u201d Every enterprise houses a wealth of valuable proprietary data, and transforming that data so that it can power agentic workflows supports positive ROI.... \u201cWith agents, enterprises have an option to leverage their proprietary data and existing enterprise workflows to differentiate and scale,\u201d says Ashoori. \u201cLast year was the year of experimentation and exploration for enterprises. They need to scale that impact and maximize their ROI of generative AI. Agents are the ticket to making that happen.\u201d\\n\\nFor more information on successful AI implementation in the enterprise, read Maryam Ashoori\u2019s guide to agentic AI cost analysis. Also be sure to catch Vyoma Gajjar and Chris Hay expounding on their predictions for AI in 2025 on IBM\u2019s Mixture of Experts podcast.\\n\\n1 5 Predictions for AI in 2025, Tharin Pillay and Harry Booth, Time, 16 January 2025.\\n\\n2 Autonomous agents and profitability to dominate AI agenda in 2025, executives forecast, Katie Paul, Reuters, 13 December 2024.\\n\\n3 2025: Agentic and Physical AI \u2014 A Multitrillion Dollar Economy Emerges, Timothy Papandreou, Forbes, 15 January 2025.\\n\\nDownload this Gartner\u00ae research to learn the potential opportunities and risks of agentic AI for IT leaders and how to prepare for this next wave of AI innovation.\\n\\nBuild, deploy and manage powerful AI assistants and agents that automate workflows and processes with generative AI.\\n\\nBuild the future of your business with AI solutions that you can trust.\\n\\nIBM Consulting AI services help reimagine how businesses work with AI for transformation.\\n\\nWhether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.",
        "published_at": "2025-03-04"
      },
      {
        "title": "The Reality of AI Oversold and Underdelivered",
        "url": "https://www.isaca.org/resources/news-and-trends/industry-news/2025/the-reality-of-ai-oversold-and-underdelivered",
        "snippet": "Artificial intelligence (AI), especially generative AI, has been dominating headlines and enterprise conversations in recent years. This innovation has been touted as a transformative force that will revolutionize everything from menial tasks to advanced analysis. Vendors, investors, venture capitalists, and media outlets have collectively fueled a narrative that positions AI as the solution to nearly every business challenge, promising unprecedented efficiency, automation, and insight.\\n\\n1\\n\\nWhile AI undoubtedly has had impressive achievements, many of those wins are narrow, context-dependent, and, frequently, hard to achieve. Organizations are beginning to discover that the road to meaningful AI adoption is far more complex\u2014and costly\u2014than what was initially anticipated.\\n\\n2 From the need for massive infrastructure investments and robust datasets to unforeseen security vulnerabilities, intellectual property risk, and lagging returns on investment, the promises of AI have frequently outpaced the outcomes. 3\\n\\nThe reality is that AI implementation often creates new layers of risk. Security professionals are grappling with increased attack surfaces, governance professionals are facing mounting concerns around explainability and compliance, and risk professionals are being asked to sign off on implementations where the decisions made by models cannot be thoroughly audited.\\n\\nDespite these challenges, it seems that the AI hype is not slowing down. In many cases, vendors are overpromising and underdelivering by adding AI features to tools where they are not necessary.... 4 AI has seemingly gone from an exciting new tool to a glorified data-harvesting vacuum sucking up input from nearly every crevice of everyday life. Executives and users alike are growing wary of AI's creeping presence, especially when the value it brings is unclear and, more concerning, its risk is poorly managed. 5\\n\\nThese concerns were validated in a June 2025 study conducted by Apple researchers, who found that large reasoning models (LRMs)\u2014a class of advanced generative AI that uses chain of thought\u2014suffer from \u201ccomplete accuracy collapse\u201d when faced with even low-complexity reasoning tasks.\\n\\n6 In many cases, the models simply halted altogether, unable to complete logical sequences. Cognitive scientist Gary Marcus called this a \u201cknockout blow for LLMs,\u201d arguing that such models rely on surface-level pattern matching rather than actual comprehension or reasoning capabilities. 7 This inability to reason becomes problematic as pattern matching models do not actually understand the content they are generating. Instead, they statistically predict the next likely word or phrase based on the training data, not context or logic. For enterprises, this means AI systems will likely produce confident-sounding answers that are incorrect, potentially misleading decision makers with hallucinated insights, or failing in cases where nuance or reasoning is required. 8 Organizations that rely on these models without robust validation risk introducing errors into financial forecasts, compliance reporting, policy decisions or customer communications, all of which are areas where accuracy and accountability are non-negotiable.\\n\\nThese findings suggest that many enterprise-grade AI deployments may be built on fragile foundations: highly capable in their demos, but prone to failure when faced with real-world complexity.... ## Acknowledging AI\u2019s Value\u2014But at What Cost?\\n\\nAI has undeniably provided value by optimizing efficiency and assisting with decision making. However, the recent surge in generative AI has shifted the focus from purposeful innovation to a race for feature saturation. In an effort to appear technologically advanced and competitive, vendors are rapidly embedding AI into an increasing number of products.\\n\\nThis trend has led to bloated tools with superficial AI features that contribute more to complexity, cost, and risk than to meaningful outcomes.\\n\\n9 Oftentimes, AI-enabled features are added to products merely for show\u2014lightweight features that offer little functional value are included to feed into market hype or meet investor expectations. 10 Rather than driving innovation, AI is increasingly being used to meet market expectations rather than operational needs. The unchecked proliferation of AI is now outpacing the ability of enterprise teams to manage associated risk. Security professionals are struggling to conduct adversarial testing, monitor model-specific vulnerabilities (such as prompt injection or data leakage), or audit black box AI systems that behave unpredictably under pressure. Furthermore, privacy professionals face challenges as these models increasingly engage in inference-based profiling such as drawing sensitive conclusions about users from seemingly innocuous data, often without consent or visibility into its reasoning. Governance professionals are attempting to apply risk models to tools that do not behave like traditional software, lacking transparency, traceability, or any clear accountability.... Further compounding these challenges is a fragmented global regulatory landscape. The European Union\u2019s AI Act has emerged as the most comprehensive attempt at AI regulation to date.\\n\\n11 However, other jurisdictions\u2014such as in Canada, where the AI and Data Act (AIDA) remains in legislative limbo, and the United States, which lacks a unified framework\u2014are falling behind. The United States instead relies on state-level laws targeting issues such as algorithmic bias (Colorado), employment surveillance (Illinois), or deepfake misuse (California and New Hampshire). 12 This regulatory disparity creates uncertainty and compliance burdens for global enterprises deploying AI across borders, and pending litigation over claims of unlawful model training threatens to cause major upheaval. 13\\n\\nThe result is a rapid escalation in enterprises harvesting data to train AI systems, often without sufficient oversight, user consent, or transparency. For instance, Meta\u2019s LLaMA models were reportedly trained on datasets that included pirated books and copywritten materials that were used without obtaining permission from authors or publishers.\\n\\n14 Similarly, OpenAI allegedly scraped user data, web copy, and personal information from across the internet to build its GPT models, all without obtaining the explicit consent of the affected parties. 15 Google has also faced backlash for updating its privacy policy in mid-2023 to retroactively authorize the use of public user data for AI training\u2014after such data had already been collected. 16 While some AI use cases may be valid, the pace and scale of AI integration are introducing new attack surfaces and even more privacy violations. 17 Moreover, ethical gray areas are being introduced faster than industry standards and policies can mature and be adopted. Instead of being a strategic asset, AI is increasingly becoming a liability masked as innovation.... ## Conclusion\\n\\nThe fascination with AI, especially generative AI, has undoubtedly increased experimentation and innovation, but it has also driven significant overreach in its implementation and adoption. While AI has demonstrated that it has real value in some areas, industries around the globe are grappling with the consequences of inflated expectations, premature adoption, and superficial integration. Vendors have too often positioned AI as a default solution rather than a purposeful one, leading to bloated products, increased operational complexity, new security vulnerabilities, governance gaps, and mounting technical debt.\\n\\nFor AI to deliver on its promised potential, the industry must shift from hype to discipline, where AI addresses a defined problem, and its deployment is governed by rigorous controls around data privacy, model transparency, and security. It also means resisting market pressure to embed AI into everything and instead focusing on responsible innovation that aligns with core business goals.\\n\\nFor digital trust professionals, the path forward is clear: Demand better accountability, question exaggerated claims, and ensure that AI deployments are auditable, ethical, and aligned with a strategy. The illusion that AI makes everything better must end in order to realize its true value as a tool, rather than a gimmick.... ## Endnotes\\n\\n1 McKinsey & Company, \u201cThe Economic Potential of Generative AI: The Next Productivity Frontier,\u201d 14 June 2023\\n\\n2 Marcus, G.; \u201cGenAI\u2019s Day of Reckoning May Have Come,\u201d Marcus on AI, 27 March 2025\\n\\n3 Invictus Sovereign, \u201cWhat are the Infrastructure Demands of AI?,\u201d 16 January 2025; Farrar, O.; \u201cUnderstanding AI Vulnerabilities,\u201d *Harvard Magazine*, 21 March 2025; Marcus, G.; \u201cPoor ROI for GenAI,\u201d Marcus on AI, 10 April 2025\\n\\n4 Gomes, G.; \u201cHype Over Reality: \u2018AI Washing\u2019 and Why Is it a Problem?,\u201d *CTO Magazine*, 23 May 2025; Yancey, J.; \u201cAI-Powered Everything, Whether You Need It or Not: The SaaS Race to Irrelevance,\u201d Medium, 17 September 2024\\n\\n5 EY, \u201cCEO Confidence in Artificial Intelligence Tempered by, Social, Ethical, and Security Risks,\u201d 24 July 2023\\n\\n6 Shojaee, P.; Mirzadeh, I.; et al.; \u201cThe Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity,\u201d Apple Machine Learning Research, June 2025; Milmo, D.; \u201cAdvanced AI Suffers \u2018Complete Accuracy Collapse\u2019 in Face of Complex Problem, Study Finds,\u201d *The Guardian*, 9 June 2025... 7 Marcus, G.; \u201cA Knockout Blow for LLMs?,\u201d Marcus on AI, 7 June 2025\\n\\n8 Wilkinson, L.; \u201cAI Project Failure Rates are on the Rise: Report,\u201d CIO Dive, 14 March 2025\\n\\n9 Doidge, F.; \u201cThreats Versus Potential Benefits: Weighing up the Enterprise Risk of Embracing AI,\u201d ComputerWeekly.com, 9 May 2025\\n\\n10 Ahmed, S.; \u201cAI Washing: The New \u2018Dot-Com\u2019 Hype \u2014 How Companies Are Misleading Investors and Consumers,\u201d Medium, 14 September 2024\\n\\n11 Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act)",
        "published_at": "2025-07-03"
      }
    ]
  }
];
